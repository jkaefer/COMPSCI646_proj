{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "#to use persistent storage"
      ],
      "metadata": {
        "id": "O3oCRv-xgI65",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "268d3b75-183a-4034-bedd-85125085a9a7"
      },
      "id": "O3oCRv-xgI65",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JQc0TxrW1mzE",
        "outputId": "f864250c-e614-490e-8711-2092545f0db2"
      },
      "id": "JQc0TxrW1mzE",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2024 NVIDIA Corporation\n",
            "Built on Thu_Jun__6_02:18:23_PDT_2024\n",
            "Cuda compilation tools, release 12.5, V12.5.82\n",
            "Build cuda_12.5.r12.5/compiler.34385749_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb996d13-4150-484b-8825-004e7e8b507c",
      "metadata": {
        "id": "cb996d13-4150-484b-8825-004e7e8b507c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1939fd51-137e-4602-c83c-1222c1af2746"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import os\n",
        "import json\n",
        "\n",
        "# Append the directory containing your package\n",
        "#sys.path.append(os.path.abspath('/content/drive/MyDrive/mRAG_and_MSRS_source'))\n",
        "#data_path = \"/content/drive/MyDrive/mRAG_and_MSRS_source\"\n",
        "\n",
        "#location of corpus\n",
        "jsonl_dir = '/content/drive/MyDrive/mRAG_and_MSRS_source/jsonl_collections'\n",
        "\n",
        "index_dir = '/content/drive/MyDrive/mRAG_and_MSRS_source/index'\n",
        "print(os.path.isdir(jsonl_dir))\n",
        "\n",
        "#corpus_chunk_dir = os.path.join(data_path, \"jsonl_collections\") # storing the converted corpus entries\n",
        "#index_dir = os.path.join(data_path, \"index\") #  storing the index components from pyserini\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#NOTE: harmless runtime restart will take place, just need to reexecute this block\n",
        "\n",
        "!pip -q install condacolab\n",
        "import condacolab; condacolab.install()\n",
        "\n",
        "#creating two envs because these were technically 2 apps with 2 different requirements.txt(dependencies) in the mRAG repository\n",
        "!mamba create -y -n retriever python=3.11\n",
        "!mamba create -y -n train_and_test python=3.11\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sbctJKiT6RIA",
        "outputId": "0d0a0d84-181d-4f35-e204-f3b063c5e45d",
        "collapsed": true
      },
      "id": "sbctJKiT6RIA",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ¨ðŸ°âœ¨ Everything looks OK!\n",
            "\n",
            "Looking for: ['python=3.11']\n",
            "\n",
            "conda-forge/linux-64                                        Using cache\n",
            "conda-forge/noarch                                          Using cache\n",
            "Transaction\n",
            "\n",
            "  Prefix: /usr/local/envs/retriever\n",
            "\n",
            "  Updating specs:\n",
            "\n",
            "   - python=3.11\n",
            "\n",
            "\n",
            "  Package                Version  Build                 Channel           Size\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "  Install:\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "\n",
            "  \u001b[32m+ tzdata          \u001b[0m       2025b  h78e105d_0            conda-forge\u001b[32m     Cached\u001b[0m\n",
            "  \u001b[32m+ ca-certificates \u001b[0m  2025.11.12  hbd8a1cb_0            conda-forge\u001b[32m     Cached\u001b[0m\n",
            "  \u001b[32m+ _libgcc_mutex   \u001b[0m         0.1  conda_forge           conda-forge\u001b[32m     Cached\u001b[0m\n",
            "  \u001b[32m+ libgomp         \u001b[0m      15.2.0  he0feb66_14           conda-forge\u001b[32m     Cached\u001b[0m\n",
            "  \u001b[32m+ _openmp_mutex   \u001b[0m         4.5  2_gnu                 conda-forge\u001b[32m     Cached\u001b[0m\n",
            "  \u001b[32m+ libgcc          \u001b[0m      15.2.0  he0feb66_14           conda-forge\u001b[32m     Cached\u001b[0m\n",
            "  \u001b[32m+ openssl         \u001b[0m       3.6.0  h26f9b46_0            conda-forge\u001b[32m     Cached\u001b[0m\n",
            "  \u001b[32m+ ncurses         \u001b[0m         6.5  h2d0b736_3            conda-forge\u001b[32m     Cached\u001b[0m\n",
            "  \u001b[32m+ libzlib         \u001b[0m       1.3.1  hb9d3cd8_2            conda-forge\u001b[32m     Cached\u001b[0m\n",
            "  \u001b[32m+ libgcc-ng       \u001b[0m      15.2.0  h69a702a_14           conda-forge\u001b[32m     Cached\u001b[0m\n",
            "  \u001b[32m+ libnsl          \u001b[0m       2.0.1  hb9d3cd8_1            conda-forge\u001b[32m     Cached\u001b[0m\n",
            "  \u001b[32m+ liblzma         \u001b[0m       5.8.1  hb9d3cd8_2            conda-forge\u001b[32m     Cached\u001b[0m\n",
            "  \u001b[32m+ libexpat        \u001b[0m       2.7.3  hecca717_0            conda-forge\u001b[32m     Cached\u001b[0m\n",
            "  \u001b[32m+ bzip2           \u001b[0m       1.0.8  hda65f42_8            conda-forge\u001b[32m     Cached\u001b[0m\n",
            "  \u001b[32m+ libuuid         \u001b[0m      2.41.2  he9a06e4_0            conda-forge\u001b[32m     Cached\u001b[0m\n",
            "  \u001b[32m+ libffi          \u001b[0m       3.5.2  h9ec8514_0            conda-forge\u001b[32m     Cached\u001b[0m\n",
            "  \u001b[32m+ readline        \u001b[0m         8.2  h8c095d6_2            conda-forge\u001b[32m     Cached\u001b[0m\n",
            "  \u001b[32m+ libsqlite       \u001b[0m      3.51.1  h0c1763c_0            conda-forge\u001b[32m     Cached\u001b[0m\n",
            "  \u001b[32m+ zstd            \u001b[0m       1.5.7  h3691f8a_5            conda-forge\u001b[32m     Cached\u001b[0m\n",
            "  \u001b[32m+ tk              \u001b[0m      8.6.13  noxft_ha0e22de_103    conda-forge\u001b[32m     Cached\u001b[0m\n",
            "  \u001b[32m+ libxcrypt       \u001b[0m      4.4.36  hd590300_1            conda-forge\u001b[32m     Cached\u001b[0m\n",
            "  \u001b[32m+ ld_impl_linux-64\u001b[0m        2.45  default_hbd61a6d_104  conda-forge\u001b[32m     Cached\u001b[0m\n",
            "  \u001b[32m+ python          \u001b[0m     3.11.14  hd63d673_2_cpython    conda-forge\u001b[32m     Cached\u001b[0m\n",
            "  \u001b[32m+ wheel           \u001b[0m      0.45.1  pyhd8ed1ab_1          conda-forge\u001b[32m     Cached\u001b[0m\n",
            "  \u001b[32m+ setuptools      \u001b[0m      80.9.0  pyhff2d567_0          conda-forge\u001b[32m     Cached\u001b[0m\n",
            "  \u001b[32m+ pip             \u001b[0m        25.3  pyh8b19718_0          conda-forge\u001b[32m     Cached\u001b[0m\n",
            "\n",
            "  Summary:\n",
            "\n",
            "  Install: 26 packages\n",
            "\n",
            "  Total download: 0 B\n",
            "\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "\n",
            "\n",
            "\u001b[?25l\u001b[2K\u001b[0G\u001b[?25h\n",
            "Downloading and Extracting Packages:\n",
            "\n",
            "Preparing transaction: - \b\b\\ \b\bdone\n",
            "Verifying transaction: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "Executing transaction: | \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "\n",
            "To activate this environment, use\n",
            "\n",
            "     $ mamba activate retriever\n",
            "\n",
            "To deactivate an active environment, use\n",
            "\n",
            "     $ mamba deactivate\n",
            "\n",
            "\n",
            "Looking for: ['python=3.11']\n",
            "\n",
            "conda-forge/linux-64                                        Using cache\n",
            "conda-forge/noarch                                          Using cache\n",
            "Transaction\n",
            "\n",
            "  Prefix: /usr/local/envs/train_and_test\n",
            "\n",
            "  Updating specs:\n",
            "\n",
            "   - python=3.11\n",
            "\n",
            "\n",
            "  Package                Version  Build                 Channel           Size\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "  Install:\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "\n",
            "  \u001b[32m+ tzdata          \u001b[0m       2025b  h78e105d_0            conda-forge\u001b[32m     Cached\u001b[0m\n",
            "  \u001b[32m+ ca-certificates \u001b[0m  2025.11.12  hbd8a1cb_0            conda-forge\u001b[32m     Cached\u001b[0m\n",
            "  \u001b[32m+ _libgcc_mutex   \u001b[0m         0.1  conda_forge           conda-forge\u001b[32m     Cached\u001b[0m\n",
            "  \u001b[32m+ libgomp         \u001b[0m      15.2.0  he0feb66_14           conda-forge\u001b[32m     Cached\u001b[0m\n",
            "  \u001b[32m+ _openmp_mutex   \u001b[0m         4.5  2_gnu                 conda-forge\u001b[32m     Cached\u001b[0m\n",
            "  \u001b[32m+ libgcc          \u001b[0m      15.2.0  he0feb66_14           conda-forge\u001b[32m     Cached\u001b[0m\n",
            "  \u001b[32m+ openssl         \u001b[0m       3.6.0  h26f9b46_0            conda-forge\u001b[32m     Cached\u001b[0m\n",
            "  \u001b[32m+ ncurses         \u001b[0m         6.5  h2d0b736_3            conda-forge\u001b[32m     Cached\u001b[0m\n",
            "  \u001b[32m+ libzlib         \u001b[0m       1.3.1  hb9d3cd8_2            conda-forge\u001b[32m     Cached\u001b[0m\n",
            "  \u001b[32m+ libgcc-ng       \u001b[0m      15.2.0  h69a702a_14           conda-forge\u001b[32m     Cached\u001b[0m\n",
            "  \u001b[32m+ libnsl          \u001b[0m       2.0.1  hb9d3cd8_1            conda-forge\u001b[32m     Cached\u001b[0m\n",
            "  \u001b[32m+ liblzma         \u001b[0m       5.8.1  hb9d3cd8_2            conda-forge\u001b[32m     Cached\u001b[0m\n",
            "  \u001b[32m+ libexpat        \u001b[0m       2.7.3  hecca717_0            conda-forge\u001b[32m     Cached\u001b[0m\n",
            "  \u001b[32m+ bzip2           \u001b[0m       1.0.8  hda65f42_8            conda-forge\u001b[32m     Cached\u001b[0m\n",
            "  \u001b[32m+ libuuid         \u001b[0m      2.41.2  he9a06e4_0            conda-forge\u001b[32m     Cached\u001b[0m\n",
            "  \u001b[32m+ libffi          \u001b[0m       3.5.2  h9ec8514_0            conda-forge\u001b[32m     Cached\u001b[0m\n",
            "  \u001b[32m+ readline        \u001b[0m         8.2  h8c095d6_2            conda-forge\u001b[32m     Cached\u001b[0m\n",
            "  \u001b[32m+ libsqlite       \u001b[0m      3.51.1  h0c1763c_0            conda-forge\u001b[32m     Cached\u001b[0m\n",
            "  \u001b[32m+ zstd            \u001b[0m       1.5.7  h3691f8a_5            conda-forge\u001b[32m     Cached\u001b[0m\n",
            "  \u001b[32m+ tk              \u001b[0m      8.6.13  noxft_ha0e22de_103    conda-forge\u001b[32m     Cached\u001b[0m\n",
            "  \u001b[32m+ libxcrypt       \u001b[0m      4.4.36  hd590300_1            conda-forge\u001b[32m     Cached\u001b[0m\n",
            "  \u001b[32m+ ld_impl_linux-64\u001b[0m        2.45  default_hbd61a6d_104  conda-forge\u001b[32m     Cached\u001b[0m\n",
            "  \u001b[32m+ python          \u001b[0m     3.11.14  hd63d673_2_cpython    conda-forge\u001b[32m     Cached\u001b[0m\n",
            "  \u001b[32m+ wheel           \u001b[0m      0.45.1  pyhd8ed1ab_1          conda-forge\u001b[32m     Cached\u001b[0m\n",
            "  \u001b[32m+ setuptools      \u001b[0m      80.9.0  pyhff2d567_0          conda-forge\u001b[32m     Cached\u001b[0m\n",
            "  \u001b[32m+ pip             \u001b[0m        25.3  pyh8b19718_0          conda-forge\u001b[32m     Cached\u001b[0m\n",
            "\n",
            "  Summary:\n",
            "\n",
            "  Install: 26 packages\n",
            "\n",
            "  Total download: 0 B\n",
            "\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "\n",
            "\n",
            "\u001b[?25l\u001b[2K\u001b[0G\u001b[?25h\n",
            "Downloading and Extracting Packages:\n",
            "\n",
            "Preparing transaction: - \b\b\\ \b\bdone\n",
            "Verifying transaction: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "Executing transaction: | \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "\n",
            "To activate this environment, use\n",
            "\n",
            "     $ mamba activate train_and_test\n",
            "\n",
            "To deactivate an active environment, use\n",
            "\n",
            "     $ mamba deactivate\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1cb54d08-3ea1-4fa9-b4fe-476f82409204",
      "metadata": {
        "id": "1cb54d08-3ea1-4fa9-b4fe-476f82409204",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d0d2caa-93b2-4168-b65c-d538db77e1cf",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: uvicorn in /usr/local/envs/retriever/lib/python3.11/site-packages (0.38.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/envs/retriever/lib/python3.11/site-packages (from uvicorn) (8.3.1)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/envs/retriever/lib/python3.11/site-packages (from uvicorn) (0.16.0)\n",
            "\n",
            "Collecting en_core_web_sm@ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl#sha256=1932429db727d4bff3deed6b34cfc05df17794f4a52eeb26cf8928f7c1a0fb85 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 23))\n",
            "  Using cached https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
            "Collecting accelerate==1.2.0 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 1))\n",
            "  Using cached accelerate-1.2.0-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting aiohappyeyeballs==2.4.4 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 2))\n",
            "  Using cached aiohappyeyeballs-2.4.4-py3-none-any.whl.metadata (6.1 kB)\n",
            "Collecting aiohttp==3.11.11 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 3))\n",
            "  Using cached aiohttp-3.11.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
            "Collecting aiosignal==1.3.2 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 4))\n",
            "  Using cached aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting annotated-types==0.7.0 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 5))\n",
            "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting asttokens==3.0.0 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 6))\n",
            "  Using cached asttokens-3.0.0-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting async-timeout==5.0.1 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 7))\n",
            "  Using cached async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting attrs==24.3.0 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 8))\n",
            "  Using cached attrs-24.3.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting beir==2.0.0 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 9))\n",
            "  Using cached beir-2.0.0.tar.gz (53 kB)\n",
            "  Installing build dependencies: started\n",
            "  Installing build dependencies: finished with status 'done'\n",
            "  Getting requirements to build wheel: started\n",
            "  Getting requirements to build wheel: finished with status 'done'\n",
            "  Preparing metadata (pyproject.toml): started\n",
            "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
            "Collecting bitsandbytes==0.45.0 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 10))\n",
            "  Using cached bitsandbytes-0.45.0-py3-none-manylinux_2_24_x86_64.whl.metadata (2.9 kB)\n",
            "Collecting blis==1.1.0 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 11))\n",
            "  Using cached blis-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
            "Collecting catalogue==2.0.10 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 12))\n",
            "  Using cached catalogue-2.0.10-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting certifi==2024.8.30 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 13))\n",
            "  Using cached certifi-2024.8.30-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting charset-normalizer==3.4.0 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 14))\n",
            "  Using cached charset_normalizer-3.4.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (34 kB)\n",
            "Collecting click==8.1.8 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 15))\n",
            "  Using cached click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting cloudpathlib==0.20.0 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 16))\n",
            "  Using cached cloudpathlib-0.20.0-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting confection==0.1.5 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 17))\n",
            "  Using cached confection-0.1.5-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting cymem==2.0.10 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 18))\n",
            "  Using cached cymem-2.0.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.4 kB)\n",
            "Collecting datasets==3.2.0 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 19))\n",
            "  Using cached datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting decorator==5.1.1 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 20))\n",
            "  Using cached decorator-5.1.1-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting dill==0.3.8 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 21))\n",
            "  Using cached dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting elasticsearch==7.9.1 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 22))\n",
            "  Using cached elasticsearch-7.9.1-py2.py3-none-any.whl.metadata (8.0 kB)\n",
            "Collecting exceptiongroup==1.2.2 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 24))\n",
            "  Using cached exceptiongroup-1.2.2-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting executing==2.1.0 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 25))\n",
            "  Using cached executing-2.1.0-py2.py3-none-any.whl.metadata (8.9 kB)\n",
            "Collecting filelock==3.16.1 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 26))\n",
            "  Using cached filelock-3.16.1-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting frozenlist==1.5.0 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 27))\n",
            "  Using cached frozenlist-1.5.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Collecting fsspec==2024.9.0 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 28))\n",
            "  Using cached fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting h5py==3.13.0 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 29))\n",
            "  Using cached h5py-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
            "Collecting huggingface-hub==0.26.5 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 30))\n",
            "  Using cached huggingface_hub-0.26.5-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting idna==3.10 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 31))\n",
            "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting ipython==8.18.1 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 32))\n",
            "  Using cached ipython-8.18.1-py3-none-any.whl.metadata (6.0 kB)\n",
            "Collecting jedi==0.19.2 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 33))\n",
            "  Using cached jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting Jinja2==3.1.4 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 34))\n",
            "  Using cached jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting joblib==1.4.2 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 35))\n",
            "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting langcodes==3.5.0 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 36))\n",
            "  Using cached langcodes-3.5.0-py3-none-any.whl.metadata (29 kB)\n",
            "Collecting language_data==1.3.0 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 37))\n",
            "  Using cached language_data-1.3.0-py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting llama-index (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Using cached llama_index-0.14.8-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting llvmlite==0.41.1 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 39))\n",
            "  Using cached llvmlite-0.41.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\n",
            "Collecting marisa-trie==1.2.1 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 40))\n",
            "  Using cached marisa_trie-1.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.0 kB)\n",
            "Collecting markdown-it-py==3.0.0 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 41))\n",
            "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting MarkupSafe==3.0.2 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 42))\n",
            "  Using cached MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
            "Collecting matplotlib-inline==0.1.7 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 43))\n",
            "  Using cached matplotlib_inline-0.1.7-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting mdurl==0.1.2 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 44))\n",
            "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting mkl-service==2.4.2 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 45))\n",
            "  Using cached mkl_service-2.4.2-0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (2.6 kB)\n",
            "Collecting mpmath==1.3.0 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 46))\n",
            "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting multidict==6.1.0 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 47))\n",
            "  Using cached multidict-6.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)\n",
            "Collecting multiprocess==0.70.16 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 48))\n",
            "  Using cached multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting murmurhash==1.0.11 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 49))\n",
            "  Using cached murmurhash-1.0.11-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.0 kB)\n",
            "Collecting networkx==3.2.1 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 50))\n",
            "  Using cached networkx-3.2.1-py3-none-any.whl.metadata (5.2 kB)\n",
            "Collecting numba==0.58.1 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 51))\n",
            "  Using cached numba-0.58.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.7 kB)\n",
            "Collecting numpy==1.26.4 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 52))\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 53))\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 54))\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 55))\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 56))\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 57))\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 58))\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 59))\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 60))\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 61))\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.21.5 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 62))\n",
            "  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 63))\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.4.127 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 64))\n",
            "  Downloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting packaging==24.1 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 65))\n",
            "  Downloading packaging-24.1-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting pandas==2.2.3 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 66))\n",
            "  Downloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
            "Collecting parso==0.8.4 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 67))\n",
            "  Downloading parso-0.8.4-py2.py3-none-any.whl.metadata (7.7 kB)\n",
            "Collecting peft==0.14.0 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 68))\n",
            "  Downloading peft-0.14.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting pexpect==4.9.0 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 69))\n",
            "  Downloading pexpect-4.9.0-py2.py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting pillow==11.1.0 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 70))\n",
            "  Downloading pillow-11.1.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.1 kB)\n",
            "Collecting preshed==3.0.9 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 71))\n",
            "  Downloading preshed-3.0.9-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.2 kB)\n",
            "Collecting prompt_toolkit==3.0.48 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 72))\n",
            "  Downloading prompt_toolkit-3.0.48-py3-none-any.whl.metadata (6.4 kB)\n",
            "Collecting propcache==0.2.1 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 73))\n",
            "  Downloading propcache-0.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.2 kB)\n",
            "Collecting psutil==6.1.0 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 74))\n",
            "  Downloading psutil-6.1.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\n",
            "Collecting ptyprocess==0.7.0 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 75))\n",
            "  Downloading ptyprocess-0.7.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting pure_eval==0.2.3 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 76))\n",
            "  Downloading pure_eval-0.2.3-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting pyarrow==18.1.0 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 77))\n",
            "  Downloading pyarrow-18.1.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
            "Collecting pydantic==2.10.4 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 78))\n",
            "  Downloading pydantic-2.10.4-py3-none-any.whl.metadata (29 kB)\n",
            "Collecting pydantic_core==2.27.2 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 79))\n",
            "  Downloading pydantic_core-2.27.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting Pygments==2.18.0 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 80))\n",
            "  Downloading pygments-2.18.0-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting python-dateutil==2.9.0.post0 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 81))\n",
            "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting pytrec-eval==0.5 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 82))\n",
            "  Downloading pytrec_eval-0.5.tar.gz (15 kB)\n",
            "  Installing build dependencies: started\n",
            "  Installing build dependencies: finished with status 'done'\n",
            "  Getting requirements to build wheel: started\n",
            "  Getting requirements to build wheel: finished with status 'done'\n",
            "  Preparing metadata (pyproject.toml): started\n",
            "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
            "Collecting pytz==2024.2 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 83))\n",
            "  Downloading pytz-2024.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting PyYAML==6.0.2 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 84))\n",
            "  Downloading PyYAML-6.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting regex==2024.11.6 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 85))\n",
            "  Downloading regex-2024.11.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
            "Collecting requests==2.32.3 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 86))\n",
            "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting rich==13.9.4 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 87))\n",
            "  Downloading rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting safetensors==0.4.5 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 88))\n",
            "  Downloading safetensors-0.4.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Collecting scikit-learn==1.6.0 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 89))\n",
            "  Downloading scikit_learn-1.6.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Collecting scipy==1.13.1 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 90))\n",
            "  Downloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "Collecting sentence-transformers==3.3.1 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 91))\n",
            "  Downloading sentence_transformers-3.3.1-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting shellingham==1.5.4 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 92))\n",
            "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting six==1.17.0 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 93))\n",
            "  Downloading six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting smart-open==7.1.0 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 94))\n",
            "  Downloading smart_open-7.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting spacy==3.8.3 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 95))\n",
            "  Downloading spacy-3.8.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (27 kB)\n",
            "Collecting spacy-legacy==3.0.12 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 96))\n",
            "  Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting spacy-loggers==1.0.5 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 97))\n",
            "  Downloading spacy_loggers-1.0.5-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting srsly==2.5.0 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 98))\n",
            "  Downloading srsly-2.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
            "Collecting stack-data==0.6.3 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 99))\n",
            "  Downloading stack_data-0.6.3-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting sympy==1.13.1 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 100))\n",
            "  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting thinc==8.3.3 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 101))\n",
            "  Downloading thinc-8.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (15 kB)\n",
            "Collecting threadpoolctl==3.5.0 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 102))\n",
            "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting tokenizers==0.19.1 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 103))\n",
            "  Downloading tokenizers-0.19.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Collecting torch==2.5.1 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 104))\n",
            "  Downloading torch-2.5.1-cp311-cp311-manylinux1_x86_64.whl.metadata (28 kB)\n",
            "Collecting tqdm==4.67.1 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 105))\n",
            "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
            "Collecting traitlets==5.14.3 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 106))\n",
            "  Downloading traitlets-5.14.3-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting transformers==4.43.1 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 107))\n",
            "  Downloading transformers-4.43.1-py3-none-any.whl.metadata (43 kB)\n",
            "Collecting triton==3.1.0 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 108))\n",
            "  Downloading triton-3.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
            "Collecting typer==0.15.1 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 109))\n",
            "  Downloading typer-0.15.1-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting typing_extensions==4.12.2 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 110))\n",
            "  Downloading typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting tzdata==2024.2 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 111))\n",
            "  Downloading tzdata-2024.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting ujson==5.10.0 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 112))\n",
            "  Downloading ujson-5.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.3 kB)\n",
            "Collecting urllib3==2.2.3 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 113))\n",
            "  Downloading urllib3-2.2.3-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting wasabi==1.1.3 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 114))\n",
            "  Downloading wasabi-1.1.3-py3-none-any.whl.metadata (28 kB)\n",
            "Collecting wcwidth==0.2.13 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 115))\n",
            "  Downloading wcwidth-0.2.13-py2.py3-none-any.whl.metadata (14 kB)\n",
            "Collecting weasel==0.4.1 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 116))\n",
            "  Downloading weasel-0.4.1-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting wrapt==1.17.0 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 117))\n",
            "  Downloading wrapt-1.17.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
            "Collecting xxhash==3.5.0 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 118))\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting yarl==1.18.3 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 119))\n",
            "  Downloading yarl-1.18.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (69 kB)\n",
            "Collecting faiss_cpu (from beir==2.0.0->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 9))\n",
            "  Downloading faiss_cpu-1.13.0-cp39-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (7.7 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/envs/retriever/lib/python3.11/site-packages (from marisa-trie==1.2.1->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 40)) (80.9.0)\n",
            "Collecting mkl (from mkl-service==2.4.2->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 45))\n",
            "  Downloading mkl-2025.3.0-py2.py3-none-manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting llama-index-cli<0.6,>=0.5.0 (from llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_index_cli-0.5.3-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting llama-index-core<0.15.0,>=0.14.8 (from llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_index_core-0.14.8-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting llama-index-embeddings-openai<0.6,>=0.5.0 (from llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_index_embeddings_openai-0.5.1-py3-none-any.whl.metadata (400 bytes)\n",
            "Collecting llama-index-indices-managed-llama-cloud>=0.4.0 (from llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_index_indices_managed_llama_cloud-0.9.4-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting llama-index-llms-openai<0.7,>=0.6.0 (from llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_index_llms_openai-0.6.10-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting llama-index-readers-file<0.6,>=0.5.0 (from llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_index_readers_file-0.5.5-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting llama-index-readers-llama-parse>=0.4.0 (from llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_index_readers_llama_parse-0.5.1-py3-none-any.whl.metadata (3.1 kB)\n",
            "Collecting nltk>3.8.1 (from llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading nltk-3.9.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting aiosqlite (from llama-index-core<0.15.0,>=0.14.8->llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading aiosqlite-0.21.0-py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting banks<3,>=2.2.0 (from llama-index-core<0.15.0,>=0.14.8->llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading banks-2.2.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting dataclasses-json (from llama-index-core<0.15.0,>=0.14.8->llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting deprecated>=1.2.9.3 (from llama-index-core<0.15.0,>=0.14.8->llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading deprecated-1.3.1-py2.py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting dirtyjson<2,>=1.0.8 (from llama-index-core<0.15.0,>=0.14.8->llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting filetype<2,>=1.2.0 (from llama-index-core<0.15.0,>=0.14.8->llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting httpx (from llama-index-core<0.15.0,>=0.14.8->llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting llama-index-workflows!=2.9.0,<3,>=2 (from llama-index-core<0.15.0,>=0.14.8->llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_index_workflows-2.11.5-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting nest-asyncio<2,>=1.5.8 (from llama-index-core<0.15.0,>=0.14.8->llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading nest_asyncio-1.6.0-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting platformdirs (from llama-index-core<0.15.0,>=0.14.8->llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading platformdirs-4.5.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting sqlalchemy>=1.4.49 (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.15.0,>=0.14.8->llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading sqlalchemy-2.0.44-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.5 kB)\n",
            "Collecting tenacity!=8.4.0,<10.0.0,>=8.2.0 (from llama-index-core<0.15.0,>=0.14.8->llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting tiktoken>=0.7.0 (from llama-index-core<0.15.0,>=0.14.8->llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading tiktoken-0.12.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.7 kB)\n",
            "Collecting typing-inspect>=0.8.0 (from llama-index-core<0.15.0,>=0.14.8->llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting griffe (from banks<3,>=2.2.0->llama-index-core<0.15.0,>=0.14.8->llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading griffe-1.15.0-py3-none-any.whl.metadata (5.2 kB)\n",
            "Collecting openai>=1.1.0 (from llama-index-embeddings-openai<0.6,>=0.5.0->llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading openai-2.8.1-py3-none-any.whl.metadata (29 kB)\n",
            "Collecting beautifulsoup4<5,>=4.12.3 (from llama-index-readers-file<0.6,>=0.5.0->llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading beautifulsoup4-4.14.3-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting defusedxml>=0.7.1 (from llama-index-readers-file<0.6,>=0.5.0->llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading defusedxml-0.7.1-py2.py3-none-any.whl.metadata (32 kB)\n",
            "Collecting pypdf<7,>=6.1.3 (from llama-index-readers-file<0.6,>=0.5.0->llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading pypdf-6.4.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file<0.6,>=0.5.0->llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading striprtf-0.0.26-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting soupsieve>=1.6.1 (from beautifulsoup4<5,>=4.12.3->llama-index-readers-file<0.6,>=0.5.0->llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading soupsieve-2.8-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting llama-index-instrumentation>=0.1.0 (from llama-index-workflows!=2.9.0,<3,>=2->llama-index-core<0.15.0,>=0.14.8->llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_index_instrumentation-0.4.2-py3-none-any.whl.metadata (1.1 kB)\n",
            "INFO: pip is looking at multiple versions of llama-index-workflows to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting llama-index-workflows!=2.9.0,<3,>=2 (from llama-index-core<0.15.0,>=0.14.8->llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_index_workflows-2.11.4-py3-none-any.whl.metadata (4.7 kB)\n",
            "  Downloading llama_index_workflows-2.11.3-py3-none-any.whl.metadata (770 bytes)\n",
            "  Downloading llama_index_workflows-2.11.2-py3-none-any.whl.metadata (766 bytes)\n",
            "  Downloading llama_index_workflows-2.11.1-py3-none-any.whl.metadata (6.5 kB)\n",
            "  Downloading llama_index_workflows-2.11.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "  Downloading llama_index_workflows-2.10.3-py3-none-any.whl.metadata (6.5 kB)\n",
            "  Downloading llama_index_workflows-2.10.2-py3-none-any.whl.metadata (6.5 kB)\n",
            "INFO: pip is still looking at multiple versions of llama-index-workflows to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading llama_index_workflows-2.10.1-py3-none-any.whl.metadata (6.5 kB)\n",
            "  Downloading llama_index_workflows-2.10.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "  Downloading llama_index_workflows-2.9.1-py3-none-any.whl.metadata (6.5 kB)\n",
            "  Downloading llama_index_workflows-2.8.3-py3-none-any.whl.metadata (6.5 kB)\n",
            "  Downloading llama_index_workflows-2.8.2-py3-none-any.whl.metadata (6.5 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Downloading llama_index_workflows-2.8.1-py3-none-any.whl.metadata (6.5 kB)\n",
            "  Downloading llama_index_workflows-2.8.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "  Downloading llama_index_workflows-2.7.1-py3-none-any.whl.metadata (6.4 kB)\n",
            "  Downloading llama_index_workflows-2.7.0-py3-none-any.whl.metadata (6.4 kB)\n",
            "  Downloading llama_index_workflows-2.6.0-py3-none-any.whl.metadata (6.4 kB)\n",
            "  Downloading llama_index_workflows-2.5.0-py3-none-any.whl.metadata (6.4 kB)\n",
            "  Downloading llama_index_workflows-2.4.0-py3-none-any.whl.metadata (6.4 kB)\n",
            "  Downloading llama_index_workflows-2.3.0-py3-none-any.whl.metadata (6.4 kB)\n",
            "  Downloading llama_index_workflows-2.2.2-py3-none-any.whl.metadata (6.4 kB)\n",
            "  Downloading llama_index_workflows-2.2.1-py3-none-any.whl.metadata (6.4 kB)\n",
            "  Downloading llama_index_workflows-2.2.0-py3-none-any.whl.metadata (6.4 kB)\n",
            "  Downloading llama_index_workflows-2.1.0-py3-none-any.whl.metadata (6.4 kB)\n",
            "  Downloading llama_index_workflows-2.0.1-py3-none-any.whl.metadata (6.4 kB)\n",
            "  Downloading llama_index_workflows-2.0.0-py3-none-any.whl.metadata (6.4 kB)\n",
            "Collecting llama-index-readers-file<0.6,>=0.5.0 (from llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_index_readers_file-0.5.4-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting llama-index-llms-openai<0.7,>=0.6.0 (from llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_index_llms_openai-0.6.9-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting llama-index-embeddings-openai<0.6,>=0.5.0 (from llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_index_embeddings_openai-0.5.0-py3-none-any.whl.metadata (400 bytes)\n",
            "Collecting llama-index-cli<0.6,>=0.5.0 (from llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_index_cli-0.5.2-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting llama-index (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_index-0.14.7-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting llama-index-core<0.15.0,>=0.14.7 (from llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_index_core-0.14.7-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting llama-index (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_index-0.14.6-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting llama-index-core<0.15.0,>=0.14.6 (from llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_index_core-0.14.6-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting llama-index-workflows<3,>=2 (from llama-index-core<0.15.0,>=0.14.6->llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_index_workflows-2.9.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting llama-index (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_index-0.14.5-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting llama-index-core<0.15.0,>=0.14.5 (from llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_index_core-0.14.5-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting llama-index (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_index-0.14.4-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting llama-index-core<0.15.0,>=0.14.4 (from llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_index_core-0.14.4-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting llama-index (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_index-0.14.3-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting llama-index-llms-openai<0.6,>=0.5.0 (from llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_index_llms_openai-0.5.6-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting llama-index-core<0.15,>=0.14.3 (from llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_index_core-0.14.3-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting llama-index (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_index-0.14.2-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting llama-index-core<0.15,>=0.14.2 (from llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_index_core-0.14.2-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting llama-index (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_index-0.14.1-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting llama-index-core<0.15,>=0.14.1 (from llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_index_core-0.14.1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting llama-index (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_index-0.14.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting llama-index-core<0.15,>=0.13.6 (from llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_index_core-0.14.0-py3-none-any.whl.metadata (2.5 kB)\n",
            "  Downloading llama_index_core-0.13.6-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting llama-index-workflows<2,>=1.0.1 (from llama-index-core<0.15,>=0.13.6->llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_index_workflows-1.3.0-py3-none-any.whl.metadata (6.4 kB)\n",
            "  Downloading llama_index_workflows-1.2.0-py3-none-any.whl.metadata (6.2 kB)\n",
            "  Downloading llama_index_workflows-1.1.0-py3-none-any.whl.metadata (6.1 kB)\n",
            "  Downloading llama_index_workflows-1.0.1-py3-none-any.whl.metadata (5.5 kB)\n",
            "Collecting llama-index (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_index-0.13.6-py3-none-any.whl.metadata (12 kB)\n",
            "  Downloading llama_index-0.13.5-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting llama-index-core<0.14,>=0.13.5 (from llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_index_core-0.13.5-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting llama-index (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_index-0.13.4-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting llama-index-core<0.14,>=0.13.4 (from llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_index_core-0.13.4-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting llama-index (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_index-0.13.3-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting llama-index-core<0.14,>=0.13.3 (from llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_index_core-0.13.3-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting llama-index (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_index-0.13.2-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting llama-index-core<0.14,>=0.13.2 (from llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_index_core-0.13.2-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting llama-index (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_index-0.13.1-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting llama-index-core<0.14,>=0.13.1 (from llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_index_core-0.13.1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting llama-index (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_index-0.13.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting llama-index-core<0.14,>=0.13.0 (from llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_index_core-0.13.0-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting llama-index (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_index-0.12.52-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting llama-index-agent-openai<0.5,>=0.4.0 (from llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_index_agent_openai-0.4.12-py3-none-any.whl.metadata (439 bytes)\n",
            "Collecting llama-index-cli<0.5,>=0.4.2 (from llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_index_cli-0.4.4-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting llama-index-core<0.13,>=0.12.52.post1 (from llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_index_core-0.12.52.post1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting llama-index-embeddings-openai<0.4,>=0.3.0 (from llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_index_embeddings_openai-0.3.1-py3-none-any.whl.metadata (684 bytes)\n",
            "Collecting llama-index-llms-openai<0.5,>=0.4.0 (from llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_index_llms_openai-0.4.7-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting llama-index-multi-modal-llms-openai<0.6,>=0.5.0 (from llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_index_multi_modal_llms_openai-0.5.3-py3-none-any.whl.metadata (441 bytes)\n",
            "Collecting llama-index-program-openai<0.4,>=0.3.0 (from llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_index_program_openai-0.3.2-py3-none-any.whl.metadata (473 bytes)\n",
            "Collecting llama-index-question-gen-openai<0.4,>=0.3.0 (from llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_index_question_gen_openai-0.3.1-py3-none-any.whl.metadata (492 bytes)\n",
            "Collecting llama-index-readers-file<0.5,>=0.4.0 (from llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_index_readers_file-0.4.11-py3-none-any.whl.metadata (5.3 kB)\n",
            "Collecting llama-index (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_index-0.12.51-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting llama-index-core<0.13,>=0.12.51 (from llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_index_core-0.12.52-py3-none-any.whl.metadata (2.5 kB)\n",
            "  Downloading llama_index_core-0.12.51-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting banks<3,>=2.0.0 (from llama-index-core<0.13,>=0.12.51->llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading banks-2.1.3-py3-none-any.whl.metadata (12 kB)\n",
            "  Downloading banks-2.1.2-py3-none-any.whl.metadata (12 kB)\n",
            "  Downloading banks-2.1.1-py3-none-any.whl.metadata (11 kB)\n",
            "  Downloading banks-2.1.0-py3-none-any.whl.metadata (11 kB)\n",
            "  Downloading banks-2.0.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting llama-index (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_index-0.12.50-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting llama-index-core<0.13,>=0.12.50 (from llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_index_core-0.12.50-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting llama-index (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_index-0.12.49-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting llama-index-core<0.13,>=0.12.49 (from llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_index_core-0.12.49-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting llama-index (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_index-0.12.48-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting llama-index-core<0.13,>=0.12.48 (from llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_index_core-0.12.48-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting llama-index (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_index-0.12.47-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting llama-index-core<0.13,>=0.12.47 (from llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_index_core-0.12.47-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting llama-index (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_index-0.12.46-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting llama-index-core<0.13,>=0.12.46 (from llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_index_core-0.12.46-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting llama-index (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_index-0.12.45-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting llama-index-core<0.13,>=0.12.45 (from llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_index_core-0.12.45-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting llama-index (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_index-0.12.44-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting llama-index-core<0.13,>=0.12.44 (from llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_index_core-0.12.44-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting llama-index (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_index-0.12.43-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting llama-index-core<0.13,>=0.12.43 (from llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_index_core-0.12.43-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting llama-index-workflows>=0.2.1 (from llama-index-core<0.13,>=0.12.43->llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_index_workflows-1.0.0-py3-none-any.whl.metadata (5.5 kB)\n",
            "  Downloading llama_index_workflows-0.2.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "  Downloading llama_index_workflows-0.2.1-py3-none-any.whl.metadata (276 bytes)\n",
            "Collecting llama-index (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_index-0.12.42-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting llama-index-core<0.13,>=0.12.42 (from llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_index_core-0.12.42-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting openai>=1.14.0 (from llama-index-agent-openai<0.5,>=0.4.0->llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading openai-1.109.1-py3-none-any.whl.metadata (29 kB)\n",
            "INFO: pip is looking at multiple versions of llama-index-multi-modal-llms-openai to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting llama-index-multi-modal-llms-openai<0.6,>=0.5.0 (from llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_index_multi_modal_llms_openai-0.5.1-py3-none-any.whl.metadata (440 bytes)\n",
            "Collecting pypdf<6,>=5.1.0 (from llama-index-readers-file<0.5,>=0.4.0->llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading pypdf-5.9.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting anyio<5,>=3.5.0 (from openai>=1.14.0->llama-index-agent-openai<0.5,>=0.4.0->llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading anyio-4.12.0-py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting distro<2,>=1.7.0 (from openai>=1.14.0->llama-index-agent-openai<0.5,>=0.4.0->llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting jiter<1,>=0.4.0 (from openai>=1.14.0->llama-index-agent-openai<0.5,>=0.4.0->llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading jiter-0.12.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
            "Collecting sniffio (from openai>=1.14.0->llama-index-agent-openai<0.5,>=0.4.0->llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting httpcore==1.* (from httpx->llama-index-core<0.15.0,>=0.14.8->llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/envs/retriever/lib/python3.11/site-packages (from httpcore==1.*->httpx->llama-index-core<0.15.0,>=0.14.8->llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38)) (0.16.0)\n",
            "Collecting deprecated>=1.2.9.3 (from llama-index-core<0.13,>=0.12.42->llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading Deprecated-1.2.18-py2.py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting llama-cloud==0.1.35 (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_cloud-0.1.35-py3-none-any.whl.metadata (1.2 kB)\n",
            "INFO: pip is looking at multiple versions of llama-index-indices-managed-llama-cloud to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting llama-index-indices-managed-llama-cloud>=0.4.0 (from llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_index_indices_managed_llama_cloud-0.9.3-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading llama_index_indices_managed_llama_cloud-0.9.2-py3-none-any.whl.metadata (3.5 kB)\n",
            "  Downloading llama_index_indices_managed_llama_cloud-0.9.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "  Downloading llama_index_indices_managed_llama_cloud-0.9.0-py3-none-any.whl.metadata (3.5 kB)\n",
            "  Downloading llama_index_indices_managed_llama_cloud-0.8.0-py3-none-any.whl.metadata (3.5 kB)\n",
            "INFO: pip is looking at multiple versions of llama-index-readers-llama-parse to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting llama-index-readers-llama-parse>=0.4.0 (from llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_index_readers_llama_parse-0.5.0-py3-none-any.whl.metadata (3.1 kB)\n",
            "  Downloading llama_index_readers_llama_parse-0.4.0-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_parse-0.6.85-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.85 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_cloud_services-0.6.85-py3-none-any.whl.metadata (3.3 kB)\n",
            "INFO: pip is looking at multiple versions of llama-cloud-services to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_parse-0.6.84-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.84 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_cloud_services-0.6.84-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_parse-0.6.83-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.82 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_cloud_services-0.6.83-py3-none-any.whl.metadata (3.3 kB)\n",
            "  Downloading llama_cloud_services-0.6.82-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_parse-0.6.82-py3-none-any.whl.metadata (6.6 kB)\n",
            "INFO: pip is still looking at multiple versions of llama-cloud-services to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading llama_parse-0.6.81-py3-none-any.whl.metadata (6.6 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "Collecting llama-cloud-services>=0.6.81 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_cloud_services-0.6.81-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_parse-0.6.80-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.80 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_cloud_services-0.6.80-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_parse-0.6.79-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.79 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_cloud_services-0.6.79-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_parse-0.6.78-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.78 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_cloud_services-0.6.78-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_parse-0.6.77-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.77 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_cloud_services-0.6.77-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_parse-0.6.76-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.76 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_cloud_services-0.6.76-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_parse-0.6.75-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.75 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_cloud_services-0.6.75-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_parse-0.6.74-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.74 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_cloud_services-0.6.74-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_parse-0.6.73-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.73 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_cloud_services-0.6.73-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_parse-0.6.72-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.72 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_cloud_services-0.6.72-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_parse-0.6.71-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.71 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_cloud_services-0.6.71-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_parse-0.6.70-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.70 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_cloud_services-0.6.70-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_parse-0.6.69-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.69 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_cloud_services-0.6.69-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_parse-0.6.68-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.68 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_cloud_services-0.6.68-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_parse-0.6.67-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.67 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_cloud_services-0.6.67-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_parse-0.6.66-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.66 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_cloud_services-0.6.66-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_parse-0.6.65-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.64 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_cloud_services-0.6.65-py3-none-any.whl.metadata (3.3 kB)\n",
            "  Downloading llama_cloud_services-0.6.64-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_parse-0.6.64-py3-none-any.whl.metadata (6.6 kB)\n",
            "  Downloading llama_parse-0.6.63-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.63 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_cloud_services-0.6.63-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_parse-0.6.62-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.62 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_cloud_services-0.6.62-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_parse-0.6.60-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.60 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_cloud_services-0.6.60-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_parse-0.6.59-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.59 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_cloud_services-0.6.59-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_parse-0.6.58-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.58 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_cloud_services-0.6.58-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_parse-0.6.57-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.56 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_cloud_services-0.6.57-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading llama_cloud_services-0.6.56-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_parse-0.6.56-py3-none-any.whl.metadata (6.6 kB)\n",
            "  Downloading llama_parse-0.6.55-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.55 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_cloud_services-0.6.55-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_parse-0.6.54-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.54 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading llama_cloud_services-0.6.54-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting python-dotenv<2,>=1.0.1 (from llama-cloud-services>=0.6.54->llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading python_dotenv-1.2.1-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting greenlet>=1 (from sqlalchemy>=1.4.49->sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.15.0,>=0.14.8->llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading greenlet-3.2.4-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (4.1 kB)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama-index-core<0.15.0,>=0.14.8->llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->llama-index-core<0.15.0,>=0.14.8->llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting colorama>=0.4 (from griffe->banks<3,>=2.2.0->llama-index-core<0.15.0,>=0.14.8->llama-index->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 38))\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Collecting onemkl-license==2025.3.0 (from mkl->mkl-service==2.4.2->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 45))\n",
            "  Downloading onemkl_license-2025.3.0-py2.py3-none-manylinux_2_28_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting intel-openmp<2026,>=2024 (from mkl->mkl-service==2.4.2->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 45))\n",
            "  Downloading intel_openmp-2025.3.1-py2.py3-none-manylinux_2_28_x86_64.whl.metadata (1.2 kB)\n",
            "Collecting tbb==2022.* (from mkl->mkl-service==2.4.2->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 45))\n",
            "  Downloading tbb-2022.3.0-py2.py3-none-manylinux_2_28_x86_64.whl.metadata (1.0 kB)\n",
            "Collecting intel-cmplr-lib-ur==2025.3.1 (from intel-openmp<2026,>=2024->mkl->mkl-service==2.4.2->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 45))\n",
            "  Downloading intel_cmplr_lib_ur-2025.3.1-py2.py3-none-manylinux_2_28_x86_64.whl.metadata (1.2 kB)\n",
            "Collecting umf==1.0.* (from intel-cmplr-lib-ur==2025.3.1->intel-openmp<2026,>=2024->mkl->mkl-service==2.4.2->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 45))\n",
            "  Downloading umf-1.0.2-py2.py3-none-manylinux_2_28_x86_64.whl.metadata (1.0 kB)\n",
            "Collecting tcmlib==1.* (from tbb==2022.*->mkl->mkl-service==2.4.2->-r /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt (line 45))\n",
            "  Downloading tcmlib-1.4.1-py2.py3-none-manylinux_2_28_x86_64.whl.metadata (962 bytes)\n",
            "Downloading accelerate-1.2.0-py3-none-any.whl (336 kB)\n",
            "Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 18.3/18.3 MB 183.1 MB/s  0:00:00\n",
            "Downloading aiohappyeyeballs-2.4.4-py3-none-any.whl (14 kB)\n",
            "Downloading aiohttp-3.11.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1.7/1.7 MB 80.0 MB/s  0:00:00\n",
            "Downloading multidict-6.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "Downloading yarl-1.18.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (344 kB)\n",
            "Downloading aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
            "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
            "Downloading asttokens-3.0.0-py3-none-any.whl (26 kB)\n",
            "Downloading async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
            "Downloading attrs-24.3.0-py3-none-any.whl (63 kB)\n",
            "Downloading bitsandbytes-0.45.0-py3-none-manylinux_2_24_x86_64.whl (69.1 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 69.1/69.1 MB 56.3 MB/s  0:00:01\n",
            "Downloading blis-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.3 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 9.3/9.3 MB 11.1 MB/s  0:00:00\n",
            "Downloading catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
            "Downloading certifi-2024.8.30-py3-none-any.whl (167 kB)\n",
            "Downloading charset_normalizer-3.4.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n",
            "Downloading click-8.1.8-py3-none-any.whl (98 kB)\n",
            "Downloading cloudpathlib-0.20.0-py3-none-any.whl (52 kB)\n",
            "Downloading confection-0.1.5-py3-none-any.whl (35 kB)\n",
            "Downloading pydantic-2.10.4-py3-none-any.whl (431 kB)\n",
            "Downloading srsly-2.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1.1/1.1 MB 61.6 MB/s  0:00:00\n",
            "Downloading cymem-2.0.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (218 kB)\n",
            "Downloading datasets-3.2.0-py3-none-any.whl (480 kB)\n",
            "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "Downloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "Downloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "Downloading decorator-5.1.1-py3-none-any.whl (9.1 kB)\n",
            "Downloading elasticsearch-7.9.1-py2.py3-none-any.whl (219 kB)\n",
            "Downloading exceptiongroup-1.2.2-py3-none-any.whl (16 kB)\n",
            "Downloading executing-2.1.0-py2.py3-none-any.whl (25 kB)\n",
            "Downloading filelock-3.16.1-py3-none-any.whl (16 kB)\n",
            "Downloading frozenlist-1.5.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (274 kB)\n",
            "Downloading h5py-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 4.5/4.5 MB 138.2 MB/s  0:00:00\n",
            "Downloading huggingface_hub-0.26.5-py3-none-any.whl (447 kB)\n",
            "Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
            "Downloading ipython-8.18.1-py3-none-any.whl (808 kB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 808.2/808.2 kB 48.4 MB/s  0:00:00\n",
            "Downloading prompt_toolkit-3.0.48-py3-none-any.whl (386 kB)\n",
            "Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1.6/1.6 MB 93.3 MB/s  0:00:00\n",
            "Downloading parso-0.8.4-py2.py3-none-any.whl (103 kB)\n",
            "Downloading jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
            "Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
            "Downloading langcodes-3.5.0-py3-none-any.whl (182 kB)\n",
            "Downloading language_data-1.3.0-py3-none-any.whl (5.4 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 5.4/5.4 MB 170.1 MB/s  0:00:00\n",
            "Downloading llvmlite-0.41.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.6 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 43.6/43.6 MB 84.6 MB/s  0:00:00\n",
            "Downloading marisa_trie-1.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1.4/1.4 MB 74.3 MB/s  0:00:00\n",
            "Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
            "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
            "Downloading MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23 kB)\n",
            "Downloading matplotlib_inline-0.1.7-py3-none-any.whl (9.9 kB)\n",
            "Downloading mkl_service-2.4.2-0-cp311-cp311-manylinux_2_28_x86_64.whl (77 kB)\n",
            "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 536.2/536.2 kB 28.2 MB/s  0:00:00\n",
            "Downloading murmurhash-1.0.11-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (134 kB)\n",
            "Downloading networkx-3.2.1-py3-none-any.whl (1.6 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1.6/1.6 MB 83.0 MB/s  0:00:00\n",
            "Downloading numba-0.58.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.6 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 3.6/3.6 MB 117.2 MB/s  0:00:00\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 363.4/363.4 MB 25.2 MB/s  0:00:10\n",
            "Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 13.8/13.8 MB 191.9 MB/s  0:00:00\n",
            "Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 24.6/24.6 MB 217.1 MB/s  0:00:00\n",
            "Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 883.7/883.7 kB 50.6 MB/s  0:00:00\n",
            "Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 664.8/664.8 MB 30.9 MB/s  0:00:11\n",
            "Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 211.5/211.5 MB 76.2 MB/s  0:00:02\n",
            "Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 56.3/56.3 MB 72.5 MB/s  0:00:00\n",
            "Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 127.9/127.9 MB 73.9 MB/s  0:00:01\n",
            "Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 207.5/207.5 MB 76.5 MB/s  0:00:02\n",
            "Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 188.7/188.7 MB 73.4 MB/s  0:00:02\n",
            "Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 21.1/21.1 MB 186.1 MB/s  0:00:00\n",
            "Downloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
            "Downloading packaging-24.1-py3-none-any.whl (53 kB)\n",
            "Downloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 13.1/13.1 MB 152.7 MB/s  0:00:00\n",
            "Downloading peft-0.14.0-py3-none-any.whl (374 kB)\n",
            "Downloading pexpect-4.9.0-py2.py3-none-any.whl (63 kB)\n",
            "Downloading pillow-11.1.0-cp311-cp311-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 4.5/4.5 MB 130.6 MB/s  0:00:00\n",
            "Downloading preshed-3.0.9-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (157 kB)\n",
            "Downloading propcache-0.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (231 kB)\n",
            "Downloading psutil-6.1.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (287 kB)\n",
            "Downloading ptyprocess-0.7.0-py2.py3-none-any.whl (13 kB)\n",
            "Downloading pure_eval-0.2.3-py3-none-any.whl (11 kB)\n",
            "Downloading pyarrow-18.1.0-cp311-cp311-manylinux_2_28_x86_64.whl (40.1 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 40.1/40.1 MB 58.0 MB/s  0:00:00\n",
            "Downloading pydantic_core-2.27.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2.0/2.0 MB 88.8 MB/s  0:00:00\n",
            "Downloading pygments-2.18.0-py3-none-any.whl (1.2 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1.2/1.2 MB 69.7 MB/s  0:00:00\n",
            "Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
            "Downloading pytz-2024.2-py2.py3-none-any.whl (508 kB)\n",
            "Downloading PyYAML-6.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (762 kB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 763.0/763.0 kB 43.4 MB/s  0:00:00\n",
            "Downloading regex-2024.11.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (792 kB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 792.7/792.7 kB 43.3 MB/s  0:00:00\n",
            "Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "Downloading urllib3-2.2.3-py3-none-any.whl (126 kB)\n",
            "Downloading rich-13.9.4-py3-none-any.whl (242 kB)\n",
            "Downloading safetensors-0.4.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (435 kB)\n",
            "Downloading scikit_learn-1.6.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 13.5/13.5 MB 147.3 MB/s  0:00:00\n",
            "Downloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 38.6/38.6 MB 59.7 MB/s  0:00:00\n",
            "Downloading sentence_transformers-3.3.1-py3-none-any.whl (268 kB)\n",
            "Downloading transformers-4.43.1-py3-none-any.whl (9.4 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 9.4/9.4 MB 131.1 MB/s  0:00:00\n",
            "Downloading tokenizers-0.19.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 3.6/3.6 MB 112.5 MB/s  0:00:00\n",
            "Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
            "Downloading six-1.17.0-py2.py3-none-any.whl (11 kB)\n",
            "Downloading smart_open-7.1.0-py3-none-any.whl (61 kB)\n",
            "Downloading spacy-3.8.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30.6 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 30.6/30.6 MB 56.0 MB/s  0:00:00\n",
            "Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
            "Downloading spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
            "Downloading thinc-8.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.9 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 3.9/3.9 MB 139.5 MB/s  0:00:00\n",
            "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "Downloading typer-0.15.1-py3-none-any.whl (44 kB)\n",
            "Downloading wasabi-1.1.3-py3-none-any.whl (27 kB)\n",
            "Downloading weasel-0.4.1-py3-none-any.whl (50 kB)\n",
            "Downloading stack_data-0.6.3-py3-none-any.whl (24 kB)\n",
            "Downloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 6.2/6.2 MB 162.8 MB/s  0:00:00\n",
            "Downloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
            "Downloading torch-2.5.1-cp311-cp311-manylinux1_x86_64.whl (906.5 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 906.5/906.5 MB 28.3 MB/s  0:00:17\n",
            "Downloading traitlets-5.14.3-py3-none-any.whl (85 kB)\n",
            "Downloading triton-3.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 209.5/209.5 MB 74.1 MB/s  0:00:02\n",
            "Downloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
            "Downloading tzdata-2024.2-py2.py3-none-any.whl (346 kB)\n",
            "Downloading ujson-5.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n",
            "Downloading wcwidth-0.2.13-py2.py3-none-any.whl (34 kB)\n",
            "Downloading wrapt-1.17.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (83 kB)\n",
            "Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "Downloading llama_index-0.12.42-py3-none-any.whl (7.1 kB)\n",
            "Downloading llama_index_core-0.12.42-py3-none-any.whl (7.7 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 7.7/7.7 MB 147.4 MB/s  0:00:00\n",
            "Downloading banks-2.2.0-py3-none-any.whl (29 kB)\n",
            "Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
            "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading llama_index_agent_openai-0.4.12-py3-none-any.whl (14 kB)\n",
            "Downloading llama_index_cli-0.4.4-py3-none-any.whl (28 kB)\n",
            "Downloading llama_index_embeddings_openai-0.3.1-py3-none-any.whl (6.2 kB)\n",
            "Downloading llama_index_llms_openai-0.4.7-py3-none-any.whl (25 kB)\n",
            "Downloading llama_index_multi_modal_llms_openai-0.5.1-py3-none-any.whl (3.4 kB)\n",
            "Downloading llama_index_program_openai-0.3.2-py3-none-any.whl (6.1 kB)\n",
            "Downloading llama_index_question_gen_openai-0.3.1-py3-none-any.whl (3.7 kB)\n",
            "Downloading llama_index_readers_file-0.4.11-py3-none-any.whl (41 kB)\n",
            "Downloading beautifulsoup4-4.14.3-py3-none-any.whl (107 kB)\n",
            "Downloading nest_asyncio-1.6.0-py3-none-any.whl (5.2 kB)\n",
            "Downloading openai-1.109.1-py3-none-any.whl (948 kB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 948.6/948.6 kB 45.2 MB/s  0:00:00\n",
            "Downloading anyio-4.12.0-py3-none-any.whl (113 kB)\n",
            "Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
            "Downloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
            "Downloading httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
            "Downloading jiter-0.12.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (364 kB)\n",
            "Downloading pypdf-5.9.0-py3-none-any.whl (313 kB)\n",
            "Downloading striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
            "Downloading tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
            "Downloading defusedxml-0.7.1-py2.py3-none-any.whl (25 kB)\n",
            "Downloading deprecated-1.3.1-py2.py3-none-any.whl (11 kB)\n",
            "Downloading llama_index_indices_managed_llama_cloud-0.8.0-py3-none-any.whl (16 kB)\n",
            "Downloading llama_cloud-0.1.35-py3-none-any.whl (303 kB)\n",
            "Downloading llama_index_readers_llama_parse-0.4.0-py3-none-any.whl (2.5 kB)\n",
            "Downloading llama_parse-0.6.54-py3-none-any.whl (4.9 kB)\n",
            "Downloading llama_cloud_services-0.6.54-py3-none-any.whl (63 kB)\n",
            "Downloading platformdirs-4.5.0-py3-none-any.whl (18 kB)\n",
            "Downloading python_dotenv-1.2.1-py3-none-any.whl (21 kB)\n",
            "Downloading nltk-3.9.2-py3-none-any.whl (1.5 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1.5/1.5 MB 74.5 MB/s  0:00:00\n",
            "Downloading soupsieve-2.8-py3-none-any.whl (36 kB)\n",
            "Downloading sqlalchemy-2.0.44-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 3.3/3.3 MB 115.2 MB/s  0:00:00\n",
            "Downloading greenlet-3.2.4-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (587 kB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 587.7/587.7 kB 29.7 MB/s  0:00:00\n",
            "Downloading tiktoken-0.12.0-cp311-cp311-manylinux_2_28_x86_64.whl (1.2 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1.2/1.2 MB 71.1 MB/s  0:00:00\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Downloading aiosqlite-0.21.0-py3-none-any.whl (15 kB)\n",
            "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "Downloading faiss_cpu-1.13.0-cp39-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (23.6 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 23.6/23.6 MB 240.0 MB/s  0:00:00\n",
            "Downloading griffe-1.15.0-py3-none-any.whl (150 kB)\n",
            "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading mkl-2025.3.0-py2.py3-none-manylinux_2_28_x86_64.whl (195.0 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 195.0/195.0 MB 70.0 MB/s  0:00:02\n",
            "Downloading onemkl_license-2025.3.0-py2.py3-none-manylinux_2_28_x86_64.whl (58 kB)\n",
            "Downloading intel_openmp-2025.3.1-py2.py3-none-manylinux_2_28_x86_64.whl (74.3 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 74.3/74.3 MB 61.2 MB/s  0:00:01\n",
            "Downloading intel_cmplr_lib_ur-2025.3.1-py2.py3-none-manylinux_2_28_x86_64.whl (30.8 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 30.8/30.8 MB 147.6 MB/s  0:00:00\n",
            "Downloading tbb-2022.3.0-py2.py3-none-manylinux_2_28_x86_64.whl (4.2 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 4.2/4.2 MB 133.2 MB/s  0:00:00\n",
            "Downloading tcmlib-1.4.1-py2.py3-none-manylinux_2_28_x86_64.whl (2.7 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2.7/2.7 MB 106.6 MB/s  0:00:00\n",
            "Downloading umf-1.0.2-py2.py3-none-manylinux_2_28_x86_64.whl (359 kB)\n",
            "Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
            "Building wheels for collected packages: beir, pytrec-eval\n",
            "  Building wheel for beir (pyproject.toml): started\n",
            "  Building wheel for beir (pyproject.toml): finished with status 'done'\n",
            "  Created wheel for beir: filename=beir-2.0.0-py3-none-any.whl size=63674 sha256=e417abd0ebb5b8a4fc3d4ee71cc344f511f9297d2f1e75476bdf4438c3492ae5\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/4d/5d/5b20c57488e83fc5dab7a9a3442c0555b6c4094d1504a22ac3\n",
            "  Building wheel for pytrec-eval (pyproject.toml): started\n",
            "  Building wheel for pytrec-eval (pyproject.toml): finished with status 'done'\n",
            "  Created wheel for pytrec-eval: filename=pytrec_eval-0.5-cp311-cp311-linux_x86_64.whl size=308632 sha256=04f93d4db2f2c9c418b28821947c9ebabdcd93fb30cd3d4479c1f5b8003d3365\n",
            "  Stored in directory: /root/.cache/pip/wheels/0f/89/42/86aecdb99975f1840c27bc37fdfed72116abcf82e2c9dc76a8\n",
            "Successfully built beir pytrec-eval\n",
            "Installing collected packages: wcwidth, tcmlib, striprtf, pytz, pure_eval, ptyprocess, onemkl-license, mpmath, filetype, en_core_web_sm, dirtyjson, cymem, xxhash, wrapt, wasabi, urllib3, umf, ujson, tzdata, typing_extensions, traitlets, tqdm, threadpoolctl, tenacity, tbb, sympy, spacy-loggers, spacy-legacy, soupsieve, sniffio, six, shellingham, safetensors, regex, PyYAML, pytrec-eval, python-dotenv, pypdf, Pygments, pyarrow, psutil, propcache, prompt_toolkit, platformdirs, pillow, pexpect, parso, packaging, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, nest-asyncio, mypy-extensions, murmurhash, multidict, mdurl, MarkupSafe, marisa-trie, llvmlite, joblib, jiter, idna, greenlet, fsspec, frozenlist, filelock, executing, exceptiongroup, distro, dill, defusedxml, decorator, colorama, cloudpathlib, click, charset-normalizer, certifi, catalogue, attrs, async-timeout, asttokens, annotated-types, aiohappyeyeballs, yarl, typing-inspect, triton, stack-data, srsly, sqlalchemy, smart-open, scipy, requests, python-dateutil, pydantic_core, preshed, nvidia-cusparse-cu12, nvidia-cudnn-cu12, numba, nltk, multiprocess, matplotlib-inline, marshmallow, markdown-it-py, language_data, Jinja2, jedi, intel-cmplr-lib-ur, httpcore, h5py, griffe, faiss_cpu, elasticsearch, deprecated, blis, beautifulsoup4, anyio, aiosqlite, aiosignal, tiktoken, scikit-learn, rich, pydantic, pandas, nvidia-cusolver-cu12, langcodes, ipython, intel-openmp, huggingface-hub, httpx, dataclasses-json, aiohttp, typer, torch, tokenizers, openai, mkl, llama-cloud, confection, banks, weasel, transformers, thinc, mkl-service, llama-index-core, datasets, bitsandbytes, accelerate, spacy, sentence-transformers, peft, llama-index-readers-file, llama-index-llms-openai, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, llama-cloud-services, llama-parse, llama-index-multi-modal-llms-openai, llama-index-cli, llama-index-agent-openai, beir, llama-index-readers-llama-parse, llama-index-program-openai, llama-index-question-gen-openai, llama-index\n",
            "  Attempting uninstall: click\n",
            "    Found existing installation: click 8.3.1\n",
            "    Uninstalling click-8.3.1:\n",
            "      Successfully uninstalled click-8.3.1\n",
            "\n",
            "Successfully installed Jinja2-3.1.4 MarkupSafe-3.0.2 PyYAML-6.0.2 Pygments-2.18.0 accelerate-1.2.0 aiohappyeyeballs-2.4.4 aiohttp-3.11.11 aiosignal-1.3.2 aiosqlite-0.21.0 annotated-types-0.7.0 anyio-4.12.0 asttokens-3.0.0 async-timeout-5.0.1 attrs-24.3.0 banks-2.2.0 beautifulsoup4-4.14.3 beir-2.0.0 bitsandbytes-0.45.0 blis-1.1.0 catalogue-2.0.10 certifi-2024.8.30 charset-normalizer-3.4.0 click-8.1.8 cloudpathlib-0.20.0 colorama-0.4.6 confection-0.1.5 cymem-2.0.10 dataclasses-json-0.6.7 datasets-3.2.0 decorator-5.1.1 defusedxml-0.7.1 deprecated-1.3.1 dill-0.3.8 dirtyjson-1.0.8 distro-1.9.0 elasticsearch-7.9.1 en_core_web_sm-3.8.0 exceptiongroup-1.2.2 executing-2.1.0 faiss_cpu-1.13.0 filelock-3.16.1 filetype-1.2.0 frozenlist-1.5.0 fsspec-2024.9.0 greenlet-3.2.4 griffe-1.15.0 h5py-3.13.0 httpcore-1.0.9 httpx-0.28.1 huggingface-hub-0.26.5 idna-3.10 intel-cmplr-lib-ur-2025.3.1 intel-openmp-2025.3.1 ipython-8.18.1 jedi-0.19.2 jiter-0.12.0 joblib-1.4.2 langcodes-3.5.0 language_data-1.3.0 llama-cloud-0.1.35 llama-cloud-services-0.6.54 llama-index-0.12.42 llama-index-agent-openai-0.4.12 llama-index-cli-0.4.4 llama-index-core-0.12.42 llama-index-embeddings-openai-0.3.1 llama-index-indices-managed-llama-cloud-0.8.0 llama-index-llms-openai-0.4.7 llama-index-multi-modal-llms-openai-0.5.1 llama-index-program-openai-0.3.2 llama-index-question-gen-openai-0.3.1 llama-index-readers-file-0.4.11 llama-index-readers-llama-parse-0.4.0 llama-parse-0.6.54 llvmlite-0.41.1 marisa-trie-1.2.1 markdown-it-py-3.0.0 marshmallow-3.26.1 matplotlib-inline-0.1.7 mdurl-0.1.2 mkl-2025.3.0 mkl-service-2.4.2 mpmath-1.3.0 multidict-6.1.0 multiprocess-0.70.16 murmurhash-1.0.11 mypy-extensions-1.1.0 nest-asyncio-1.6.0 networkx-3.2.1 nltk-3.9.2 numba-0.58.1 numpy-1.26.4 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 onemkl-license-2025.3.0 openai-1.109.1 packaging-24.1 pandas-2.2.3 parso-0.8.4 peft-0.14.0 pexpect-4.9.0 pillow-11.1.0 platformdirs-4.5.0 preshed-3.0.9 prompt_toolkit-3.0.48 propcache-0.2.1 psutil-6.1.0 ptyprocess-0.7.0 pure_eval-0.2.3 pyarrow-18.1.0 pydantic-2.10.4 pydantic_core-2.27.2 pypdf-5.9.0 python-dateutil-2.9.0.post0 python-dotenv-1.2.1 pytrec-eval-0.5 pytz-2024.2 regex-2024.11.6 requests-2.32.3 rich-13.9.4 safetensors-0.4.5 scikit-learn-1.6.0 scipy-1.13.1 sentence-transformers-3.3.1 shellingham-1.5.4 six-1.17.0 smart-open-7.1.0 sniffio-1.3.1 soupsieve-2.8 spacy-3.8.3 spacy-legacy-3.0.12 spacy-loggers-1.0.5 sqlalchemy-2.0.44 srsly-2.5.0 stack-data-0.6.3 striprtf-0.0.26 sympy-1.13.1 tbb-2022.3.0 tcmlib-1.4.1 tenacity-9.1.2 thinc-8.3.3 threadpoolctl-3.5.0 tiktoken-0.12.0 tokenizers-0.19.1 torch-2.5.1 tqdm-4.67.1 traitlets-5.14.3 transformers-4.43.1 triton-3.1.0 typer-0.15.1 typing-inspect-0.9.0 typing_extensions-4.12.2 tzdata-2024.2 ujson-5.10.0 umf-1.0.2 urllib3-2.2.3 wasabi-1.1.3 wcwidth-0.2.13 weasel-0.4.1 wrapt-1.17.0 xxhash-3.5.0 yarl-1.18.3\n",
            "\n",
            "Collecting fastapi\n",
            "  Using cached fastapi-0.123.4-py3-none-any.whl.metadata (30 kB)\n",
            "Collecting starlette<0.51.0,>=0.40.0 (from fastapi)\n",
            "  Using cached starlette-0.50.0-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/envs/retriever/lib/python3.11/site-packages (from fastapi) (2.10.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/envs/retriever/lib/python3.11/site-packages (from fastapi) (4.12.2)\n",
            "Collecting annotated-doc>=0.0.2 (from fastapi)\n",
            "  Using cached annotated_doc-0.0.4-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/envs/retriever/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/envs/retriever/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.27.2)\n",
            "Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/envs/retriever/lib/python3.11/site-packages (from starlette<0.51.0,>=0.40.0->fastapi) (4.12.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/envs/retriever/lib/python3.11/site-packages (from anyio<5,>=3.6.2->starlette<0.51.0,>=0.40.0->fastapi) (3.10)\n",
            "Downloading fastapi-0.123.4-py3-none-any.whl (111 kB)\n",
            "Downloading starlette-0.50.0-py3-none-any.whl (74 kB)\n",
            "Downloading annotated_doc-0.0.4-py3-none-any.whl (5.3 kB)\n",
            "Installing collected packages: annotated-doc, starlette, fastapi\n",
            "\n",
            "Successfully installed annotated-doc-0.0.4 fastapi-0.123.4 starlette-0.50.0\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#retriever server dependency\n",
        "!mamba run -n retriever pip install uvicorn\n",
        "\n",
        "\n",
        "\n",
        "#!mamba run -n retriever pip install conda-pack\n",
        "#!mamba run -n train_and_test pip install conda-pack\n",
        "\n",
        "#ensure installation of certain files related to cuda 12.5 the one that comes with this runtime despite repo 12.6 suggestion\n",
        "#!pip install --index-url https://download.pytorch.org/whl/cu124 torch==2.5.1 torchvision==0.20.1 torchaudio==2.5.1\n",
        "\n",
        "#installing the requirements for the mRAG project github repo\n",
        "\n",
        "!mamba run -n retriever pip install -r  /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt\n",
        "#!PIP_CACHE_DIR=/content/drive/MyDrive/mRAG_and_MSRS_source/pip_cache_retriever mamba run -n retriever pip install -r  /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup/requirements.txt\n",
        "!mamba run -n retriever pip install fastapi\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mamba run -n train_and_test pip install -r  /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_UiC_9p_pbgW",
        "outputId": "455fdd34-7b66-481e-b130-c55a6057fc68",
        "collapsed": true
      },
      "id": "_UiC_9p_pbgW",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting accelerate==1.6.0 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 1))\n",
            "  Downloading accelerate-1.6.0-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting aiohappyeyeballs==2.6.1 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 2))\n",
            "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting aiohttp==3.11.13 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 3))\n",
            "  Downloading aiohttp-3.11.13-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
            "Collecting aiosignal==1.3.2 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 4))\n",
            "  Using cached aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting aiosqlite==0.21.0 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 5))\n",
            "  Using cached aiosqlite-0.21.0-py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting airportsdata==20250224 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 6))\n",
            "  Downloading airportsdata-20250224-py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting annotated-types==0.7.0 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 7))\n",
            "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting anyio==4.8.0 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 8))\n",
            "  Downloading anyio-4.8.0-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting astor==0.8.1 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 9))\n",
            "  Downloading astor-0.8.1-py2.py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting attrs==25.3.0 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 10))\n",
            "  Downloading attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting banks==2.1.2 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 11))\n",
            "  Using cached banks-2.1.2-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting beautifulsoup4==4.13.4 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 12))\n",
            "  Downloading beautifulsoup4-4.13.4-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting bitsandbytes==0.45.5 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 13))\n",
            "  Downloading bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl.metadata (5.0 kB)\n",
            "Collecting blake3==1.0.4 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 14))\n",
            "  Downloading blake3-1.0.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
            "Collecting blinker==1.9.0 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 15))\n",
            "  Downloading blinker-1.9.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting certifi==2025.1.31 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 16))\n",
            "  Downloading certifi-2025.1.31-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting charset-normalizer==3.4.1 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 17))\n",
            "  Downloading charset_normalizer-3.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (35 kB)\n",
            "Collecting click==8.1.8 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 18))\n",
            "  Using cached click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting cloudpickle==3.1.1 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 19))\n",
            "  Downloading cloudpickle-3.1.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting colorama==0.4.6 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 20))\n",
            "  Using cached colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Collecting coloredlogs==15.0.1 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 21))\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Collecting compressed-tensors==0.9.1 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 22))\n",
            "  Downloading compressed_tensors-0.9.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting cupy-cuda12x==13.4.0 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 23))\n",
            "  Downloading cupy_cuda12x-13.4.0-cp311-cp311-manylinux2014_x86_64.whl.metadata (2.6 kB)\n",
            "Collecting cut-cross-entropy==25.1.1 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 24))\n",
            "  Downloading cut_cross_entropy-25.1.1-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting Cython==3.0.12 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 25))\n",
            "  Downloading Cython-3.0.12-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.3 kB)\n",
            "Collecting dataclasses-json==0.6.7 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 26))\n",
            "  Using cached dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting datasets==3.4.0 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 27))\n",
            "  Downloading datasets-3.4.0-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting Deprecated==1.2.18 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 28))\n",
            "  Using cached Deprecated-1.2.18-py2.py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting depyf==0.18.0 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 29))\n",
            "  Downloading depyf-0.18.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting diffusers==0.33.1 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 30))\n",
            "  Downloading diffusers-0.33.1-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting dill==0.3.8 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 31))\n",
            "  Using cached dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting dirtyjson==1.0.8 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 32))\n",
            "  Using cached dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting diskcache==5.6.3 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 33))\n",
            "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting distro==1.9.0 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 34))\n",
            "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting dnspython==2.7.0 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 35))\n",
            "  Downloading dnspython-2.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting docstring_parser==0.16 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 36))\n",
            "  Downloading docstring_parser-0.16-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting einops==0.8.1 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 37))\n",
            "  Downloading einops-0.8.1-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting email_validator==2.2.0 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 38))\n",
            "  Downloading email_validator-2.2.0-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting fastapi==0.115.11 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 39))\n",
            "  Downloading fastapi-0.115.11-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting fastapi-cli==0.0.7 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 40))\n",
            "  Downloading fastapi_cli-0.0.7-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting fastrlock==0.8.3 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 41))\n",
            "  Downloading fastrlock-0.8.3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_28_x86_64.whl.metadata (7.7 kB)\n",
            "Collecting filelock==3.17.0 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 42))\n",
            "  Downloading filelock-3.17.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting filetype==1.2.0 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 43))\n",
            "  Using cached filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting Flask==3.1.0 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 45))\n",
            "  Downloading flask-3.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting flatbuffers==25.2.10 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 46))\n",
            "  Downloading flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
            "Collecting frozenlist==1.5.0 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 47))\n",
            "  Using cached frozenlist-1.5.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Collecting fsspec==2024.12.0 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 48))\n",
            "  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting gguf==0.10.0 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 49))\n",
            "  Downloading gguf-0.10.0-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting greenlet==3.2.2 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 50))\n",
            "  Downloading greenlet-3.2.2-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (4.1 kB)\n",
            "Collecting griffe==1.7.3 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 51))\n",
            "  Downloading griffe-1.7.3-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting h11==0.14.0 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 52))\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Collecting hf_transfer==0.1.9 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 53))\n",
            "  Downloading hf_transfer-0.1.9-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting httpcore==1.0.7 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 54))\n",
            "  Downloading httpcore-1.0.7-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting httptools==0.6.4 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 55))\n",
            "  Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Collecting httpx==0.28.1 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 56))\n",
            "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting huggingface-hub==0.29.3 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 57))\n",
            "  Downloading huggingface_hub-0.29.3-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting humanfriendly==10.0 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 58))\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Collecting idna==3.10 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 59))\n",
            "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting importlib_metadata==8.6.1 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 60))\n",
            "  Downloading importlib_metadata-8.6.1-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting iniconfig==2.0.0 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 61))\n",
            "  Downloading iniconfig-2.0.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting interegular==0.3.3 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 62))\n",
            "  Downloading interegular-0.3.3-py37-none-any.whl.metadata (3.0 kB)\n",
            "Collecting itsdangerous==2.2.0 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 63))\n",
            "  Downloading itsdangerous-2.2.0-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting Jinja2==3.1.6 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 64))\n",
            "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting jiter==0.9.0 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 65))\n",
            "  Downloading jiter-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
            "Collecting joblib==1.4.2 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 66))\n",
            "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting json5==0.10.0 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 67))\n",
            "  Downloading json5-0.10.0-py3-none-any.whl.metadata (34 kB)\n",
            "Collecting jsonschema==4.23.0 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 68))\n",
            "  Downloading jsonschema-4.23.0-py3-none-any.whl.metadata (7.9 kB)\n",
            "Collecting jsonschema-specifications==2024.10.1 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 69))\n",
            "  Downloading jsonschema_specifications-2024.10.1-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting lark==1.2.2 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 70))\n",
            "  Downloading lark-1.2.2-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting llama-cloud==0.1.19 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 71))\n",
            "  Downloading llama_cloud-0.1.19-py3-none-any.whl.metadata (902 bytes)\n",
            "Collecting llama-cloud-services==0.6.22 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 72))\n",
            "  Downloading llama_cloud_services-0.6.22-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting llama-index==0.12.35 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 73))\n",
            "  Downloading llama_index-0.12.35-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting llama-index-agent-openai==0.4.7 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 74))\n",
            "  Downloading llama_index_agent_openai-0.4.7-py3-none-any.whl.metadata (438 bytes)\n",
            "Collecting llama-index-cli==0.4.1 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 75))\n",
            "  Downloading llama_index_cli-0.4.1-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting llama-index-core==0.12.35 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 76))\n",
            "  Downloading llama_index_core-0.12.35-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting llama-index-embeddings-openai==0.3.1 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 77))\n",
            "  Using cached llama_index_embeddings_openai-0.3.1-py3-none-any.whl.metadata (684 bytes)\n",
            "Collecting llama-index-indices-managed-llama-cloud==0.6.11 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 78))\n",
            "  Downloading llama_index_indices_managed_llama_cloud-0.6.11-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting llama-index-llms-openai==0.3.38 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 79))\n",
            "  Downloading llama_index_llms_openai-0.3.38-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-index-multi-modal-llms-openai==0.4.3 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 80))\n",
            "  Downloading llama_index_multi_modal_llms_openai-0.4.3-py3-none-any.whl.metadata (726 bytes)\n",
            "Collecting llama-index-program-openai==0.3.1 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 81))\n",
            "  Downloading llama_index_program_openai-0.3.1-py3-none-any.whl.metadata (764 bytes)\n",
            "Collecting llama-index-question-gen-openai==0.3.0 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 82))\n",
            "  Downloading llama_index_question_gen_openai-0.3.0-py3-none-any.whl.metadata (783 bytes)\n",
            "Collecting llama-index-readers-file==0.4.7 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 83))\n",
            "  Downloading llama_index_readers_file-0.4.7-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting llama-index-readers-llama-parse==0.4.0 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 84))\n",
            "  Using cached llama_index_readers_llama_parse-0.4.0-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting llama-parse==0.6.22 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 85))\n",
            "  Downloading llama_parse-0.6.22-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting llvmlite==0.43.0 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 86))\n",
            "  Downloading llvmlite-0.43.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\n",
            "Collecting lm-format-enforcer==0.10.11 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 87))\n",
            "  Downloading lm_format_enforcer-0.10.11-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting markdown-it-py==3.0.0 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 88))\n",
            "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting MarkupSafe==3.0.2 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 89))\n",
            "  Using cached MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
            "Collecting marshmallow==3.26.1 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 90))\n",
            "  Using cached marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting mdurl==0.1.2 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 91))\n",
            "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting mistral_common==1.5.3 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 92))\n",
            "  Downloading mistral_common-1.5.3-py3-none-any.whl.metadata (4.5 kB)\n",
            "Collecting mpmath==1.3.0 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 93))\n",
            "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting msgpack==1.1.0 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 94))\n",
            "  Downloading msgpack-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.4 kB)\n",
            "Collecting msgspec==0.19.0 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 95))\n",
            "  Downloading msgspec-0.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
            "Collecting multidict==6.1.0 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 96))\n",
            "  Using cached multidict-6.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)\n",
            "Collecting multiprocess==0.70.16 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 97))\n",
            "  Using cached multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting mypy_extensions==1.1.0 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 98))\n",
            "  Using cached mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting nest-asyncio==1.6.0 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 99))\n",
            "  Using cached nest_asyncio-1.6.0-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting networkx==3.4.2 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 100))\n",
            "  Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting nltk==3.9.1 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 101))\n",
            "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting numba==0.60.0 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 102))\n",
            "  Downloading numba-0.60.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.7 kB)\n",
            "Collecting numpy==1.26.4 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 103))\n",
            "  Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 104))\n",
            "  Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 105))\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 106))\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 107))\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 108))\n",
            "  Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 109))\n",
            "  Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 110))\n",
            "  Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 111))\n",
            "  Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 112))\n",
            "  Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.21.5 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 113))\n",
            "  Using cached nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 114))\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.4.127 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 115))\n",
            "  Using cached nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting onnxruntime==1.21.0 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 116))\n",
            "  Downloading onnxruntime-1.21.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Collecting openai==1.66.3 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 117))\n",
            "  Downloading openai-1.66.3-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting opencv-python-headless==4.11.0.86 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 118))\n",
            "  Downloading opencv_python_headless-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Collecting outlines==0.1.11 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 119))\n",
            "  Downloading outlines-0.1.11-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting outlines_core==0.1.26 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 120))\n",
            "  Downloading outlines_core-0.1.26-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Collecting packaging==24.2 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 121))\n",
            "  Downloading packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting pandas==2.2.3 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 122))\n",
            "  Using cached pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
            "Collecting partial-json-parser==0.2.1.1.post5 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 123))\n",
            "  Downloading partial_json_parser-0.2.1.1.post5-py3-none-any.whl.metadata (6.1 kB)\n",
            "Collecting peft==0.15.2 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 124))\n",
            "  Downloading peft-0.15.2-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting pillow==11.1.0 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 125))\n",
            "  Using cached pillow-11.1.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.1 kB)\n",
            "Collecting platformdirs==4.3.8 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 126))\n",
            "  Downloading platformdirs-4.3.8-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting pluggy==1.5.0 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 127))\n",
            "  Downloading pluggy-1.5.0-py3-none-any.whl.metadata (4.8 kB)\n",
            "Collecting prometheus-fastapi-instrumentator==7.0.2 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 128))\n",
            "  Downloading prometheus_fastapi_instrumentator-7.0.2-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting prometheus_client==0.21.1 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 129))\n",
            "  Downloading prometheus_client-0.21.1-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting propcache==0.3.0 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 130))\n",
            "  Downloading propcache-0.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Collecting protobuf==3.20.3 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 131))\n",
            "  Downloading protobuf-3.20.3-py2.py3-none-any.whl.metadata (720 bytes)\n",
            "Collecting psutil==7.0.0 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 132))\n",
            "  Downloading psutil-7.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\n",
            "Collecting py-cpuinfo==9.0.0 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 133))\n",
            "  Downloading py_cpuinfo-9.0.0-py3-none-any.whl.metadata (794 bytes)\n",
            "Collecting pyarrow==19.0.1 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 134))\n",
            "  Downloading pyarrow-19.0.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
            "Collecting pybind11==2.13.6 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 135))\n",
            "  Downloading pybind11-2.13.6-py3-none-any.whl.metadata (9.5 kB)\n",
            "Collecting pycountry==24.6.1 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 136))\n",
            "  Downloading pycountry-24.6.1-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting pydantic==2.10.6 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 137))\n",
            "  Downloading pydantic-2.10.6-py3-none-any.whl.metadata (30 kB)\n",
            "Collecting pydantic_core==2.27.2 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 138))\n",
            "  Using cached pydantic_core-2.27.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting Pygments==2.19.1 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 139))\n",
            "  Downloading pygments-2.19.1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting pyjnius==1.6.1 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 140))\n",
            "  Downloading pyjnius-1.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Collecting pypdf==5.5.0 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 141))\n",
            "  Downloading pypdf-5.5.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting pyserini==0.44.0 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 142))\n",
            "  Downloading pyserini-0.44.0.tar.gz (195.3 MB)\n",
            "     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 195.3/195.3 MB 62.7 MB/s  0:00:03\n",
            "  Installing build dependencies: started\n",
            "  Installing build dependencies: finished with status 'done'\n",
            "  Getting requirements to build wheel: started\n",
            "  Getting requirements to build wheel: finished with status 'done'\n",
            "  Preparing metadata (pyproject.toml): started\n",
            "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
            "Collecting pytest==8.3.5 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 143))\n",
            "  Downloading pytest-8.3.5-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting python-dateutil==2.9.0.post0 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 144))\n",
            "  Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting python-dotenv==1.0.1 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 145))\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting python-multipart==0.0.20 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 146))\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting pytz==2025.1 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 147))\n",
            "  Downloading pytz-2025.1-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting PyYAML==6.0.2 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 148))\n",
            "  Using cached PyYAML-6.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting pyzmq==26.3.0 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 149))\n",
            "  Downloading pyzmq-26.3.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.2 kB)\n",
            "Collecting ray==2.40.0 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 150))\n",
            "  Downloading ray-2.40.0-cp311-cp311-manylinux2014_x86_64.whl.metadata (17 kB)\n",
            "Collecting referencing==0.36.2 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 151))\n",
            "  Downloading referencing-0.36.2-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting regex==2024.11.6 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 152))\n",
            "  Using cached regex-2024.11.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
            "Collecting requests==2.32.3 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 153))\n",
            "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting rich==13.9.4 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 154))\n",
            "  Using cached rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting rich-toolkit==0.13.2 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 155))\n",
            "  Downloading rich_toolkit-0.13.2-py3-none-any.whl.metadata (999 bytes)\n",
            "Collecting rpds-py==0.23.1 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 156))\n",
            "  Downloading rpds_py-0.23.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Collecting safetensors==0.5.3 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 157))\n",
            "  Downloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Collecting scikit-learn==1.6.1 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 158))\n",
            "  Downloading scikit_learn-1.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Collecting scipy==1.15.2 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 159))\n",
            "  Downloading scipy-1.15.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Collecting sentencepiece==0.2.0 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 160))\n",
            "  Downloading sentencepiece-0.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
            "Collecting setuptools==76.0.0 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 161))\n",
            "  Downloading setuptools-76.0.0-py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting shellingham==1.5.4 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 162))\n",
            "  Using cached shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting shtab==1.7.2 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 163))\n",
            "  Downloading shtab-1.7.2-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting six==1.17.0 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 164))\n",
            "  Using cached six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting sniffio==1.3.1 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 165))\n",
            "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting soupsieve==2.7 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 166))\n",
            "  Downloading soupsieve-2.7-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting SQLAlchemy==2.0.40 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 167))\n",
            "  Downloading sqlalchemy-2.0.40-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
            "Collecting starlette==0.46.1 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 168))\n",
            "  Downloading starlette-0.46.1-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting striprtf==0.0.26 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 169))\n",
            "  Using cached striprtf-0.0.26-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting sympy==1.13.1 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 170))\n",
            "  Using cached sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting tenacity==9.1.2 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 171))\n",
            "  Using cached tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting threadpoolctl==3.6.0 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 172))\n",
            "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting tiktoken==0.9.0 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 173))\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Collecting tokenizers==0.21.1 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 174))\n",
            "  Downloading tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting torch==2.5.1 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 175))\n",
            "  Using cached torch-2.5.1-cp311-cp311-manylinux1_x86_64.whl.metadata (28 kB)\n",
            "Collecting torchaudio==2.5.1 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 176))\n",
            "  Downloading torchaudio-2.5.1-cp311-cp311-manylinux1_x86_64.whl.metadata (6.4 kB)\n",
            "Collecting torchvision==0.20.1 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 177))\n",
            "  Downloading torchvision-0.20.1-cp311-cp311-manylinux1_x86_64.whl.metadata (6.1 kB)\n",
            "Collecting tqdm==4.67.1 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 178))\n",
            "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
            "Collecting transformers==4.49.0 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 179))\n",
            "  Downloading transformers-4.49.0-py3-none-any.whl.metadata (44 kB)\n",
            "Collecting triton==3.1.0 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 180))\n",
            "  Using cached triton-3.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
            "Collecting trl==0.15.2 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 181))\n",
            "  Downloading trl-0.15.2-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting typeguard==4.4.2 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 182))\n",
            "  Downloading typeguard-4.4.2-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting typer==0.15.2 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 183))\n",
            "  Downloading typer-0.15.2-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting typing-inspect==0.9.0 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 184))\n",
            "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting typing_extensions==4.13.2 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 185))\n",
            "  Downloading typing_extensions-4.13.2-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting tyro==0.9.19 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 186))\n",
            "  Downloading tyro-0.9.19-py3-none-any.whl.metadata (9.9 kB)\n",
            "Collecting tzdata==2025.1 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 187))\n",
            "  Downloading tzdata-2025.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting ujson==5.10.0 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 188))\n",
            "  Using cached ujson-5.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.3 kB)\n",
            "Collecting unsloth==2025.4.1 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 189))\n",
            "  Downloading unsloth-2025.4.1-py3-none-any.whl.metadata (46 kB)\n",
            "Collecting unsloth_zoo==2025.4.1 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 190))\n",
            "  Downloading unsloth_zoo-2025.4.1-py3-none-any.whl.metadata (8.0 kB)\n",
            "Collecting urllib3==2.3.0 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 191))\n",
            "  Downloading urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting uvicorn==0.34.0 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 192))\n",
            "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting uvloop==0.21.0 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 193))\n",
            "  Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting vllm==0.7.3 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 194))\n",
            "  Downloading vllm-0.7.3-cp38-abi3-manylinux1_x86_64.whl.metadata (25 kB)\n",
            "Collecting watchfiles==1.0.4 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 195))\n",
            "  Downloading watchfiles-1.0.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting websockets==15.0.1 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 196))\n",
            "  Downloading websockets-15.0.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting Werkzeug==3.1.3 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 197))\n",
            "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: wheel==0.45.1 in /usr/local/envs/train_and_test/lib/python3.11/site-packages (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 198)) (0.45.1)\n",
            "Collecting wrapt==1.17.2 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 199))\n",
            "  Downloading wrapt-1.17.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
            "Collecting xformers==0.0.28.post3 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 200))\n",
            "  Downloading xformers-0.0.28.post3-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (1.0 kB)\n",
            "Collecting xgrammar==0.1.11 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 201))\n",
            "  Downloading xgrammar-0.1.11-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (2.0 kB)\n",
            "Collecting xxhash==3.5.0 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 202))\n",
            "  Using cached xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting yarl==1.18.3 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 203))\n",
            "  Using cached yarl-1.18.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (69 kB)\n",
            "Collecting zipp==3.21.0 (from -r /content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/requirements.txt (line 204))\n",
            "  Downloading zipp-3.21.0-py3-none-any.whl.metadata (3.7 kB)\n",
            "Downloading accelerate-1.6.0-py3-none-any.whl (354 kB)\n",
            "Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
            "Downloading aiohttp-3.11.13-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1.7/1.7 MB 4.5 MB/s  0:00:00\n",
            "Using cached multidict-6.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "Using cached yarl-1.18.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (344 kB)\n",
            "Using cached aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
            "Using cached aiosqlite-0.21.0-py3-none-any.whl (15 kB)\n",
            "Downloading airportsdata-20250224-py3-none-any.whl (913 kB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 913.7/913.7 kB 57.7 MB/s  0:00:00\n",
            "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
            "Downloading anyio-4.8.0-py3-none-any.whl (96 kB)\n",
            "Downloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
            "Downloading attrs-25.3.0-py3-none-any.whl (63 kB)\n",
            "Downloading banks-2.1.2-py3-none-any.whl (28 kB)\n",
            "Downloading beautifulsoup4-4.13.4-py3-none-any.whl (187 kB)\n",
            "Downloading bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl (76.1 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 76.1/76.1 MB 31.0 MB/s  0:00:02\n",
            "Using cached torch-2.5.1-cp311-cp311-manylinux1_x86_64.whl (906.5 MB)\n",
            "Downloading blake3-1.0.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (376 kB)\n",
            "Downloading blinker-1.9.0-py3-none-any.whl (8.5 kB)\n",
            "Downloading certifi-2025.1.31-py3-none-any.whl (166 kB)\n",
            "Downloading charset_normalizer-3.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (143 kB)\n",
            "Using cached click-8.1.8-py3-none-any.whl (98 kB)\n",
            "Downloading cloudpickle-3.1.1-py3-none-any.whl (20 kB)\n",
            "Using cached colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "Downloading compressed_tensors-0.9.1-py3-none-any.whl (96 kB)\n",
            "Downloading cupy_cuda12x-13.4.0-cp311-cp311-manylinux2014_x86_64.whl (105.4 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 105.4/105.4 MB 33.5 MB/s  0:00:03\n",
            "Downloading cut_cross_entropy-25.1.1-py3-none-any.whl (22 kB)\n",
            "Downloading Cython-3.0.12-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 3.6/3.6 MB 95.5 MB/s  0:00:00\n",
            "Using cached dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Using cached marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading datasets-3.4.0-py3-none-any.whl (487 kB)\n",
            "Using cached dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "Downloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
            "Using cached multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "Downloading Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\n",
            "Downloading wrapt-1.17.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (83 kB)\n",
            "Downloading depyf-0.18.0-py3-none-any.whl (38 kB)\n",
            "Downloading diffusers-0.33.1-py3-none-any.whl (3.6 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 3.6/3.6 MB 64.0 MB/s  0:00:00\n",
            "Using cached dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
            "Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
            "Downloading dnspython-2.7.0-py3-none-any.whl (313 kB)\n",
            "Downloading docstring_parser-0.16-py3-none-any.whl (36 kB)\n",
            "Downloading einops-0.8.1-py3-none-any.whl (64 kB)\n",
            "Downloading email_validator-2.2.0-py3-none-any.whl (33 kB)\n",
            "Downloading fastapi-0.115.11-py3-none-any.whl (94 kB)\n",
            "Downloading pydantic-2.10.6-py3-none-any.whl (431 kB)\n",
            "Downloading starlette-0.46.1-py3-none-any.whl (71 kB)\n",
            "Downloading fastapi_cli-0.0.7-py3-none-any.whl (10 kB)\n",
            "Downloading fastrlock-0.8.3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_28_x86_64.whl (54 kB)\n",
            "Downloading filelock-3.17.0-py3-none-any.whl (16 kB)\n",
            "Using cached filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading flask-3.1.0-py3-none-any.whl (102 kB)\n",
            "Downloading flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
            "Using cached frozenlist-1.5.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (274 kB)\n",
            "Downloading gguf-0.10.0-py3-none-any.whl (71 kB)\n",
            "Downloading greenlet-3.2.2-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (583 kB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 583.9/583.9 kB 33.5 MB/s  0:00:00\n",
            "Downloading griffe-1.7.3-py3-none-any.whl (129 kB)\n",
            "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "Downloading hf_transfer-0.1.9-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 3.6/3.6 MB 110.9 MB/s  0:00:00\n",
            "Downloading httpcore-1.0.7-py3-none-any.whl (78 kB)\n",
            "Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (459 kB)\n",
            "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
            "Downloading huggingface_hub-0.29.3-py3-none-any.whl (468 kB)\n",
            "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
            "Downloading importlib_metadata-8.6.1-py3-none-any.whl (26 kB)\n",
            "Downloading iniconfig-2.0.0-py3-none-any.whl (5.9 kB)\n",
            "Downloading interegular-0.3.3-py37-none-any.whl (23 kB)\n",
            "Downloading itsdangerous-2.2.0-py3-none-any.whl (16 kB)\n",
            "Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
            "Downloading jiter-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (351 kB)\n",
            "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
            "Downloading json5-0.10.0-py3-none-any.whl (34 kB)\n",
            "Downloading jsonschema-4.23.0-py3-none-any.whl (88 kB)\n",
            "Downloading jsonschema_specifications-2024.10.1-py3-none-any.whl (18 kB)\n",
            "Downloading lark-1.2.2-py3-none-any.whl (111 kB)\n",
            "Downloading llama_cloud-0.1.19-py3-none-any.whl (263 kB)\n",
            "Downloading llama_cloud_services-0.6.22-py3-none-any.whl (37 kB)\n",
            "Downloading platformdirs-4.3.8-py3-none-any.whl (18 kB)\n",
            "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading llama_index-0.12.35-py3-none-any.whl (7.0 kB)\n",
            "Downloading llama_index_agent_openai-0.4.7-py3-none-any.whl (14 kB)\n",
            "Downloading llama_index_cli-0.4.1-py3-none-any.whl (28 kB)\n",
            "Downloading llama_index_core-0.12.35-py3-none-any.whl (7.7 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 7.7/7.7 MB 54.1 MB/s  0:00:00\n",
            "Using cached llama_index_embeddings_openai-0.3.1-py3-none-any.whl (6.2 kB)\n",
            "Downloading llama_index_llms_openai-0.3.38-py3-none-any.whl (23 kB)\n",
            "Downloading llama_index_multi_modal_llms_openai-0.4.3-py3-none-any.whl (5.9 kB)\n",
            "Downloading llama_index_program_openai-0.3.1-py3-none-any.whl (5.3 kB)\n",
            "Downloading llama_index_question_gen_openai-0.3.0-py3-none-any.whl (2.9 kB)\n",
            "Downloading llama_index_readers_file-0.4.7-py3-none-any.whl (40 kB)\n",
            "Using cached nest_asyncio-1.6.0-py3-none-any.whl (5.2 kB)\n",
            "Downloading openai-1.66.3-py3-none-any.whl (567 kB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 567.4/567.4 kB 15.3 MB/s  0:00:00\n",
            "Downloading pypdf-5.5.0-py3-none-any.whl (303 kB)\n",
            "Using cached striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
            "Using cached tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
            "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "Downloading typing_extensions-4.13.2-py3-none-any.whl (45 kB)\n",
            "Downloading llama_index_indices_managed_llama_cloud-0.6.11-py3-none-any.whl (14 kB)\n",
            "Using cached llama_index_readers_llama_parse-0.4.0-py3-none-any.whl (2.5 kB)\n",
            "Downloading llama_parse-0.6.22-py3-none-any.whl (4.9 kB)\n",
            "Downloading llvmlite-0.43.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.9 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 43.9/43.9 MB 14.4 MB/s  0:00:03\n",
            "Downloading lm_format_enforcer-0.10.11-py3-none-any.whl (44 kB)\n",
            "Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
            "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
            "Using cached MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23 kB)\n",
            "Downloading mistral_common-1.5.3-py3-none-any.whl (6.5 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 6.5/6.5 MB 43.0 MB/s  0:00:00\n",
            "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "Downloading msgpack-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (403 kB)\n",
            "Downloading msgspec-0.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (210 kB)\n",
            "Using cached mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1.7/1.7 MB 44.9 MB/s  0:00:00\n",
            "Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1.5/1.5 MB 85.6 MB/s  0:00:00\n",
            "Downloading numba-0.60.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.7 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 3.7/3.7 MB 17.2 MB/s  0:00:00\n",
            "Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "Using cached nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
            "Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Using cached nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
            "Downloading onnxruntime-1.21.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.0 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 16.0/16.0 MB 24.2 MB/s  0:00:00\n",
            "Downloading opencv_python_headless-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (50.0 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 50.0/50.0 MB 49.2 MB/s  0:00:01\n",
            "Downloading outlines-0.1.11-py3-none-any.whl (87 kB)\n",
            "Downloading outlines_core-0.1.26-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (343 kB)\n",
            "Downloading packaging-24.2-py3-none-any.whl (65 kB)\n",
            "Using cached pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
            "Downloading partial_json_parser-0.2.1.1.post5-py3-none-any.whl (10 kB)\n",
            "Downloading peft-0.15.2-py3-none-any.whl (411 kB)\n",
            "Using cached pillow-11.1.0-cp311-cp311-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "Downloading pluggy-1.5.0-py3-none-any.whl (20 kB)\n",
            "Downloading prometheus_fastapi_instrumentator-7.0.2-py3-none-any.whl (18 kB)\n",
            "Downloading prometheus_client-0.21.1-py3-none-any.whl (54 kB)\n",
            "Downloading propcache-0.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (231 kB)\n",
            "Downloading protobuf-3.20.3-py2.py3-none-any.whl (162 kB)\n",
            "Downloading psutil-7.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (277 kB)\n",
            "Downloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
            "Downloading pyarrow-19.0.1-cp311-cp311-manylinux_2_28_x86_64.whl (42.1 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 42.1/42.1 MB 24.0 MB/s  0:00:01\n",
            "Downloading pybind11-2.13.6-py3-none-any.whl (243 kB)\n",
            "Downloading pycountry-24.6.1-py3-none-any.whl (6.3 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 6.3/6.3 MB 128.9 MB/s  0:00:00\n",
            "Using cached pydantic_core-2.27.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "Downloading pygments-2.19.1-py3-none-any.whl (1.2 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1.2/1.2 MB 68.4 MB/s  0:00:00\n",
            "Downloading pyjnius-1.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1.6/1.6 MB 9.5 MB/s  0:00:00\n",
            "Downloading pytest-8.3.5-py3-none-any.whl (343 kB)\n",
            "Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
            "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading pytz-2025.1-py2.py3-none-any.whl (507 kB)\n",
            "Using cached PyYAML-6.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (762 kB)\n",
            "Downloading pyzmq-26.3.0-cp311-cp311-manylinux_2_28_x86_64.whl (867 kB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 867.6/867.6 kB 50.3 MB/s  0:00:00\n",
            "Downloading ray-2.40.0-cp311-cp311-manylinux2014_x86_64.whl (67.0 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 67.0/67.0 MB 9.4 MB/s  0:00:07\n",
            "Downloading referencing-0.36.2-py3-none-any.whl (26 kB)\n",
            "Using cached regex-2024.11.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (792 kB)\n",
            "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "Downloading urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
            "Using cached rich-13.9.4-py3-none-any.whl (242 kB)\n",
            "Downloading rich_toolkit-0.13.2-py3-none-any.whl (13 kB)\n",
            "Downloading rpds_py-0.23.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (386 kB)\n",
            "Downloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (471 kB)\n",
            "Downloading scikit_learn-1.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 13.5/13.5 MB 70.6 MB/s  0:00:00\n",
            "Downloading scipy-1.15.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.6 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 37.6/37.6 MB 38.2 MB/s  0:00:00\n",
            "Downloading sentencepiece-0.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1.3/1.3 MB 21.0 MB/s  0:00:00\n",
            "Downloading setuptools-76.0.0-py3-none-any.whl (1.2 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1.2/1.2 MB 21.2 MB/s  0:00:00\n",
            "Using cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
            "Downloading shtab-1.7.2-py3-none-any.whl (14 kB)\n",
            "Using cached six-1.17.0-py2.py3-none-any.whl (11 kB)\n",
            "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
            "Downloading soupsieve-2.7-py3-none-any.whl (36 kB)\n",
            "Downloading sqlalchemy-2.0.40-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 3.2/3.2 MB 14.3 MB/s  0:00:00\n",
            "Using cached sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
            "Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
            "Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1.2/1.2 MB 21.8 MB/s  0:00:00\n",
            "Downloading tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 3.0/3.0 MB 15.3 MB/s  0:00:00\n",
            "Downloading torchaudio-2.5.1-cp311-cp311-manylinux1_x86_64.whl (3.4 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 3.4/3.4 MB 85.6 MB/s  0:00:00\n",
            "Downloading torchvision-0.20.1-cp311-cp311-manylinux1_x86_64.whl (7.2 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 7.2/7.2 MB 81.6 MB/s  0:00:00\n",
            "Downloading transformers-4.49.0-py3-none-any.whl (10.0 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 10.0/10.0 MB 109.7 MB/s  0:00:00\n",
            "Using cached triton-3.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n",
            "Downloading trl-0.15.2-py3-none-any.whl (318 kB)\n",
            "Downloading typeguard-4.4.2-py3-none-any.whl (35 kB)\n",
            "Downloading typer-0.15.2-py3-none-any.whl (45 kB)\n",
            "Downloading tyro-0.9.19-py3-none-any.whl (124 kB)\n",
            "Downloading tzdata-2025.1-py2.py3-none-any.whl (346 kB)\n",
            "Using cached ujson-5.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n",
            "Downloading unsloth-2025.4.1-py3-none-any.whl (193 kB)\n",
            "Downloading unsloth_zoo-2025.4.1-py3-none-any.whl (128 kB)\n",
            "Downloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
            "Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 4.0/4.0 MB 29.7 MB/s  0:00:00\n",
            "Downloading vllm-0.7.3-cp38-abi3-manylinux1_x86_64.whl (264.6 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 264.6/264.6 MB 6.1 MB/s  0:00:43\n",
            "Downloading watchfiles-1.0.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (452 kB)\n",
            "Downloading websockets-15.0.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (182 kB)\n",
            "Downloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
            "Downloading xformers-0.0.28.post3-cp311-cp311-manylinux_2_28_x86_64.whl (16.7 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 16.7/16.7 MB 19.2 MB/s  0:00:00\n",
            "Downloading xgrammar-0.1.11-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (396 kB)\n",
            "Using cached xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "Downloading zipp-3.21.0-py3-none-any.whl (9.6 kB)\n",
            "Building wheels for collected packages: pyserini\n",
            "  Building wheel for pyserini (pyproject.toml): started\n",
            "  Building wheel for pyserini (pyproject.toml): finished with status 'done'\n",
            "  Created wheel for pyserini: filename=pyserini-0.44.0-py3-none-any.whl size=195388880 sha256=94b0588fd71535e10b1270dc92e657f5776fff08a0129872b3132230ba0e2244\n",
            "  Stored in directory: /root/.cache/pip/wheels/4d/fb/2c/523bde7d33a5dd4d0da19070ad3c96113f2b0face35a863f25\n",
            "Successfully built pyserini\n",
            "Installing collected packages: striprtf, sentencepiece, pytz, pyjnius, py-cpuinfo, mpmath, flatbuffers, filetype, fastrlock, dirtyjson, blake3, zipp, xxhash, wrapt, websockets, uvloop, urllib3, ujson, tzdata, typing_extensions, tqdm, threadpoolctl, tenacity, sympy, soupsieve, sniffio, six, shtab, shellingham, setuptools, safetensors, rpds-py, regex, pyzmq, PyYAML, python-multipart, python-dotenv, pypdf, Pygments, pycountry, pybind11, pyarrow, psutil, protobuf, propcache, prometheus_client, pluggy, platformdirs, pillow, partial-json-parser, packaging, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, nest-asyncio, mypy_extensions, multidict, msgspec, msgpack, mdurl, MarkupSafe, llvmlite, lark, json5, joblib, jiter, itsdangerous, interegular, iniconfig, idna, humanfriendly, httptools, hf_transfer, h11, greenlet, fsspec, frozenlist, filelock, einops, docstring_parser, dnspython, distro, diskcache, dill, Cython, colorama, cloudpickle, click, charset-normalizer, certifi, blinker, attrs, astor, annotated-types, airportsdata, aiohappyeyeballs, yarl, Werkzeug, uvicorn, typing-inspect, typeguard, triton, SQLAlchemy, scipy, requests, referencing, python-dateutil, pytest, pydantic_core, opencv-python-headless, nvidia-cusparse-cu12, nvidia-cudnn-cu12, numba, nltk, multiprocess, marshmallow, markdown-it-py, Jinja2, importlib_metadata, httpcore, griffe, gguf, email_validator, depyf, Deprecated, cupy-cuda12x, coloredlogs, beautifulsoup4, anyio, aiosqlite, aiosignal, watchfiles, tiktoken, starlette, scikit-learn, rich, pydantic, pandas, onnxruntime, nvidia-cusolver-cu12, jsonschema-specifications, huggingface-hub, httpx, Flask, dataclasses-json, aiohttp, tyro, typer, torch, tokenizers, rich-toolkit, prometheus-fastapi-instrumentator, openai, lm-format-enforcer, llama-cloud, jsonschema, fastapi, diffusers, banks, xformers, transformers, torchvision, torchaudio, ray, outlines_core, mistral_common, llama-index-core, fastapi-cli, datasets, cut-cross-entropy, bitsandbytes, accelerate, xgrammar, trl, pyserini, peft, outlines, llama-index-readers-file, llama-index-llms-openai, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, llama-cloud-services, compressed-tensors, unsloth_zoo, llama-parse, llama-index-multi-modal-llms-openai, llama-index-cli, llama-index-agent-openai, vllm, unsloth, llama-index-readers-llama-parse, llama-index-program-openai, llama-index-question-gen-openai, llama-index\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 80.9.0\n",
            "    Uninstalling setuptools-80.9.0:\n",
            "      Successfully uninstalled setuptools-80.9.0\n",
            "\n",
            "Successfully installed Cython-3.0.12 Deprecated-1.2.18 Flask-3.1.0 Jinja2-3.1.6 MarkupSafe-3.0.2 PyYAML-6.0.2 Pygments-2.19.1 SQLAlchemy-2.0.40 Werkzeug-3.1.3 accelerate-1.6.0 aiohappyeyeballs-2.6.1 aiohttp-3.11.13 aiosignal-1.3.2 aiosqlite-0.21.0 airportsdata-20250224 annotated-types-0.7.0 anyio-4.8.0 astor-0.8.1 attrs-25.3.0 banks-2.1.2 beautifulsoup4-4.13.4 bitsandbytes-0.45.5 blake3-1.0.4 blinker-1.9.0 certifi-2025.1.31 charset-normalizer-3.4.1 click-8.1.8 cloudpickle-3.1.1 colorama-0.4.6 coloredlogs-15.0.1 compressed-tensors-0.9.1 cupy-cuda12x-13.4.0 cut-cross-entropy-25.1.1 dataclasses-json-0.6.7 datasets-3.4.0 depyf-0.18.0 diffusers-0.33.1 dill-0.3.8 dirtyjson-1.0.8 diskcache-5.6.3 distro-1.9.0 dnspython-2.7.0 docstring_parser-0.16 einops-0.8.1 email_validator-2.2.0 fastapi-0.115.11 fastapi-cli-0.0.7 fastrlock-0.8.3 filelock-3.17.0 filetype-1.2.0 flatbuffers-25.2.10 frozenlist-1.5.0 fsspec-2024.12.0 gguf-0.10.0 greenlet-3.2.2 griffe-1.7.3 h11-0.14.0 hf_transfer-0.1.9 httpcore-1.0.7 httptools-0.6.4 httpx-0.28.1 huggingface-hub-0.29.3 humanfriendly-10.0 idna-3.10 importlib_metadata-8.6.1 iniconfig-2.0.0 interegular-0.3.3 itsdangerous-2.2.0 jiter-0.9.0 joblib-1.4.2 json5-0.10.0 jsonschema-4.23.0 jsonschema-specifications-2024.10.1 lark-1.2.2 llama-cloud-0.1.19 llama-cloud-services-0.6.22 llama-index-0.12.35 llama-index-agent-openai-0.4.7 llama-index-cli-0.4.1 llama-index-core-0.12.35 llama-index-embeddings-openai-0.3.1 llama-index-indices-managed-llama-cloud-0.6.11 llama-index-llms-openai-0.3.38 llama-index-multi-modal-llms-openai-0.4.3 llama-index-program-openai-0.3.1 llama-index-question-gen-openai-0.3.0 llama-index-readers-file-0.4.7 llama-index-readers-llama-parse-0.4.0 llama-parse-0.6.22 llvmlite-0.43.0 lm-format-enforcer-0.10.11 markdown-it-py-3.0.0 marshmallow-3.26.1 mdurl-0.1.2 mistral_common-1.5.3 mpmath-1.3.0 msgpack-1.1.0 msgspec-0.19.0 multidict-6.1.0 multiprocess-0.70.16 mypy_extensions-1.1.0 nest-asyncio-1.6.0 networkx-3.4.2 nltk-3.9.1 numba-0.60.0 numpy-1.26.4 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 onnxruntime-1.21.0 openai-1.66.3 opencv-python-headless-4.11.0.86 outlines-0.1.11 outlines_core-0.1.26 packaging-24.2 pandas-2.2.3 partial-json-parser-0.2.1.1.post5 peft-0.15.2 pillow-11.1.0 platformdirs-4.3.8 pluggy-1.5.0 prometheus-fastapi-instrumentator-7.0.2 prometheus_client-0.21.1 propcache-0.3.0 protobuf-3.20.3 psutil-7.0.0 py-cpuinfo-9.0.0 pyarrow-19.0.1 pybind11-2.13.6 pycountry-24.6.1 pydantic-2.10.6 pydantic_core-2.27.2 pyjnius-1.6.1 pypdf-5.5.0 pyserini-0.44.0 pytest-8.3.5 python-dateutil-2.9.0.post0 python-dotenv-1.0.1 python-multipart-0.0.20 pytz-2025.1 pyzmq-26.3.0 ray-2.40.0 referencing-0.36.2 regex-2024.11.6 requests-2.32.3 rich-13.9.4 rich-toolkit-0.13.2 rpds-py-0.23.1 safetensors-0.5.3 scikit-learn-1.6.1 scipy-1.15.2 sentencepiece-0.2.0 setuptools-76.0.0 shellingham-1.5.4 shtab-1.7.2 six-1.17.0 sniffio-1.3.1 soupsieve-2.7 starlette-0.46.1 striprtf-0.0.26 sympy-1.13.1 tenacity-9.1.2 threadpoolctl-3.6.0 tiktoken-0.9.0 tokenizers-0.21.1 torch-2.5.1 torchaudio-2.5.1 torchvision-0.20.1 tqdm-4.67.1 transformers-4.49.0 triton-3.1.0 trl-0.15.2 typeguard-4.4.2 typer-0.15.2 typing-inspect-0.9.0 typing_extensions-4.13.2 tyro-0.9.19 tzdata-2025.1 ujson-5.10.0 unsloth-2025.4.1 unsloth_zoo-2025.4.1 urllib3-2.3.0 uvicorn-0.34.0 uvloop-0.21.0 vllm-0.7.3 watchfiles-1.0.4 websockets-15.0.1 wrapt-1.17.2 xformers-0.0.28.post3 xgrammar-0.1.11 xxhash-3.5.0 yarl-1.18.3 zipp-3.21.0\n",
            "\n",
            "WARNING: The candidate selected for download or install is a yanked version: 'aiohttp' candidate (version 3.11.13 at https://files.pythonhosted.org/packages/95/de/faba18a0af09969e10eb89fdbd4cb968bea95e75449a7fa944d4de7d1d2f/aiohttp-3.11.13-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (from https://pypi.org/simple/aiohttp/) (requires-python:>=3.9))\n",
            "Reason for being yanked: Regression: https://github.com/aio-libs/aiohttp/issues/10617\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#installed at a separate point removed from requirements.txt file, because torch has to be guaranteed to be built before\n",
        "!mamba run -n train_and_test pip install --no-build-isolation flash-attn==2.7.4.post1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EGsMylvAsLif",
        "outputId": "f9ddfac4-9539-4638-e354-22708f0cf9ea",
        "collapsed": true
      },
      "id": "EGsMylvAsLif",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting flash-attn==2.7.4.post1\n",
            "  Downloading flash_attn-2.7.4.post1.tar.gz (6.0 MB)\n",
            "     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 6.0/6.0 MB 94.2 MB/s  0:00:00\n",
            "  Preparing metadata (pyproject.toml): started\n",
            "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
            "Requirement already satisfied: torch in /usr/local/envs/train_and_test/lib/python3.11/site-packages (from flash-attn==2.7.4.post1) (2.5.1)\n",
            "Requirement already satisfied: einops in /usr/local/envs/train_and_test/lib/python3.11/site-packages (from flash-attn==2.7.4.post1) (0.8.1)\n",
            "Requirement already satisfied: filelock in /usr/local/envs/train_and_test/lib/python3.11/site-packages (from torch->flash-attn==2.7.4.post1) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/envs/train_and_test/lib/python3.11/site-packages (from torch->flash-attn==2.7.4.post1) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/envs/train_and_test/lib/python3.11/site-packages (from torch->flash-attn==2.7.4.post1) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/envs/train_and_test/lib/python3.11/site-packages (from torch->flash-attn==2.7.4.post1) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/envs/train_and_test/lib/python3.11/site-packages (from torch->flash-attn==2.7.4.post1) (2024.12.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/envs/train_and_test/lib/python3.11/site-packages (from torch->flash-attn==2.7.4.post1) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/envs/train_and_test/lib/python3.11/site-packages (from torch->flash-attn==2.7.4.post1) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/envs/train_and_test/lib/python3.11/site-packages (from torch->flash-attn==2.7.4.post1) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/envs/train_and_test/lib/python3.11/site-packages (from torch->flash-attn==2.7.4.post1) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/envs/train_and_test/lib/python3.11/site-packages (from torch->flash-attn==2.7.4.post1) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/envs/train_and_test/lib/python3.11/site-packages (from torch->flash-attn==2.7.4.post1) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/envs/train_and_test/lib/python3.11/site-packages (from torch->flash-attn==2.7.4.post1) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/envs/train_and_test/lib/python3.11/site-packages (from torch->flash-attn==2.7.4.post1) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/envs/train_and_test/lib/python3.11/site-packages (from torch->flash-attn==2.7.4.post1) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/envs/train_and_test/lib/python3.11/site-packages (from torch->flash-attn==2.7.4.post1) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/envs/train_and_test/lib/python3.11/site-packages (from torch->flash-attn==2.7.4.post1) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/envs/train_and_test/lib/python3.11/site-packages (from torch->flash-attn==2.7.4.post1) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/envs/train_and_test/lib/python3.11/site-packages (from torch->flash-attn==2.7.4.post1) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/envs/train_and_test/lib/python3.11/site-packages (from torch->flash-attn==2.7.4.post1) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/envs/train_and_test/lib/python3.11/site-packages (from sympy==1.13.1->torch->flash-attn==2.7.4.post1) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/envs/train_and_test/lib/python3.11/site-packages (from jinja2->torch->flash-attn==2.7.4.post1) (3.0.2)\n",
            "Building wheels for collected packages: flash-attn\n",
            "  Building wheel for flash-attn (pyproject.toml): started\n",
            "  Building wheel for flash-attn (pyproject.toml): finished with status 'done'\n",
            "  Created wheel for flash-attn: filename=flash_attn-2.7.4.post1-cp311-cp311-linux_x86_64.whl size=187815463 sha256=d944fc7d2f962bce83fc4708c2fc0c21eaf8255962a0b350ae919362a51b7ef2\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/88/d8/284b89f56af7d5bf366b10d6b8e251ac8a7c7bf3f04203fb4f\n",
            "Successfully built flash-attn\n",
            "Installing collected packages: flash-attn\n",
            "Successfully installed flash-attn-2.7.4.post1\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#CACHE the entire mamba models\n",
        "#!mamba run -n retriever conda-pack -o /content/drive/MyDrive/mRAG_and_MSRS_source/conda_envs/retriever.tar.gz\n",
        "#!mamba run -n train_and_test conda-pack -o /content/drive/MyDrive/mRAG_and_MSRS_source/conda_envs/train_and_test.tar.gz"
      ],
      "metadata": {
        "id": "WMdP-0znNbPT",
        "collapsed": true
      },
      "id": "WMdP-0znNbPT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!mamba run -n train_and_test pip install conda-pack\n",
        "#!mamba run -n train_and_test conda-pack -o /content/drive/MyDrive/mRAG_and_MSRS_source/conda_envs/train_and_test.tar.gz"
      ],
      "metadata": {
        "id": "GkJtu4ARQ8TA"
      },
      "id": "GkJtu4ARQ8TA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Retrieve cached mamba models"
      ],
      "metadata": {
        "id": "xOgTnP4vNiKx"
      },
      "id": "xOgTnP4vNiKx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ############ MSRS PORTION (https://huggingface.co/datasets/yale-nlp/MSRS)"
      ],
      "metadata": {
        "id": "tDTc5XyZCtwZ"
      },
      "id": "tDTc5XyZCtwZ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Indexing Task 1 (Always Run)"
      ],
      "metadata": {
        "id": "EJ8YRbFEw0H3"
      },
      "id": "EJ8YRbFEw0H3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f179174-9cce-4214-9a7b-af50b0c5803e",
      "metadata": {
        "id": "0f179174-9cce-4214-9a7b-af50b0c5803e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "2ad78b352db24dfa980c18dbf4273bdb",
            "cc8be01e63aa4b7db209bae0ab97c6af",
            "ddfbebc0588746eaba0011e460d65ad6",
            "14e1af12952647fab7e41f4e4a083298",
            "03780aedb72749c78c3bf9777e1df3ab",
            "5633beeb17e24892ba2bea02a263c330",
            "45777d0c16c04bdbb6371343449128de",
            "172543718d9441dd8b60eca6a8feb93a",
            "6a41485fc53e4660a6033b699ee5f3fc",
            "b4e0cc440c824aa8974fa194c496439e",
            "d7329ecc02cb4be2815c378e724941d1",
            "2e31699227d54db18a32e601ebe807a1",
            "021c3ec1ff684d228e547dccd215e641",
            "1b7b29d84faa4c5ab3aa8a698be7b4b7",
            "a7d808a860914b2495bd11bc36a2dd69",
            "de9cd1786ff44e56a907a3f3aa6bc122",
            "acc5f3df32a9454da53c6beccdd9bff5",
            "dd2d6fc045ca4d74b39f963d4d74ed62",
            "949cef931da1446d8d67936bbae0410d",
            "d3abb39ee9944750a3108948ef5beaf3",
            "88dffef9346d4803b6d097eda0ec4af9",
            "e358b218c43d4b35a3d7b5bebb94423b",
            "00f154fffe6c42ec8ec345fc913d3d3c",
            "ceb043e76e444db59a440f19045c16f3",
            "c40ded0841724894b5600e2cd8524227",
            "5417bd40c614486cb0e181e21a737278",
            "71b0159ba5c24c2b99d0714e88aaf5ff",
            "dff9ef3b001b4a53a70ae3eff0bcb7cb",
            "70b69f8ca43a41c8aef4c001c34265fa",
            "8bb4c95b68f8457db7a433d921ab6ad2",
            "173031b77c944f70b5d8f41dc7a978c7",
            "6fd042b3bb86488aa3d7afb45037e74d",
            "a0c7d424fc5a4efd93642501e9cc8e39",
            "8266eb85666c4bf3a12cbccb1da15b24",
            "16b02efa581f405d99569c81ee5f7937",
            "737ecd1593424bd39c36149b069db59c",
            "bc02d3f41983429ab26f0c624771fbcc",
            "340b023546d4412fa9af0866bafa1a0b",
            "08ae6fa641684fd0ac306de1aa8a30a4",
            "95870202f8ad4271bb18ee5a481d304e",
            "435a5445a9284b1d9ffe2f0ec206b8e9",
            "4f7c47e807d546c08d6bed464360ed15",
            "262d84953b864506be66cf270bf847db",
            "de0f33fa7e0145719b11e72b33d4656e",
            "f29cba1f3ef94106a39a75aa4f88d606",
            "794e86e121b74cbab83d2afe9499fd97",
            "3d3b4f1861da42a5a43b6020f5b16860",
            "77536342dc0f4d77b8cad34ecfe02fda",
            "c5989481862f43c1940235b64c796cf4",
            "7d49af1458474403ad3636b9901c6a39",
            "03f9105782c242f5b0de34f226066586",
            "2127c4fa10624ec89a0db2cece5f0169",
            "a22d1795e0524349af104d8a5646aad0",
            "6c7ad5854dd54135a0ff688a5aab878a",
            "7c54759f8b5f4d649fe67c8523ff68d7",
            "498c4afe79d147ce863ec384dc603983",
            "44555aa9bb134d3bb2087f61fe717670",
            "cd5ce2f5214347deaf221efae82d8d6f",
            "c33dd65af2ca4ead907b86eba275672e",
            "181828fd1ca7431c93962aa30e21b600",
            "c84030c227164541b9a9458b486b505b",
            "9e01394d03e14558a41d8d0b583cd385",
            "865c33a3258e43a7bfa7fdf83199a5b4",
            "401ef170d34f421a90c6799aa7bc15b2",
            "5ccdbc5e6caf45b1856e416bcf509210",
            "e69664f152e74c01b557f3a1ccc3f779"
          ]
        },
        "outputId": "fdf053ec-23ae-4f05-9629-314bf4e7cf40",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-4.4.1-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting filelock (from datasets)\n",
            "  Downloading filelock-3.20.0-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting numpy>=1.17 (from datasets)\n",
            "  Downloading numpy-2.3.5-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (62 kB)\n",
            "Collecting pyarrow>=21.0.0 (from datasets)\n",
            "  Downloading pyarrow-22.0.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.2 kB)\n",
            "Collecting dill<0.4.1,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.4.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting pandas (from datasets)\n",
            "  Downloading pandas-2.3.3-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (91 kB)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/site-packages (from datasets) (2.32.3)\n",
            "Collecting httpx<1.0.0 (from datasets)\n",
            "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/site-packages (from datasets) (4.67.1)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.6.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (13 kB)\n",
            "Collecting multiprocess<0.70.19 (from datasets)\n",
            "  Downloading multiprocess-0.70.18-py311-none-any.whl.metadata (7.5 kB)\n",
            "Collecting fsspec<=2025.10.0,>=2023.1.0 (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2025.10.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting huggingface-hub<2.0,>=0.25.0 (from datasets)\n",
            "  Downloading huggingface_hub-1.1.7-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/site-packages (from datasets) (24.2)\n",
            "Collecting pyyaml>=5.1 (from datasets)\n",
            "  Downloading pyyaml-6.0.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.4 kB)\n",
            "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
            "  Downloading aiohttp-3.13.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (8.1 kB)\n",
            "Collecting anyio (from httpx<1.0.0->datasets)\n",
            "  Using cached anyio-4.12.0-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/site-packages (from httpx<1.0.0->datasets) (2024.12.14)\n",
            "Collecting httpcore==1.* (from httpx<1.0.0->datasets)\n",
            "  Using cached httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/site-packages (from httpx<1.0.0->datasets) (3.10)\n",
            "Collecting h11>=0.16 (from httpcore==1.*->httpx<1.0.0->datasets)\n",
            "  Using cached h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
            "Collecting hf-xet<2.0.0,>=1.2.0 (from huggingface-hub<2.0,>=0.25.0->datasets)\n",
            "  Downloading hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting shellingham (from huggingface-hub<2.0,>=0.25.0->datasets)\n",
            "  Using cached shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting typer-slim (from huggingface-hub<2.0,>=0.25.0->datasets)\n",
            "  Downloading typer_slim-0.20.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting typing-extensions>=3.7.4.3 (from huggingface-hub<2.0,>=0.25.0->datasets)\n",
            "  Using cached typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Collecting python-dateutil>=2.8.2 (from pandas->datasets)\n",
            "  Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting pytz>=2020.1 (from pandas->datasets)\n",
            "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting tzdata>=2022.7 (from pandas->datasets)\n",
            "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
            "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting aiosignal>=1.4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
            "  Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting attrs>=17.3.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
            "  Downloading attrs-25.4.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
            "  Downloading frozenlist-1.8.0-cp311-cp311-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (20 kB)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
            "  Downloading multidict-6.7.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.3 kB)\n",
            "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
            "  Downloading propcache-0.4.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (13 kB)\n",
            "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
            "  Downloading yarl-1.22.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (75 kB)\n",
            "Collecting six>=1.5 (from python-dateutil>=2.8.2->pandas->datasets)\n",
            "  Using cached six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting click>=8.0.0 (from typer-slim->huggingface-hub<2.0,>=0.25.0->datasets)\n",
            "  Using cached click-8.3.1-py3-none-any.whl.metadata (2.6 kB)\n",
            "Downloading datasets-4.4.1-py3-none-any.whl (511 kB)\n",
            "Downloading dill-0.4.0-py3-none-any.whl (119 kB)\n",
            "Downloading fsspec-2025.10.0-py3-none-any.whl (200 kB)\n",
            "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
            "Using cached httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
            "Downloading huggingface_hub-1.1.7-py3-none-any.whl (516 kB)\n",
            "Downloading multiprocess-0.70.18-py311-none-any.whl (144 kB)\n",
            "Downloading numpy-2.3.5-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m16.9/16.9 MB\u001b[0m \u001b[31m215.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow-22.0.0-cp311-cp311-manylinux_2_28_x86_64.whl (47.7 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m47.7/47.7 MB\u001b[0m \u001b[31m74.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyyaml-6.0.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (806 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m806.6/806.6 kB\u001b[0m \u001b[31m50.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filelock-3.20.0-py3-none-any.whl (16 kB)\n",
            "Downloading pandas-2.3.3-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (12.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m135.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.6.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (193 kB)\n",
            "Downloading aiohttp-3.13.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m83.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m113.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
            "Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
            "Downloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
            "Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
            "Using cached anyio-4.12.0-py3-none-any.whl (113 kB)\n",
            "Using cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
            "Downloading typer_slim-0.20.0-py3-none-any.whl (47 kB)\n",
            "Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
            "Downloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
            "Downloading attrs-25.4.0-py3-none-any.whl (67 kB)\n",
            "Using cached click-8.3.1-py3-none-any.whl (108 kB)\n",
            "Downloading frozenlist-1.8.0-cp311-cp311-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (231 kB)\n",
            "Using cached h11-0.16.0-py3-none-any.whl (37 kB)\n",
            "Downloading multidict-6.7.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (246 kB)\n",
            "Downloading propcache-0.4.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (210 kB)\n",
            "Using cached six-1.17.0-py2.py3-none-any.whl (11 kB)\n",
            "Downloading yarl-1.22.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (365 kB)\n",
            "Installing collected packages: pytz, xxhash, tzdata, typing-extensions, six, shellingham, pyyaml, pyarrow, propcache, numpy, multidict, hf-xet, h11, fsspec, frozenlist, filelock, dill, click, attrs, aiohappyeyeballs, yarl, typer-slim, python-dateutil, multiprocess, httpcore, anyio, aiosignal, pandas, httpx, aiohttp, huggingface-hub, datasets\n",
            "Successfully installed aiohappyeyeballs-2.6.1 aiohttp-3.13.2 aiosignal-1.4.0 anyio-4.12.0 attrs-25.4.0 click-8.3.1 datasets-4.4.1 dill-0.4.0 filelock-3.20.0 frozenlist-1.8.0 fsspec-2025.10.0 h11-0.16.0 hf-xet-1.2.0 httpcore-1.0.9 httpx-0.28.1 huggingface-hub-1.1.7 multidict-6.7.0 multiprocess-0.70.18 numpy-2.3.5 pandas-2.3.3 propcache-0.4.1 pyarrow-22.0.0 python-dateutil-2.9.0.post0 pytz-2025.2 pyyaml-6.0.3 shellingham-1.5.4 six-1.17.0 typer-slim-0.20.0 typing-extensions-4.15.0 tzdata-2025.2 xxhash-3.6.0 yarl-1.22.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "dateutil",
                  "numpy",
                  "six"
                ]
              },
              "id": "5ab29bc932d6467b8b22207206b95406"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2ad78b352db24dfa980c18dbf4273bdb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "corpus.jsonl: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2e31699227d54db18a32e601ebe807a1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating corpus split:   0%|          | 0/1138 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "00f154fffe6c42ec8ec345fc913d3d3c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "corpus.jsonl: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8266eb85666c4bf3a12cbccb1da15b24"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating corpus split:   0%|          | 0/231 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f29cba1f3ef94106a39a75aa4f88d606"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'datasets.arrow_dataset.Dataset'>\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Creating json from Arrow format:   0%|          | 0/2 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "498c4afe79d147ce863ec384dc603983"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['story_corpus.jsonl']\n"
          ]
        }
      ],
      "source": [
        "######## In place of using datamorgana using MSRS Benchmark\n",
        "######## due to proprietary nature of datamorgana.\n",
        "######## Gold answers in MSRS paper are groundtruth answers\n",
        "######## morphing MSRS set/benchmark to be similar in format to datamorgana set/benchmark\n",
        "\n",
        "\n",
        "!pip install datasets\n",
        "import pickle\n",
        "\n",
        "from datasets import load_dataset\n",
        "\n",
        "story_corpus = load_dataset(\"yale-nlp/MSRS\", \"story-corpus\", split=\"corpus\")\n",
        "\n",
        "#for use in the retriever_setup code in mRAG app, needs a doc_ids pickle\n",
        "doc_ids = [row[\"id\"] for row in story_corpus]\n",
        "with open(os.path.join(\"/content/drive/MyDrive/mRAG_and_MSRS_source/index\", \"doc_ids.pkl\"), \"wb\") as f:\n",
        "    pickle.dump(doc_ids, f)\n",
        "\n",
        "\n",
        "meeting_corpus = load_dataset(\"yale-nlp/MSRS\", \"meeting-corpus\", split=\"corpus\")\n",
        "'''\n",
        "this is a list of corpus'\n",
        "{\n",
        "    \"id\": // Unique ID for the document\n",
        "    \"text\": // Document text\n",
        "}\n",
        "'''\n",
        "\n",
        "\n",
        "print(type(story_corpus))\n",
        "#'contents' is expected instead of 'text' by pyserini basic indexer so rename that field\n",
        "\n",
        "story_corpus = story_corpus.rename_columns({\"text\": \"contents\"})\n",
        "\n",
        "#Any necessary preprocessing?\n",
        "\n",
        "#exporting the corpus to jsonl\n",
        "story_corpus.to_json(jsonl_dir+\"/story_corpus.jsonl\", lines=True)\n",
        "\n",
        "print(os.listdir(jsonl_dir))\n",
        "#meeting_corpus.to_json(\"./jsonl_collections/meeting_corpus.jsonl\", lines=True)\n",
        "\n",
        "#story_corpus.to_json(data_path + \"/story_corpus.jsonl\", lines=True)\n",
        "#meeting_corpus.to_json(data_path + \"/meeting_corpus.jsonl\", lines=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print(len(story_qa))\n",
        "# print(len(list(story_qa)))\n",
        "# print(story_qa)\n",
        "\n",
        "# print(story_qa['train'])\n",
        "# print(story_qa['test'])\n",
        "\n",
        "print(len(story_corpus))\n",
        "print(story_corpus)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1oNVXlOxuQR",
        "outputId": "ea0fe717-b25d-4fa8-c65e-44cf38858c05"
      },
      "id": "b1oNVXlOxuQR",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1138\n",
            "Dataset({\n",
            "    features: ['id', 'contents'],\n",
            "    num_rows: 1138\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chunking Corpus (to tokens rather than what was done in Assignment 1)\n",
        "# NOTE: retriever_setup app in the repository is to setup retriever, but is mostly to facilitate the SparseRetriever model, BM25Retriever just functions off of an index"
      ],
      "metadata": {
        "id": "B_ewW1jymAZ1"
      },
      "id": "B_ewW1jymAZ1"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Changes to files:\n",
        "#retriever_setup/fine_web_chunking.py\n",
        "#retreiver_setup/constants.py\n",
        "#retrieval/retrievers.py ( for BM25 changed referenced index and the format of #output)\n"
      ],
      "metadata": {
        "id": "C47z-5BYwxec"
      },
      "id": "C47z-5BYwxec"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Because BM25 is hardcoded to reference an index, need to generate that using MSRS Corpus"
      ],
      "metadata": {
        "id": "KBmGro04z8Wk"
      },
      "id": "KBmGro04z8Wk"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Indexing Task 2"
      ],
      "metadata": {
        "id": "7HGhebO9w68H"
      },
      "id": "7HGhebO9w68H"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3d8AEs2XrBqa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6440fedb-c494-4b91-9d84-c3872597bf0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E: Failed to fetch http://security.ubuntu.com/ubuntu/pool/universe/o/openjdk-21/openjdk-21-jre-headless_21.0.8%2b9%7eus1-0ubuntu1%7e22.04.1_amd64.deb  404  Not Found [IP: 91.189.92.23 80]\n",
            "E: Failed to fetch http://security.ubuntu.com/ubuntu/pool/universe/o/openjdk-21/openjdk-21-jdk-headless_21.0.8%2b9%7eus1-0ubuntu1%7e22.04.1_amd64.deb  404  Not Found [IP: 91.189.92.23 80]\n",
            "E: Unable to fetch some archives, maybe run apt-get update or try with --fix-missing?\n",
            "update-alternatives: error: alternative /usr/lib/jvm/java-21-openjdk-amd64/jre/bin/java for java not registered; not setting\n",
            "openjdk version \"17.0.16\" 2025-07-15\n",
            "OpenJDK Runtime Environment (build 17.0.16+8-Ubuntu-0ubuntu122.04.1)\n",
            "OpenJDK 64-Bit Server VM (build 17.0.16+8-Ubuntu-0ubuntu122.04.1, mixed mode, sharing)\n"
          ]
        }
      ],
      "source": [
        "# ### Pyserini require updating java version ###\n",
        "# !apt-get install openjdk-21-jdk-headless -qq > /dev/null\n",
        "# os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-21-openjdk-amd64\"\n",
        "# !update-alternatives --set java /usr/lib/jvm/java-21-openjdk-amd64/jre/bin/java\n",
        "# !java -version\n",
        "\n",
        "\n",
        "# #!pip install pyserini"
      ],
      "id": "3d8AEs2XrBqa"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# 1. Refresh the package list (Crucial step to fix 404 errors)\n",
        "print(\"Updating package lists...\")\n",
        "!apt-get update > /dev/null\n",
        "\n",
        "# 2. Install Java 21 (with --fix-missing to handle connection hiccups)\n",
        "print(\"Installing Java 21...\")\n",
        "!apt-get install -y openjdk-21-jdk-headless --fix-missing > /dev/null\n",
        "\n",
        "# 3. Verify the installation\n",
        "print(\"Verifying installation...\")\n",
        "!java -version\n",
        "\n",
        "# 4. Set the Environment Variables for THIS Python session\n",
        "# (This tells Pyserini exactly where the new Java is)\n",
        "java_home = \"/usr/lib/jvm/java-21-openjdk-amd64\"\n",
        "os.environ[\"JAVA_HOME\"] = java_home\n",
        "os.environ[\"JVM_PATH\"] = f\"{java_home}/lib/server/libjvm.so\"\n",
        "\n",
        "print(f\"\\nSUCCESS: JAVA_HOME set to {os.environ['JAVA_HOME']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4cipootf2luU",
        "outputId": "2ba8424f-a664-48ed-da14-cb01abb6b4eb"
      },
      "id": "4cipootf2luU",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updating package lists...\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Installing Java 21...\n",
            "Verifying installation...\n",
            "openjdk version \"21.0.9\" 2025-10-21\n",
            "OpenJDK Runtime Environment (build 21.0.9+10-Ubuntu-122.04)\n",
            "OpenJDK 64-Bit Server VM (build 21.0.9+10-Ubuntu-122.04, mixed mode, sharing)\n",
            "\n",
            "SUCCESS: JAVA_HOME set to /usr/lib/jvm/java-21-openjdk-amd64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(os.listdir(index_dir))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVIBv0SMqjzu",
        "outputId": "10ae8229-ce74-48b6-b4da-b0cdaaef4559"
      },
      "id": "HVIBv0SMqjzu",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['write.lock', '_2.nvd', '_2.nvm', '_2_Lucene90_0.dvd', '_2_Lucene90_0.dvm', '_2.fdx', '_2.fdm', '_2.fdt', '_2.tvx', '_2.tvm', '_2.tvd', '_2_Lucene99_0.tmd', '_2_Lucene99_0.tim', '_2_Lucene99_0.tip', '_2_Lucene99_0.doc', '_2_Lucene99_0.pos', '_2.fnm', '_2.si', 'segments_3', 'doc_ids.pkl']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Indexing Task 3"
      ],
      "metadata": {
        "id": "8qf6lNuKw87X"
      },
      "id": "8qf6lNuKw87X"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZyJL3WXZyY22",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3cf17d9-1d75-4385-e5b4-e66150dfeb84",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "index folder is not empty, found processed files.\n"
          ]
        }
      ],
      "source": [
        "if os.path.isdir(index_dir) and os.listdir(index_dir):\n",
        "    print('index folder is not empty, found processed files.')\n",
        "else:\n",
        "    # Call the Pyserini indexer function here\n",
        "    #for jsonl_file in os.listdir(jsonl_dir):\n",
        "    !python -m pyserini.index.lucene --collection JsonCollection --input {jsonl_dir} --index {index_dir} --generator DefaultLuceneDocumentGenerator --threads 8 --storePositions --storeDocvectors --storeRaw\n"
      ],
      "id": "ZyJL3WXZyY22"
    },
    {
      "cell_type": "markdown",
      "source": [
        "NOTE: number of documents significantly small in MSRS-Story (1138), will step this up using hotpotqa dataset in another test"
      ],
      "metadata": {
        "id": "HXPIRivQqqUi"
      },
      "id": "HXPIRivQqqUi"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Creating Chunks(Pre-processing) Conforms to size and overlap in fine_web_chunking.py"
      ],
      "metadata": {
        "id": "T2JKDF6O_PJ5"
      },
      "id": "T2JKDF6O_PJ5"
    },
    {
      "cell_type": "code",
      "source": [
        "#Pre-processed chunking, file required in sparse_retrieval_cpu.py script\n",
        "\n",
        "#Question: what is the relevance of chunk size and overlap to size of text?\n",
        "\n",
        "#NOTE: chunk sizes match those specified in fine_web_chunking.py SentenceSplitter\n",
        "def make_chunks(text, max_words=512, overlap=80):\n",
        "    if not text:\n",
        "        return\n",
        "    words = text.split()\n",
        "    step = max_words - overlap\n",
        "    if step <= 0:\n",
        "        step = max_words\n",
        "    for i in range(0, len(words), step):\n",
        "        yield \" \".join(words[i:i+max_words])\n",
        "\n",
        "out_path = \"/content/drive/MyDrive/mRAG_and_MSRS_source/chunked_data/story_corpus_chunked.jsonl\"\n",
        "with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    for row in story_corpus:\n",
        "        doc_id = row[\"id\"]\n",
        "        text = row[\"contents\"]\n",
        "        for j, chunk in enumerate(make_chunks(text)):\n",
        "            rec = {\n",
        "                \"chunk_id\": f\"{doc_id}#{j}\",\n",
        "                \"contents\": chunk\n",
        "            }\n",
        "            f.write(json.dumps(rec, ensure_ascii=False) + \"\\n\")"
      ],
      "metadata": {
        "id": "JjXBa5M08Kvo"
      },
      "id": "JjXBa5M08Kvo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "#for use in the retriever_setup code in mRAG app, needs a doc_ids pickle\n",
        "doc_ids = [row[\"id\"] for row in story_corpus]\n",
        "with open(os.path.join(\"/content/drive/MyDrive/mRAG_and_MSRS_source/index\", \"doc_ids.pkl\"), \"wb\") as f:\n",
        "    pickle.dump(doc_ids, f)"
      ],
      "metadata": {
        "id": "-1aQVr5D2u36"
      },
      "id": "-1aQVr5D2u36",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ############# mRAG PORTION (https://github.com/muktac5/CIIR-LiveRAG/tree/main)"
      ],
      "metadata": {
        "id": "Rw_dPlzYCxTJ"
      },
      "id": "Rw_dPlzYCxTJ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  SERVER INITIALIZATION, hosted on 127.0.0.1, localhost ################"
      ],
      "metadata": {
        "id": "f63a7abc-593e-445b-99a6-dad8a2b054fb"
      },
      "id": "f63a7abc-593e-445b-99a6-dad8a2b054fb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58117c48-40ea-4964-97d4-1e05accef839",
      "metadata": {
        "id": "58117c48-40ea-4964-97d4-1e05accef839"
      },
      "outputs": [],
      "source": [
        "######### Start the Retriever server  ( pure CPU )\n",
        "######### Initially Retrievesd from FineWeb Dataset, Modified to retrieve from MSRS Corpus"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#huggingface access token\n",
        "\n",
        "added to files:\n",
        "\n",
        "./retriever_setup/eval_sparse.py\n",
        "./retriever_setup/scaling_retriever/modeling/llm_encoder.py\n",
        "\n",
        "\n",
        "#from huggingface_hub import login\n",
        "\n",
        "\n",
        "Reason for providing token : Is this because for sparse retriever requires llama2 and llama2 requires user license agreement"
      ],
      "metadata": {
        "id": "IXLuwg-iYmSw"
      },
      "id": "IXLuwg-iYmSw"
    },
    {
      "cell_type": "code",
      "source": [
        "######################################################"
      ],
      "metadata": {
        "id": "jA3dzcBFCxP0"
      },
      "id": "jA3dzcBFCxP0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "When"
      ],
      "metadata": {
        "id": "TXsV-KeDCyN0"
      },
      "id": "TXsV-KeDCyN0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e95dc05-0d2e-4d28-9182-cafa6a5850d9",
      "metadata": {
        "id": "0e95dc05-0d2e-4d28-9182-cafa6a5850d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb56a960-d55d-40a6-ce17-ba51f4c4937d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5920\n"
          ]
        }
      ],
      "source": [
        "# #UPDATE: made comment in sparse_retrieval_cpu.py to enforce 'cpu' use to conserve cuda for other models:\n",
        "# #device = \"cpu\"\n",
        "\n",
        "# !echo \"127.0.0.1\" > /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_log/retriever.log\n",
        "# !echo \"8000\" >> /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_log/retriever.log\n",
        "\n",
        "\n",
        "# #nohup is necessary to run in the background and have other cells as well(nonblocking)\n",
        "\n",
        "# !PYTHONPATH=/content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup \\\n",
        "#   nohup mamba run -n retriever uvicorn \\\n",
        "#   --app-dir /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_setup \\\n",
        "#   sparse_retrieval_cpu:app --host 127.0.0.1 --port 8000 \\\n",
        "#   >> /content/drive/MyDrive/mRAG_and_MSRS_source/retriever_log/retriever.log 2>&1 & echo $!\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Reclaim retriever server memory\n",
        "# !pkill uvicorn"
      ],
      "metadata": {
        "id": "57LZX-TsbtwB"
      },
      "id": "57LZX-TsbtwB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pkill -9 uvicorn\n"
      ],
      "metadata": {
        "id": "tSTQu7wagZ2T"
      },
      "id": "tSTQu7wagZ2T",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "######### Kill the Retriever server"
      ],
      "metadata": {
        "id": "aw1E7q3zxlmI"
      },
      "id": "aw1E7q3zxlmI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #killing the retriever\n",
        "# !kill -TERM 35084\n",
        "# #close the associated port\n",
        "# !fuser -k 8000/tcp"
      ],
      "metadata": {
        "id": "MD6HSylFv6_i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "501decd8-9176-4c7d-c206-90b88cf2f450"
      },
      "id": "MD6HSylFv6_i",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: kill: (35084) - No such process\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# #NOTE: the cell output seems to be a lowball, but might be true, these are in kilobytes\n",
        "\n",
        "# #NOTE: in reality seems like it takes more\n",
        "# #5.2GB is the estimate from jump\n",
        "\n",
        "# #resources stats for launched process(vram)\n",
        "# !ps -p 30584 -o pid,ppid,cmd,%mem,rss,vsz\n",
        "# #Uses 9.5GB on the GPU, but was supposed to use CPU right?\n",
        "# #Uses a little bit of ram"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2C3_v05Bz9bj",
        "outputId": "edee6ea6-fa3a-41c6-c1f0-39eee1080459"
      },
      "id": "2C3_v05Bz9bj",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    PID    PPID CMD                         %MEM   RSS    VSZ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5959631f-d084-4313-91c2-38829978a483",
      "metadata": {
        "id": "5959631f-d084-4313-91c2-38829978a483"
      },
      "outputs": [],
      "source": [
        "######### Start the Agent server"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fda999bf-63c7-4495-9d7a-6cf3abc104d1",
      "metadata": {
        "id": "fda999bf-63c7-4495-9d7a-6cf3abc104d1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6cc4ceef-5a0f-4c82-af95-90ba0096d7b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12367\n"
          ]
        }
      ],
      "source": [
        "#NOTE: attempting to limit system ram with --swap-space 0 or --swap-space 1 causes crash\n",
        "#0.5 works for gpu memory utilization, but\n",
        "\n",
        "!echo \"127.0.0.1\" > /content/drive/MyDrive/mRAG_and_MSRS_source/agent_server_log/agent.log\n",
        "!echo \"8100\" >> /content/drive/MyDrive/mRAG_and_MSRS_source/agent_server_log/agent.log\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#NOTE: shrinking context and kv cache datatype 16->8 allows for fitting in a smaller portion of the gpu, aka, .15 of the gpu\n",
        "# takes time for the model to get loaded into the gpu\n",
        "\n",
        "!PYTHONPATH=/content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training \\\n",
        "  VLLM_LOGGING_LEVEL=INFO\\\n",
        "  nohup mamba run -n train_and_test vllm serve \"Qwen/Qwen2.5-7B-Instruct-GPTQ-Int4\" --host 127.0.0.1 --port 8100 --uvicorn-log-level info  --download_dir /content/drive/MyDrive/mRAG_and_MSRS_source/vllm_cache --gpu-memory-utilization 0.75 --swap-space 0 --enforce-eager  \\\n",
        "  >> /content/drive/MyDrive/mRAG_and_MSRS_source/agent_server_log/agent_runtime.log 2>&1 & echo $!"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pkill vllm"
      ],
      "metadata": {
        "id": "5UWR-X3ouMdv"
      },
      "id": "5UWR-X3ouMdv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %%bash\n",
        "# set -euo pipefail\n",
        "# mkdir -p /content/drive/MyDrive/mRAG_and_MSRS_source/agent_server_log\n",
        "\n",
        "# # discovery file (2 lines host/port)\n",
        "# printf \"127.0.0.1\\n8100\\n\" > /content/drive/MyDrive/mRAG_and_MSRS_source/agent_server_log/agent.log\n",
        "\n",
        "# # runtime log\n",
        "# RLOG=/content/drive/MyDrive/mRAG_and_MSRS_source/agent_server_log/agent_runtime.log\n",
        "# : > \"$RLOG\"\n",
        "\n",
        "# export PYTHONPATH=/content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training\n",
        "# export VLLM_LOGGING_LEVEL=INFO\n",
        "\n",
        "# nohup mamba run -n train_and_test vllm serve \"Qwen/Qwen2.5-0.5B-Instruct-GPTQ-Int4\" \\\n",
        "#   --host 127.0.0.1 --port 8100 \\\n",
        "#   --uvicorn-log-level info \\\n",
        "#   --download_dir /content/drive/MyDrive/mRAG_and_MSRS_source/vllm_cache \\\n",
        "#   --gpu-memory-utilization 0.15 \\\n",
        "#   --max-model-len 10240 --swap-space 0 --enforce-eager \\\n",
        "#   >> \"$RLOG\" 2>&1 & echo $!"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kAKKTGeTPRHs",
        "outputId": "f62d4ca5-9086-457b-b296-915f675f7c3a"
      },
      "id": "kAKKTGeTPRHs",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6014\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -s http://127.0.0.1:8100/v1/models | jq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nOS7aUBzEKaa",
        "outputId": "67ce92c3-cbcf-4e1b-aa92-53c855590c05"
      },
      "id": "nOS7aUBzEKaa",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "curl: /usr/local/lib/libcurl.so.4: no version information available (required by curl)\n",
            "\u001b[1;39m{\n",
            "  \u001b[0m\u001b[34;1m\"object\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"list\"\u001b[0m\u001b[1;39m,\n",
            "  \u001b[0m\u001b[34;1m\"data\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m[\n",
            "    \u001b[1;39m{\n",
            "      \u001b[0m\u001b[34;1m\"id\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"Qwen/Qwen2.5-3B-Instruct-GPTQ-Int4\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"object\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"model\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"created\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m1764707027\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"owned_by\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"vllm\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"root\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"Qwen/Qwen2.5-3B-Instruct-GPTQ-Int4\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"parent\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;30mnull\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"max_model_len\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m10240\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"permission\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m[\n",
            "        \u001b[1;39m{\n",
            "          \u001b[0m\u001b[34;1m\"id\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"modelperm-a35e0f6af89d41b482b6ccbdf2f5afbb\"\u001b[0m\u001b[1;39m,\n",
            "          \u001b[0m\u001b[34;1m\"object\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"model_permission\"\u001b[0m\u001b[1;39m,\n",
            "          \u001b[0m\u001b[34;1m\"created\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m1764707027\u001b[0m\u001b[1;39m,\n",
            "          \u001b[0m\u001b[34;1m\"allow_create_engine\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39mfalse\u001b[0m\u001b[1;39m,\n",
            "          \u001b[0m\u001b[34;1m\"allow_sampling\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39mtrue\u001b[0m\u001b[1;39m,\n",
            "          \u001b[0m\u001b[34;1m\"allow_logprobs\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39mtrue\u001b[0m\u001b[1;39m,\n",
            "          \u001b[0m\u001b[34;1m\"allow_search_indices\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39mfalse\u001b[0m\u001b[1;39m,\n",
            "          \u001b[0m\u001b[34;1m\"allow_view\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39mtrue\u001b[0m\u001b[1;39m,\n",
            "          \u001b[0m\u001b[34;1m\"allow_fine_tuning\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39mfalse\u001b[0m\u001b[1;39m,\n",
            "          \u001b[0m\u001b[34;1m\"organization\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"*\"\u001b[0m\u001b[1;39m,\n",
            "          \u001b[0m\u001b[34;1m\"group\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;30mnull\u001b[0m\u001b[1;39m,\n",
            "          \u001b[0m\u001b[34;1m\"is_blocking\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39mfalse\u001b[0m\u001b[1;39m\n",
            "        \u001b[1;39m}\u001b[0m\u001b[1;39m\n",
            "      \u001b[1;39m]\u001b[0m\u001b[1;39m\n",
            "    \u001b[1;39m}\u001b[0m\u001b[1;39m\n",
            "  \u001b[1;39m]\u001b[0m\u001b[1;39m\n",
            "\u001b[1;39m}\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ps -ef | grep vllm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-MMgIT1Pf9Nl",
        "outputId": "34b1eb89-d229-4452-c12c-ed59c5fd8d01"
      },
      "id": "-MMgIT1Pf9Nl",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root       12367       1  0 20:20 ?        00:00:00 /usr/local/bin/python /usr/local/bin/mamba run -n train_and_test vllm serve Qwen/Qwen2.5-3B-Instruct-GPTQ-Int4 --host 127.0.0.1 --port 8100 --uvicorn-log-level info --download_dir /content/drive/MyDrive/mRAG_and_MSRS_source/vllm_cache --gpu-memory-utilization 0.75 --max-model-len 10240 --swap-space 0 --enforce-eager\n",
            "root       12387   12372  3 20:20 ?        00:00:09 /usr/local/envs/train_and_test/bin/python3.11 /usr/local/envs/train_and_test/bin/vllm serve Qwen/Qwen2.5-3B-Instruct-GPTQ-Int4 --host 127.0.0.1 --port 8100 --uvicorn-log-level info --download_dir /content/drive/MyDrive/mRAG_and_MSRS_source/vllm_cache --gpu-memory-utilization 0.75 --max-model-len 10240 --swap-space 0 --enforce-eager\n",
            "root       13510    1998  0 20:24 ?        00:00:00 /bin/bash -c ps -ef | grep vllm\n",
            "root       13512   13510  0 20:24 ?        00:00:00 grep vllm\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Example access to server using api"
      ],
      "metadata": {
        "id": "kGd8iiA8SWxs"
      },
      "id": "kGd8iiA8SWxs"
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "resp = requests.post(\n",
        "    \"http://127.0.0.1:8100/v1/chat/completions\",\n",
        "    json={\n",
        "        \"model\": \"Qwen/Qwen2.5-7B-Instruct-GPTQ-Int4\",\n",
        "        \"messages\": [{\"role\":\"user\",\"content\":\"Write a paragraph about books\"}],\n",
        "        \"temperature\": 0.2,\n",
        "        \"max_tokens\": 256,\n",
        "    },\n",
        "    timeout=60,\n",
        ")\n",
        "print(resp.json()[\"choices\"][0][\"message\"][\"content\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RMncWdngQX9F",
        "outputId": "59fdf182-cf32-4d30-ea2b-c2067e7a41bf"
      },
      "id": "RMncWdngQX9F",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Books are the gateways to the infinite realms of human knowledge and imagination. They are not merely collections of words on pages; they are windows into the lives and minds of authors, chronicling their experiences, thoughts, and emotions. Through the pages of books, readers can embark on journeys to distant lands and times, experiencing the joys and sorrows of their characters. Books are the carriers of cultural heritage, preserving the wisdom, myths, and histories of past civilizations. They also serve as the medium for personal growth, offering insights into the human condition and the complexities of the world. Whether they are novels, biographies, science fiction, or philosophical treatises, books continue to be a vital part of our cultural and intellectual landscape, inspiring, educating, and entertaining us.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tail -n 50 /content/drive/MyDrive/mRAG_and_MSRS_source/agent_server_log/agent_runtime.log"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_sARQSH1dvOP",
        "outputId": "c5785ff5-fb0c-4057-ab93-c3a25eab370d",
        "collapsed": true
      },
      "id": "_sARQSH1dvOP",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO 12-02 20:18:25 api_server.py:912] vLLM API server version 0.7.3\n",
            "INFO 12-02 20:18:25 api_server.py:913] args: Namespace(subparser='serve', model_tag='Qwen/Qwen2.5-3B-Instruct-GPTQ-Int4', config='', host='127.0.0.1', port=8100, uvicorn_log_level='info', allow_credentials=False, allowed_origins=['*'], allowed_methods=['*'], allowed_headers=['*'], api_key=None, lora_modules=None, prompt_adapters=None, chat_template=None, chat_template_content_format='auto', response_role='assistant', ssl_keyfile=None, ssl_certfile=None, ssl_ca_certs=None, ssl_cert_reqs=0, root_path=None, middleware=[], return_tokens_as_token_ids=False, disable_frontend_multiprocessing=False, enable_request_id_headers=False, enable_auto_tool_choice=False, enable_reasoning=False, reasoning_parser=None, tool_call_parser=None, tool_parser_plugin='', model='Qwen/Qwen2.5-3B-Instruct-GPTQ-Int4', task='auto', tokenizer=None, skip_tokenizer_init=False, revision=None, code_revision=None, tokenizer_revision=None, tokenizer_mode='auto', trust_remote_code=False, allowed_local_media_path=None, download_dir='/content/drive/MyDrive/mRAG_and_MSRS_source/vllm_cache', load_format='auto', config_format=<ConfigFormat.AUTO: 'auto'>, dtype='auto', kv_cache_dtype='auto', max_model_len=10240, guided_decoding_backend='xgrammar', logits_processor_pattern=None, model_impl='auto', distributed_executor_backend=None, pipeline_parallel_size=1, tensor_parallel_size=1, max_parallel_loading_workers=None, ray_workers_use_nsight=False, block_size=None, enable_prefix_caching=None, disable_sliding_window=False, use_v2_block_manager=True, num_lookahead_slots=0, seed=0, swap_space=0.0, cpu_offload_gb=0, gpu_memory_utilization=0.9, num_gpu_blocks_override=None, max_num_batched_tokens=None, max_num_partial_prefills=1, max_long_partial_prefills=1, long_prefill_token_threshold=0, max_num_seqs=None, max_logprobs=20, disable_log_stats=False, quantization=None, rope_scaling=None, rope_theta=None, hf_overrides=None, enforce_eager=True, max_seq_len_to_capture=8192, disable_custom_all_reduce=False, tokenizer_pool_size=0, tokenizer_pool_type='ray', tokenizer_pool_extra_config=None, limit_mm_per_prompt=None, mm_processor_kwargs=None, disable_mm_preprocessor_cache=False, enable_lora=False, enable_lora_bias=False, max_loras=1, max_lora_rank=16, lora_extra_vocab_size=256, lora_dtype='auto', long_lora_scaling_factors=None, max_cpu_loras=None, fully_sharded_loras=False, enable_prompt_adapter=False, max_prompt_adapters=1, max_prompt_adapter_token=0, device='auto', num_scheduler_steps=1, multi_step_stream_outputs=True, scheduler_delay_factor=0.0, enable_chunked_prefill=None, speculative_model=None, speculative_model_quantization=None, num_speculative_tokens=None, speculative_disable_mqa_scorer=False, speculative_draft_tensor_parallel_size=None, speculative_max_model_len=None, speculative_disable_by_batch_size=None, ngram_prompt_lookup_max=None, ngram_prompt_lookup_min=None, spec_decoding_acceptance_method='rejection_sampler', typical_acceptance_sampler_posterior_threshold=None, typical_acceptance_sampler_posterior_alpha=None, disable_logprobs_during_spec_decoding=None, model_loader_extra_config=None, ignore_patterns=[], preemption_mode=None, served_model_name=None, qlora_adapter_name_or_path=None, otlp_traces_endpoint=None, collect_detailed_traces=None, disable_async_output_proc=False, scheduling_policy='fcfs', scheduler_cls='vllm.core.scheduler.Scheduler', override_neuron_config=None, override_pooler_config=None, compilation_config=None, kv_transfer_config=None, worker_cls='auto', generation_config=None, override_generation_config=None, enable_sleep_mode=False, calculate_kv_scales=False, additional_config=None, disable_log_requests=False, max_log_len=None, disable_fastapi_docs=False, enable_prompt_tokens_details=False, dispatch_function=<function ServeSubcommand.cmd at 0x7ef1e855e5c0>)\n",
            "INFO 12-02 20:18:25 api_server.py:209] Started engine process with PID 11719\n",
            "INFO 12-02 20:18:36 __init__.py:207] Automatically detected platform cuda.\n",
            "INFO 12-02 20:18:40 config.py:549] This model supports multiple tasks: {'generate', 'reward', 'classify', 'embed', 'score'}. Defaulting to 'generate'.\n",
            "WARNING 12-02 20:18:41 config.py:628] gptq quantization is not fully optimized yet. The speed can be slower than non-quantized models.\n",
            "WARNING 12-02 20:18:41 cuda.py:95] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used\n",
            "WARNING 12-02 20:18:41 config.py:685] Async output processing is not supported on the current platform type cuda.\n",
            "INFO 12-02 20:18:47 config.py:549] This model supports multiple tasks: {'classify', 'score', 'reward', 'embed', 'generate'}. Defaulting to 'generate'.\n",
            "WARNING 12-02 20:18:49 config.py:628] gptq quantization is not fully optimized yet. The speed can be slower than non-quantized models.\n",
            "WARNING 12-02 20:18:49 cuda.py:95] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used\n",
            "WARNING 12-02 20:18:49 config.py:685] Async output processing is not supported on the current platform type cuda.\n",
            "INFO 12-02 20:18:49 llm_engine.py:234] Initializing a V0 LLM engine (v0.7.3) with config: model='Qwen/Qwen2.5-3B-Instruct-GPTQ-Int4', speculative_config=None, tokenizer='Qwen/Qwen2.5-3B-Instruct-GPTQ-Int4', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=10240, download_dir='/content/drive/MyDrive/mRAG_and_MSRS_source/vllm_cache', load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=gptq, enforce_eager=True, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=Qwen/Qwen2.5-3B-Instruct-GPTQ-Int4, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=False, chunked_prefill_enabled=False, use_async_output_proc=False, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={\"splitting_ops\":[],\"compile_sizes\":[],\"cudagraph_capture_sizes\":[],\"max_capture_size\":0}, use_cached_outputs=True, \n",
            "INFO 12-02 20:18:50 cuda.py:178] Cannot use FlashAttention-2 backend for Volta and Turing GPUs.\n",
            "INFO 12-02 20:18:50 cuda.py:226] Using XFormers backend.\n",
            "INFO 12-02 20:18:50 model_runner.py:1110] Starting to load model Qwen/Qwen2.5-3B-Instruct-GPTQ-Int4...\n",
            "INFO 12-02 20:18:51 weight_utils.py:254] Using model weights format ['*.safetensors']\n",
            "INFO 12-02 20:18:52 weight_utils.py:304] No model.safetensors.index.json found in remote.\n",
            "INFO 12-02 20:18:55 model_runner.py:1115] Loading model weights took 1.9536 GB\n",
            "INFO 12-02 20:18:59 worker.py:267] Memory profiling takes 3.45 seconds\n",
            "INFO 12-02 20:18:59 worker.py:267] the current vLLM instance can use total_gpu_memory (14.74GiB) x gpu_memory_utilization (0.90) = 13.27GiB\n",
            "INFO 12-02 20:18:59 worker.py:267] model weights take 1.95GiB; non_torch_memory takes 0.05GiB; PyTorch activation peak memory takes 1.42GiB; the rest of the memory reserved for KV Cache is 9.84GiB.\n",
            "INFO 12-02 20:18:59 executor_base.py:111] # cuda blocks: 17913, # CPU blocks: 0\n",
            "INFO 12-02 20:18:59 executor_base.py:116] Maximum concurrency for 10240 tokens per request: 27.99x\n",
            "INFO 12-02 20:18:59 llm_engine.py:436] init engine (profile, create kv cache, warmup model) took 4.01 seconds\n",
            "INFO 12-02 20:18:59 api_server.py:958] Starting vLLM API server on http://127.0.0.1:8100\n",
            "INFO 12-02 20:18:59 launcher.py:23] Available routes are:\n",
            "INFO 12-02 20:18:59 launcher.py:31] Route: /openapi.json, Methods: HEAD, GET\n",
            "INFO 12-02 20:18:59 launcher.py:31] Route: /docs, Methods: HEAD, GET\n",
            "INFO 12-02 20:18:59 launcher.py:31] Route: /docs/oauth2-redirect, Methods: HEAD, GET\n",
            "INFO 12-02 20:18:59 launcher.py:31] Route: /redoc, Methods: HEAD, GET\n",
            "INFO 12-02 20:18:59 launcher.py:31] Route: /health, Methods: GET\n",
            "INFO 12-02 20:18:59 launcher.py:31] Route: /ping, Methods: GET, POST\n",
            "INFO 12-02 20:18:59 launcher.py:31] Route: /tokenize, Methods: POST\n",
            "INFO 12-02 20:18:59 launcher.py:31] Route: /detokenize, Methods: POST\n",
            "INFO 12-02 20:18:59 launcher.py:31] Route: /v1/models, Methods: GET\n",
            "INFO 12-02 20:18:59 launcher.py:31] Route: /version, Methods: GET\n",
            "INFO 12-02 20:18:59 launcher.py:31] Route: /v1/chat/completions, Methods: POST\n",
            "INFO 12-02 20:18:59 launcher.py:31] Route: /v1/completions, Methods: POST\n",
            "INFO 12-02 20:18:59 launcher.py:31] Route: /v1/embeddings, Methods: POST\n",
            "INFO 12-02 20:18:59 launcher.py:31] Route: /pooling, Methods: POST\n",
            "INFO 12-02 20:18:59 launcher.py:31] Route: /score, Methods: POST\n",
            "INFO 12-02 20:18:59 launcher.py:31] Route: /v1/score, Methods: POST\n",
            "INFO 12-02 20:18:59 launcher.py:31] Route: /v1/audio/transcriptions, Methods: POST\n",
            "INFO 12-02 20:18:59 launcher.py:31] Route: /rerank, Methods: POST\n",
            "INFO 12-02 20:18:59 launcher.py:31] Route: /v1/rerank, Methods: POST\n",
            "INFO 12-02 20:18:59 launcher.py:31] Route: /v2/rerank, Methods: POST\n",
            "INFO 12-02 20:18:59 launcher.py:31] Route: /invocations, Methods: POST\n",
            "INFO 12-02 20:20:21 launcher.py:62] Shutting down FastAPI HTTP server.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "######### Kill the Agent server"
      ],
      "metadata": {
        "id": "VK02IPe5xcBB"
      },
      "id": "VK02IPe5xcBB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#kill the agent server\n",
        "!kill -TERM 8932\n",
        "!fuser -k 8100/tcp"
      ],
      "metadata": {
        "id": "0RgnXTAlw6PS"
      },
      "id": "0RgnXTAlw6PS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mamba run -n train_and_test python -c 'import torch; torch.cuda.empty_cache()'"
      ],
      "metadata": {
        "id": "EswlPQjqH-Qr"
      },
      "id": "EswlPQjqH-Qr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#resources\n",
        "#11GB GPU RAM + 0.8GB additional system ram using \"Qwen/Qwen2.5-3B-Instruct-GPTQ-Int4\"\n",
        "\n",
        "#Observation: need to lower more to facilitate less vram use, still need to run two models\n",
        "\n",
        "\n",
        "#Trick:\n",
        "'''\n",
        "vllm serve Qwen/Qwen2.5-0.5B-Instruct-GPTQ-Int4 \\\n",
        "  --quantization gptq \\\n",
        "  --gpu-memory-utilization 0.5 \\\n",
        "  --kv-cache-dtype fp8 \\\n",
        "  --max-model-len 2048 \\\n",
        "  --tensor-parallel-size 1\n",
        "'''\n",
        "\n",
        "#Result of 50% utilization should be 5gb instead of 11, right?\n",
        "#specifically using the following: --quantization gptq --gpu-memory-utilization 0.5\n",
        "\n",
        "#8GB system,\n",
        "#5.3gb gpu(which is accurate)\n",
        "\n",
        "#Challenge, how to bring down system ram usage\n"
      ],
      "metadata": {
        "id": "7hz0EjlAE97I"
      },
      "id": "7hz0EjlAE97I",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5de079f8-5966-4ddf-8b6f-c8387338a040",
      "metadata": {
        "id": "5de079f8-5966-4ddf-8b6f-c8387338a040"
      },
      "outputs": [],
      "source": [
        "######### Start the Environment server"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39c38995-3576-4449-bc1c-5048f063a46a",
      "metadata": {
        "id": "39c38995-3576-4449-bc1c-5048f063a46a"
      },
      "outputs": [],
      "source": [
        "# !echo \"127.0.0.1\" > /content/drive/MyDrive/mRAG_and_MSRS_source/environment_server_log/environment.log\n",
        "# !echo \"8200\" >> /content/drive/MyDrive/mRAG_and_MSRS_source/environment_server_log/environment.log\n",
        "\n",
        "# !PYTHONPATH=/content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training \\\n",
        "#   nohup mamba run -n train_and_test vllm serve \"tiiuae/Falcon3-1B-Instruct-GPTQ-Int4\" --host 127.0.0.1 --port 8200 --download_dir /content/drive/MyDrive/mRAG_and_MSRS_source/vllm_cache --gpu-memory-utilization 0.3 --max-model-len 8192 --swap-space 0 --dtype=half --enforce-eager\\\n",
        "#   >> /content/drive/MyDrive/mRAG_and_MSRS_source/environment_server_log/environment.log 2>&1 & echo $!"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "######### Kill the Environment server"
      ],
      "metadata": {
        "id": "RdhrAu-2xiw-"
      },
      "id": "RdhrAu-2xiw-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #kill the environment server\n",
        "# !kill -TERM 8710\n",
        "# !fuser -k 8200/tcp"
      ],
      "metadata": {
        "id": "uDZn-r4jwwTH"
      },
      "id": "uDZn-r4jwwTH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #NOTE: the cell output seems to be a lowball, but might be true, these are in kilobytes\n",
        "\n",
        "# #NOTE: in reality seems like it takes more\n",
        "# #5.2GB is the estimate from jump\n",
        "\n",
        "# #resources stats for launched process(vram)\n",
        "# !ps -p 37553 -o pid,ppid,cmd,%mem,rss,vsz\n",
        "# #Uses 9.5GB on the GPU, but was supposed to use CPU right?\n",
        "# #Uses a little bit of ram"
      ],
      "metadata": {
        "id": "tvDSo73HGlqX"
      },
      "id": "tvDSo73HGlqX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "74b57763-5053-4b53-9df3-25b3287ce15e",
      "metadata": {
        "id": "74b57763-5053-4b53-9df3-25b3287ce15e"
      },
      "outputs": [],
      "source": [
        "######### Start the Reward Server"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "099456d0-97ae-4dec-baf5-08a2b9901e74",
      "metadata": {
        "id": "099456d0-97ae-4dec-baf5-08a2b9901e74"
      },
      "outputs": [],
      "source": [
        "# !echo \"127.0.0.1\" > /content/drive/MyDrive/mRAG_and_MSRS_source/judge_server_log/judge.log\n",
        "# !echo \"8300\" >> /content/drive/MyDrive/mRAG_and_MSRS_source/judge_server_log/judge.log\n",
        "\n",
        "# !PYTHONPATH=/content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training \\\n",
        "#   nohup mamba run -n train_and_test vllm serve \"Qwen/Qwen2.5-0.5B-Instruct-GPTQ-Int4\" --host 127.0.0.1 --port 8300 --download_dir /content/drive/MyDrive/mRAG_and_MSRS_source/vllm_cache --gpu-memory-utilization 0.15 --max-model-len 10240 --swap-space 0 --enforce-eager \\\n",
        "#   >> /content/drive/MyDrive/mRAG_and_MSRS_source/judge_server_log/judge.log 2>&1 & echo $!"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pkill -f 'vllm serve'"
      ],
      "metadata": {
        "id": "tZIE5hByN1Z-"
      },
      "id": "tZIE5hByN1Z-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !grep -E 'MemTotal|MemFree|MemAvailable|Buffers|^Cached' /proc/meminfo"
      ],
      "metadata": {
        "id": "24C51zSFNS56"
      },
      "id": "24C51zSFNS56",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "######### Kill the Reward server"
      ],
      "metadata": {
        "id": "45b-lg5LxesE"
      },
      "id": "45b-lg5LxesE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92e42c2f-e470-4bcb-a1de-fed17b08018e",
      "metadata": {
        "id": "92e42c2f-e470-4bcb-a1de-fed17b08018e"
      },
      "outputs": [],
      "source": [
        "# #kill the reward server\n",
        "# !kill -TERM 9594\n",
        "# !fuser -k 8300/tcp"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using the QA pairs of yale-nlp MSRS instead of DataMorgana Generated:"
      ],
      "metadata": {
        "id": "o6ICyhKumlgi"
      },
      "id": "o6ICyhKumlgi"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0579b084-8120-4a26-8f1d-a14e8c68d75a",
      "metadata": {
        "id": "0579b084-8120-4a26-8f1d-a14e8c68d75a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258,
          "referenced_widgets": [
            "483cba3c924343af8a1cb29833d29a98",
            "a230e6980f364e91b50368df1c162116",
            "c6e8ce58b0b8498dbc9faa7b9a3230dd",
            "be584e1d426e41848739b109afb8ecc3",
            "f7315dedafd443369a8a30bcbb39186e",
            "c1011b9798c345c5b071f842ea5007b2",
            "625af6623ac947a6b41cdaeb6fe9c218",
            "acd2217afcbf4eb4a8341b8de29ec4cc",
            "39cc11419a0f46539a14b78713a9d014",
            "b05a0c74b5a14c7bb98d3f28b1d53654",
            "7c7ef180d5b14c4bae29b02c7d472665",
            "383dfde115834b68ae5e785a64d43c07",
            "73797b204b464b269eba7c40960bd837",
            "204a4f9115cd4a1abc136a1d92c339b2",
            "c1b80b7d105d45d4a13b64334e2fa25b",
            "8ccfca73b3b24f6d8e0ebbf35998b818",
            "72a7dc2f647c40df88a1c59a1f745e0d",
            "05981865bb8d4870b54a62ce00b3d251",
            "e3750b8054fb4aeaae6e27792e772d56",
            "0801df578756406f860f5a8bc82435f9",
            "b1269758141941bb89a46c070f29bb81",
            "e3801f1924fc4a3896e701ed7c13d111",
            "92a484041fd54055b7992f0d43fc2cef",
            "1bb0edc0a9cb4e69bfc6dbe5cea3714b",
            "58ada396b94f4958b3d9e708e46af8e8",
            "86a923917ad64091a9366a891672a0ce",
            "e4d105f3c100400a94c0d0792f6bcf90",
            "f75a5556c76c460f8fb033ed7a4c4410",
            "8a04aaf00fdc44789e9a06c9f3e11edb",
            "2d906cbec4974cec96affca47d9a0dc5",
            "50f8891ea99b426995fc2ccb1ae3da79",
            "fc029cb769dc445187a459a50d1ec1cf",
            "0f5b0997298d411cb2ccd3a4337c96bf",
            "4914dcfd4ff74eaca9b4da7d66383ca3",
            "7b83386a4ca9479fb0fbe1b8af2ebf52",
            "4e6d1b23af8a49cda47b0ad9ff7b686b",
            "32c1ad1b73684df789dae1ba9863e3ad",
            "09e09715f1504522b946080f5b089edc",
            "e972c27fd96e40779000171c0b33f4e5",
            "7498eb8d9a114fb2a474a728cf684772",
            "25f562a5f3ff4685a814ef4b4d07411d",
            "2016379acb81464caef78a769eaa40c9",
            "0a7ecc9ed8ca4b31836260eaf514513f",
            "4b5299f6e6764188a853164689e62fdd",
            "6ad0a338f6fa4b969fdcae852bb2cfdc",
            "e8bb8bd044c44bf29ff954a47b03d4a1",
            "9120cde3bf054630a8577d16d2fdd07b",
            "3be657354a974adea11b8e3bc512756d",
            "2ec6b799affd40ebb7a5860988f9b590",
            "2b83e8c1b7834a0a9b87c12ccd2ce91e",
            "044635bb7db74c34828dce31e8b40871",
            "25d567f59023498a9ed73040d9399855",
            "75bc27194a994bb2b9d48ab6d155bd94",
            "04d69989d80d45e89e42f35810720d42",
            "36d808358a6e43848f5e8bf0b042d10c",
            "3d9ba12e97db4a188d55f3782ec84012",
            "5a9c0e23e0284473b801e8d996b50722",
            "2d6aae5018054772a602de77c384ce4c",
            "42df521ef7214b8bab580696b3e4c86f",
            "638582c8939a4c74ac238ca2a049b530",
            "47e1b3a919eb45149d5f4f86c052f73b",
            "31ad1bbf384c485f81939bb54c8eeeaa",
            "e9cafc14fb96444688d1a2654d718c3e",
            "1a672719385d41059c06dee8adb3ed9d",
            "bd247c398db642d88da036c422e9dc88",
            "4d2a17750615455e981520969b99d872",
            "16d8eae03294426ab081353e7169529a",
            "df2d71ce434e4f39bb481cdd82dec98b",
            "9ba6d07c6491411bb38919ab7dd9d92a",
            "e290c9b1e6194b3db96a8c19a412c3db",
            "b597e26df0b149e19c50fe098bcc223a",
            "29730af95b924a1c9a3cd13bb269b215",
            "1f9db07dbff34235921566d1f20eb857",
            "e2b8a5c96ef543a9bf9f8413534e432e",
            "fc9e8186346143bd93ce689e5bc8a87c",
            "cb2b0e12dc0349948822fcd8d04493c2",
            "fabb2754f63d4029b01d82124decdeae"
          ]
        },
        "outputId": "5bb9514c-7787-4203-a6f3-ef6b3924729d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "train.jsonl: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "483cba3c924343af8a1cb29833d29a98"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "dev.jsonl: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "383dfde115834b68ae5e785a64d43c07"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "test.jsonl: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "92a484041fd54055b7992f0d43fc2cef"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/250 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4914dcfd4ff74eaca9b4da7d66383ca3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating validation split:   0%|          | 0/125 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6ad0a338f6fa4b969fdcae852bb2cfdc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/260 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3d9ba12e97db4a188d55f3782ec84012"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "16d8eae03294426ab081353e7169529a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3538237"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "#NOTES:\n",
        "#story_qa Benchmark from Human authored dataset SQuALITY, so is not synthetic\n",
        "#meeting_qa Benchmark from Human authored dataset QMSum, so is not synthetic\n",
        "\n",
        "\n",
        "story_qa = load_dataset(\"yale-nlp/MSRS\", \"story-qa\")\n",
        "#meeting_qa = load_dataset(\"yale-nlp/MSRS\", \"meeting-qa\")\n",
        "\n",
        "\n",
        "'''\n",
        "#in the form\n",
        "DatasetDict({\n",
        "    train: Dataset({\n",
        "        features: ['id', 'query', 'gold_documents', 'answer'],\n",
        "        num_rows: 250\n",
        "    })\n",
        "    validation: Dataset({\n",
        "        features: ['id', 'query', 'gold_documents', 'answer'],\n",
        "        num_rows: 125\n",
        "    })\n",
        "    test: Dataset({\n",
        "        features: ['id', 'query', 'gold_documents', 'answer'],\n",
        "        num_rows: 260\n",
        "    })\n",
        "})\n",
        "'''\n",
        "\n",
        "#NOTICE: Merging the datasets because the train_test splitting is done elsewhere, in train_test_separate.py script\n",
        "from datasets import concatenate_datasets\n",
        "splits = [story_qa[\"train\"], story_qa[\"validation\"], story_qa[\"test\"]]\n",
        "story_qa = concatenate_datasets(splits)\n",
        "\n",
        "\n",
        "#rename query column question\n",
        "story_qa = story_qa.rename_columns({\"query\":\"question\"})\n",
        "\n",
        "#For use by eventual evaluation, have the gold standard documents, they have defined gold standard documents that will encompass the answer\n",
        "#story_qa_orig = story_qa\n",
        "\n",
        "#remove columns that aren't meant to be there, only leaving questions and answers, for use as training set with mRAG\n",
        "#story_qa = story_qa.remove_columns([\"id\",\"gold_documents\"])\n",
        "\n",
        "\n",
        "#exporting the corpus to jsonl\n",
        "story_qa.to_json(\"/content/drive/MyDrive/mRAG_and_MSRS_source/qa_files/story_qa.json\", lines=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "#story_qa_orig[0]\n",
        "#print(story_qa_orig[0])\n",
        "#print()\n",
        "#print(story_qa[0])\n",
        "#print(len(story_qa[0]['answer']))\n",
        "\n",
        "#Test set, ultimately used for eval needs to actually preserve this format { id, question, gold_documents, answer}"
      ],
      "metadata": {
        "id": "NGbFyiKjlFtL",
        "collapsed": true
      },
      "id": "NGbFyiKjlFtL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#NOTICE: number of test samples need to be changed within the file train_test_saparate.py in order to be suitable for dataset, because MSRS so small, 635 QAs\n",
        "#doing 90% 10% split so update train_test_separate.py to set num_test variable = to 64\n",
        "\n",
        "#UPDATE: added argument num_test in train_test_seperate.py so that it is easier to change on the fly\n",
        "\n",
        "#UPDATE: outputed train.json is of different format than test.json\n",
        "#train now formatted to drop 'id' and 'gold_documents' fields because subsequent script takes just queries 'question' and answer\n",
        "#BUT test.json in original format because it still contains ids and ground truth/golden documents\n",
        "\n",
        "\n",
        "\n",
        "!mamba run -n train_and_test python \"/content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/utils/train_test_seperate.py\" \\\n",
        "    --datamorgana_data_addr \"/content/drive/MyDrive/mRAG_and_MSRS_source/qa_files\" \\\n",
        "    --output_dir \"/content/drive/MyDrive/mRAG_and_MSRS_source/train_test_jsons\" \\\n",
        "    --num_test 550\n",
        "\n",
        "# theres 650 total story_qa which we are splitting into test and train. Experiences are generated on the train split.\n",
        "\n"
      ],
      "metadata": {
        "id": "iSWwBsE_m1zD"
      },
      "id": "iSWwBsE_m1zD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "827b7f91-2117-4225-bf65-9f430d131269",
      "metadata": {
        "id": "827b7f91-2117-4225-bf65-9f430d131269"
      },
      "outputs": [],
      "source": [
        "########## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c90f2023-9860-4408-a5d6-a0b2fede678c",
      "metadata": {
        "id": "c90f2023-9860-4408-a5d6-a0b2fede678c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "421ae715-2930-439c-f3dc-6d41e4f3f010"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SUBMIT q: Q4. Describe the setting(s) of the story, which revolves around a character with a peculiar ability who faces a life-threatening situation during a flight. Why is it important?\n",
            "SUBMIT a: ['This story has two settings: first, on an airplane from San Francisco to Los Angeles and second, at the Los Angeles airport in the baggage claim and arrivals terminal. The first setting - on the airplane mid flight - is highly important to the story because it is here that the protagonist discovered the bomb in the luggage. Not only that, he discovers that bomb is on a countdown with 10 minutes remaining before detonation while the flight still has 40 minutes before arrival. It is due to this fact that the protagonist utilizes his time manipulation ability to stop the clock successfully. \\n\\nIn the second setting, the tensions in this story continue to rise. Despite the protagonist successfully stopping the clock in the air, it appears to continue on the ground. With both the anticipation of watching to see who picks up the little red bag and dodging suspicions from the airport policeman and workers, we can imagine the hectic and panicked energy that sometimes appears in baggage claims. Additionally, an airport is filled with many people arriving and departing, which adds to the pressure the protagonist is facing in dealing with deactivating the bomb before anyone gets hurt. \\n', 'The first part of the story is happening on a plane that is flying from San Francisco to Los Angeles. When the protagonist finds the bomb in one of the bags in the luggage compartment, the plane is somewhere above the mountain range north of Los Angeles - even in theory, it is impossible to land because there are no airports around this area. He stops the clock mechanism, using his extraordinary ability. After the landing, the story continues in the building of the airport, where the protagonist finds the owner of the bag with the bomb - Julia Claremont. He tells her about the bomb and how he sensed it during the flight. She cries and tells him that her husband put it in her bag after she had finished packing. They go back to the lobby and see that their suitcases got stolen. The protagonist tries to chase the thief, but the man quickly drives off with the bags. When they decide to file a report, something explodes loudly near the airport, and Julia, together with the protagonist, walks away, refusing to report the theft. \\n', 'The story first begins on a plane from San Francisco to Los Angeles. The protagonist first expects to see San Joaquin Valley, but he is greeted by a sea of clouds instead. He sits next to an old woman on the plane. A little north of Bakersfield, he finds that one of the bags on the plane contains a bomb. It is forty minutes from Burbank to Lockheed Air Terminal, and there would be no place to land the plane any time soon. Once the protagonist gets off the plane, he heads to the baggage claim at the airport for his bag. When Julia gets her bag, he leads her to a telephone booth to make the fake call. Then, they leave their bags in the lobby and go to a coffee shop. The airport policeman is across the street from the parking lot. The setting of the plane is important because it is where the protagonist first discovers the bomb. Without his extraordinary ability to feel around any enclosed object, he would not be able to detect and temporarily stop the bombâ€™s timer before it was too late. This is also significant because the plane would have exploded had he not found it. The airport is important too because that is where he meets Julia. He would not have figured out who the bag belonged to and the entire story without waiting at the airport. ', \"The story's setting is in an ordinary world where no extrasensory ability is found or known. This setting is essential because the protagonist has the extrasensory ability, which allows him to see the insides of things and move some very light objects with his mind. However, since the world does not know the existence of the ability, he cannot tell anyone about it because if he tells people the truth, people either do not believe him or see him as a freak. Furthermore, since he cannot tell anyone his ability, neither can he tell people about what he finds in any bags, like a bomb, because he cannot explain how he knows what is inside of things that do not belong to him. Therefore, this inability to reveal his extrasensory ability drives the story to progress.\"]\n",
            "q: Q4. Describe the setting(s) of the story, which revolves around a character with a peculiar ability who faces a life-threatening situation during a flight. Why is it important?\n",
            "SUBMIT q: What is the plot of the story involving a man who awakens in an unfamiliar place and grapples with the implications of his surroundings and a mysterious figure, while exploring themes of ambition and the future?\n",
            "a: ['This story has two settings: first, on an airplane from San Francisco to Los Angeles and second, at the Los Angeles airport in the baggage claim and arrivals terminal. The first setting - on the airplane mid flight - is highly important to the story because it is here that the protagonist discovered the bomb in the luggage. Not only that, he discovers that bomb is on a countdown with 10 minutes remaining before detonation while the flight still has 40 minutes before arrival. It is due to this fact that the protagonist utilizes his time manipulation ability to stop the clock successfully. \\n\\nIn the second setting, the tensions in this story continue to rise. Despite the protagonist successfully stopping the clock in the air, it appears to continue on the ground. With both the anticipation of watching to see who picks up the little red bag and dodging suspicions from the airport policeman and workers, we can imagine the hectic and panicked energy that sometimes appears in baggage claims. Additionally, an airport is filled with many people arriving and departing, which adds to the pressure the protagonist is facing in dealing with deactivating the bomb before anyone gets hurt. \\n', 'The first part of the story is happening on a plane that is flying from San Francisco to Los Angeles. When the protagonist finds the bomb in one of the bags in the luggage compartment, the plane is somewhere above the mountain range north of Los Angeles - even in theory, it is impossible to land because there are no airports around this area. He stops the clock mechanism, using his extraordinary ability. After the landing, the story continues in the building of the airport, where the protagonist finds the owner of the bag with the bomb - Julia Claremont. He tells her about the bomb and how he sensed it during the flight. She cries and tells him that her husband put it in her bag after she had finished packing. They go back to the lobby and see that their suitcases got stolen. The protagonist tries to chase the thief, but the man quickly drives off with the bags. When they decide to file a report, something explodes loudly near the airport, and Julia, together with the protagonist, walks away, refusing to report the theft. \\n', 'The story first begins on a plane from San Francisco to Los Angeles. The protagonist first expects to see San Joaquin Valley, but he is greeted by a sea of clouds instead. He sits next to an old woman on the plane. A little north of Bakersfield, he finds that one of the bags on the plane contains a bomb. It is forty minutes from Burbank to Lockheed Air Terminal, and there would be no place to land the plane any time soon. Once the protagonist gets off the plane, he heads to the baggage claim at the airport for his bag. When Julia gets her bag, he leads her to a telephone booth to make the fake call. Then, they leave their bags in the lobby and go to a coffee shop. The airport policeman is across the street from the parking lot. The setting of the plane is important because it is where the protagonist first discovers the bomb. Without his extraordinary ability to feel around any enclosed object, he would not be able to detect and temporarily stop the bombâ€™s timer before it was too late. This is also significant because the plane would have exploded had he not found it. The airport is important too because that is where he meets Julia. He would not have figured out who the bag belonged to and the entire story without waiting at the airport. ', \"The story's setting is in an ordinary world where no extrasensory ability is found or known. This setting is essential because the protagonist has the extrasensory ability, which allows him to see the insides of things and move some very light objects with his mind. However, since the world does not know the existence of the ability, he cannot tell anyone about it because if he tells people the truth, people either do not believe him or see him as a freak. Furthermore, since he cannot tell anyone his ability, neither can he tell people about what he finds in any bags, like a bomb, because he cannot explain how he knows what is inside of things that do not belong to him. Therefore, this inability to reveal his extrasensory ability drives the story to progress.\"]\n",
            "SUBMIT a: [\"Maitland, a militant engineer specialized in atomic rocket motors, awakes one night to a strange sound in his room. He blacks out and awakes again, this time in a room that isn't his. He takes in his surroundings and notices a prairie and a river outside his window, and within his room a door to exit which he cannot open. As Maitland wonders helplessly, a man by the name of Swarts enters his room. Swarts tells Maitland that he is here to participate in a series of psychological tests, assuring him that he is not interested in any secret intelligence related to his career. Swarts leads Maitland to his laboratory, where a cot stands in the center of the room under a ceiling of electric cables. Maitland resists initially, wary of the extent Swarts would go to in order for him to comply; however, Swarts manages to get Maitland onto the cot by force. He then reveals his main objective, which is figuring out why Maitland has a passion and longing to go to the Moon. Later that evening, Maitland meets a girl, later referred to as Ingrid Ching, who silently brings him a meal. He stares outside his window, trying to piece together where he could be, when he notices the presence of Venus in the sky as an evening star and comes to the realization that he has traveled to the future. Bewildered, Maitland is eager to learn more about the advancements of society, namely the status of man's trip to space. He asks Ching, who refuses to answer, and is then brought back to Swarts' lab. Maitland, determined to have his questions answered, rebels against Swarts' following tests through mental resistance. Becoming frustrated, Swarts tells Maitland that they are in the year A.D 2634, and that Ching would answer remaining questions if he complied with the tests. Agreeing, Ching visits Maitland that evening, and indulges him in the history of the human race up to this point, including stories of the Afrikanders, who dominated technological advancements and ruled the global empire, and how the world eventually transformed into one race. Maitland asks Ching whether humans have been able to go to space yet, and she is perplexed. She tells him that though she doesn't think it would be impossible, it has not been done, and she wonders why such a thing would be desired. Ching explains that the world is no longer in an age of technology, but an age of understanding humans and cultures within their world. Maitland is defeated; he cannot comprehend how there is no interest in traveling to space, realizing that his lifelong goal has become unattainable. \", 'The story starts with Maitland waking up from a loud thump but quickly goes back to sleep. Later he realizes that he is not in his room. This is not the Reservation. Then he remembers that something has happened during the night. He believes that whoever captures him must want information about the rocket motor. He gets up to inspect the room but only find a door leading to the bathroom. The other door cannot be opened and the view from the window is unfamiliar. About half an hour later, the other door opens and a man named Swarts explains that he will perform some psychological tests on Maitland for about a week and does not want any information regarding the rocket motor. Even though Swarts made it clear that he can obtain the results he want with or without Maitlandâ€™s cooperation, Maitland still protests. He puts up a fight but ends up on the cot that will record his body changes. Swarts notes that the question regarding traveling to the moon seems to have created involuntary responses, and he wants to know why. \\n\\nBack at the cell, dinner is brought by an Oriental looking girl. Maitland watches the sunset and suddenly realizes that Venus was a morning star, but now he sees it after sunset. He becomes excited after learning that he has time travelled and is determined to ask Swarts which year he is in. He assumes that there are spaceports in the space to reach the starts. The next day Maitland asks the girl what year theyâ€™re in, but she refuses to tell him. Swarts also refuses to tell him anything, thus he does not cooperate in the labs. Finally, Swarts yields and tells him that they are in A.D. 2634. He assures Maitland that the girl, Ingrid Ching, will answer his questions. Then Maitland cooperates. Later Maitland learns about the â€˜historyâ€™ that has happened since his time. And he learns that they have no interest in going to outer space. Instead of the age of technology, they are in the age of man.   ', \"Maitland wakes up in his room in the residential section of the Reservation. He thinks he sees a man in the corner of his room, and just then, he is knocked unconscious. He awakens again the next morning, soon realising that he is not in his room anymore, and he is not in the Reservation either. He must have been abducted in the night and taken to this strange place that is steeped in beautiful nature. Through the window of his room he sees a man and a woman coming up a hill towards the building he is in. Half an hour later, the man he had seen earlier arrives in his room. He tells Maitland his name is Swarts. He isn't going to tell him where he is, and that even though Maitland works in the engineering of rocket motors, he has no interest in extracting secrets from his job. He will be performing a series of tests on Maitland. He takes him to his lab, where Maitland refuses to participate in Swarts' test, so Swarts beats him up and pins him down. He asks Maitland if he wants to go to the moon, then telling him that he wants to understand why. In the evening, a girl enters Maitland's room, bringing him dinner. He notices how beautiful she is. He wonders what this is all about. He watches the sun set, and the stars come out. He notices Venus in the sky, his favourite planet. He then realises that Venus was just a morning star, and it is now an evening star. He must've traveled into the future. Maitland is determined to get the truth about what year it is from Swarts. After great resistance to the tests that Swarts puts him through the next day, the man finally gives into Maitlands question, telling him it is the year 2634. He tells him that the girl who had brought him food, named Ingrid Ching, would answer any questions he might have. Maitland is overcome with excitement at the idea that he might find a place in this society, and be able to use their technology to travel in space. He is quickly brought down though when Ching tells him that there is no such thing as space travel, as the population of Earth, which is now only 300 million, have no interest in such a thing. She tells him a bit about the history of Earth since the 20th century and Maitland is devastated to learn that he will never realise his dream of traveling to space. \", 'Maitland wakes up in a strange room in an unexpected location. He thinks to himself where he might be and starts to feel scared and helpless because he is unsure. Suddenly, a man, Swarts, appears at the now opened entrance to his room. Swarts tells Maitland that he will be there for a week and be fed 3 meals a day. Swarts continues to say that he will not tell Maitland where he is and that the purpose of his stay is to undergo psychological tests. \\n\\nSwarts leads Maitland into the laboratory room tells Maitland to lie down on the surgical cot at the center of the room. The first test will be similar to a lie detector test. He warns Maitland that he should cooperate, but Maitland becomes purposefully defiant. Swarts then forces Maitland onto the cot and straps him into it. Maitland begins to think about what the tests might be as Swarts sets up the different instruments. Swarts then begins the experiment and asks Maitland to explain why he wants to go to the moon. Maitland is intrigued by the question as it was unexpected.\\n\\nAfter returning to his cell and eating the meal that Ching brought him, Maitland begins to think about the situation. After making some observations about the sky, Maitland realizes where he is. He notices that Venus is suddenly an evening star. He becomes full of excitement and thinks about all the possible implications. Energized by his new knowledge, he thinks of a plan to get Swarts to be more open with him and then goes to sleep. After conversing with Ching during his breakfast, Maitland waits in his room until Swarts walks in and then promptly asks Swarts the year. Swarts avoid answering the question and takes Maitland to the laboratory for more testing. \\n\\nMaitland tries to fight against the new machine hoping Swarts will answer his question and his efforts are successful. Swarts tells him that it is the year 2634, and Maitland responds with a grin. He agrees to cooperate with Swarts as long as Ching answers his questions after the experiments. Back in his cell, Ching tells Maitland a quick history of the world of the last 500 years. She explains the deadly war that occurred and the response to it. Maitland then excitedly asks about space innovation but Ching seems confused by the question. Ching asks Maitland why he or anyone else during his time wants to travel in space. Maitland finds it incredulous that with all of the technology at hand people have not traveled to space. Ching explains that her time is the Age of Man and as long as machines work, humans donâ€™t want to think about them, while Maitlandâ€™s time is the Age of Technology. Maitland is very discouraged upon learning that in the present time there is not a familiar interest in space travel and asks to be alone in his room in reaction to the upsetting news. \\n']\n",
            "q: What is the plot of the story involving a man who awakens in an unfamiliar place and grapples with the implications of his surroundings and a mysterious figure, while exploring themes of ambition and the future?\n",
            "SUBMIT q: What are the key aspects of the life cycle and culture of the peculiar beings that resemble turtles but possess distinct characteristics and social dynamics?\n",
            "a: [\"Maitland, a militant engineer specialized in atomic rocket motors, awakes one night to a strange sound in his room. He blacks out and awakes again, this time in a room that isn't his. He takes in his surroundings and notices a prairie and a river outside his window, and within his room a door to exit which he cannot open. As Maitland wonders helplessly, a man by the name of Swarts enters his room. Swarts tells Maitland that he is here to participate in a series of psychological tests, assuring him that he is not interested in any secret intelligence related to his career. Swarts leads Maitland to his laboratory, where a cot stands in the center of the room under a ceiling of electric cables. Maitland resists initially, wary of the extent Swarts would go to in order for him to comply; however, Swarts manages to get Maitland onto the cot by force. He then reveals his main objective, which is figuring out why Maitland has a passion and longing to go to the Moon. Later that evening, Maitland meets a girl, later referred to as Ingrid Ching, who silently brings him a meal. He stares outside his window, trying to piece together where he could be, when he notices the presence of Venus in the sky as an evening star and comes to the realization that he has traveled to the future. Bewildered, Maitland is eager to learn more about the advancements of society, namely the status of man's trip to space. He asks Ching, who refuses to answer, and is then brought back to Swarts' lab. Maitland, determined to have his questions answered, rebels against Swarts' following tests through mental resistance. Becoming frustrated, Swarts tells Maitland that they are in the year A.D 2634, and that Ching would answer remaining questions if he complied with the tests. Agreeing, Ching visits Maitland that evening, and indulges him in the history of the human race up to this point, including stories of the Afrikanders, who dominated technological advancements and ruled the global empire, and how the world eventually transformed into one race. Maitland asks Ching whether humans have been able to go to space yet, and she is perplexed. She tells him that though she doesn't think it would be impossible, it has not been done, and she wonders why such a thing would be desired. Ching explains that the world is no longer in an age of technology, but an age of understanding humans and cultures within their world. Maitland is defeated; he cannot comprehend how there is no interest in traveling to space, realizing that his lifelong goal has become unattainable. \", 'The story starts with Maitland waking up from a loud thump but quickly goes back to sleep. Later he realizes that he is not in his room. This is not the Reservation. Then he remembers that something has happened during the night. He believes that whoever captures him must want information about the rocket motor. He gets up to inspect the room but only find a door leading to the bathroom. The other door cannot be opened and the view from the window is unfamiliar. About half an hour later, the other door opens and a man named Swarts explains that he will perform some psychological tests on Maitland for about a week and does not want any information regarding the rocket motor. Even though Swarts made it clear that he can obtain the results he want with or without Maitlandâ€™s cooperation, Maitland still protests. He puts up a fight but ends up on the cot that will record his body changes. Swarts notes that the question regarding traveling to the moon seems to have created involuntary responses, and he wants to know why. \\n\\nBack at the cell, dinner is brought by an Oriental looking girl. Maitland watches the sunset and suddenly realizes that Venus was a morning star, but now he sees it after sunset. He becomes excited after learning that he has time travelled and is determined to ask Swarts which year he is in. He assumes that there are spaceports in the space to reach the starts. The next day Maitland asks the girl what year theyâ€™re in, but she refuses to tell him. Swarts also refuses to tell him anything, thus he does not cooperate in the labs. Finally, Swarts yields and tells him that they are in A.D. 2634. He assures Maitland that the girl, Ingrid Ching, will answer his questions. Then Maitland cooperates. Later Maitland learns about the â€˜historyâ€™ that has happened since his time. And he learns that they have no interest in going to outer space. Instead of the age of technology, they are in the age of man.   ', \"Maitland wakes up in his room in the residential section of the Reservation. He thinks he sees a man in the corner of his room, and just then, he is knocked unconscious. He awakens again the next morning, soon realising that he is not in his room anymore, and he is not in the Reservation either. He must have been abducted in the night and taken to this strange place that is steeped in beautiful nature. Through the window of his room he sees a man and a woman coming up a hill towards the building he is in. Half an hour later, the man he had seen earlier arrives in his room. He tells Maitland his name is Swarts. He isn't going to tell him where he is, and that even though Maitland works in the engineering of rocket motors, he has no interest in extracting secrets from his job. He will be performing a series of tests on Maitland. He takes him to his lab, where Maitland refuses to participate in Swarts' test, so Swarts beats him up and pins him down. He asks Maitland if he wants to go to the moon, then telling him that he wants to understand why. In the evening, a girl enters Maitland's room, bringing him dinner. He notices how beautiful she is. He wonders what this is all about. He watches the sun set, and the stars come out. He notices Venus in the sky, his favourite planet. He then realises that Venus was just a morning star, and it is now an evening star. He must've traveled into the future. Maitland is determined to get the truth about what year it is from Swarts. After great resistance to the tests that Swarts puts him through the next day, the man finally gives into Maitlands question, telling him it is the year 2634. He tells him that the girl who had brought him food, named Ingrid Ching, would answer any questions he might have. Maitland is overcome with excitement at the idea that he might find a place in this society, and be able to use their technology to travel in space. He is quickly brought down though when Ching tells him that there is no such thing as space travel, as the population of Earth, which is now only 300 million, have no interest in such a thing. She tells him a bit about the history of Earth since the 20th century and Maitland is devastated to learn that he will never realise his dream of traveling to space. \", 'Maitland wakes up in a strange room in an unexpected location. He thinks to himself where he might be and starts to feel scared and helpless because he is unsure. Suddenly, a man, Swarts, appears at the now opened entrance to his room. Swarts tells Maitland that he will be there for a week and be fed 3 meals a day. Swarts continues to say that he will not tell Maitland where he is and that the purpose of his stay is to undergo psychological tests. \\n\\nSwarts leads Maitland into the laboratory room tells Maitland to lie down on the surgical cot at the center of the room. The first test will be similar to a lie detector test. He warns Maitland that he should cooperate, but Maitland becomes purposefully defiant. Swarts then forces Maitland onto the cot and straps him into it. Maitland begins to think about what the tests might be as Swarts sets up the different instruments. Swarts then begins the experiment and asks Maitland to explain why he wants to go to the moon. Maitland is intrigued by the question as it was unexpected.\\n\\nAfter returning to his cell and eating the meal that Ching brought him, Maitland begins to think about the situation. After making some observations about the sky, Maitland realizes where he is. He notices that Venus is suddenly an evening star. He becomes full of excitement and thinks about all the possible implications. Energized by his new knowledge, he thinks of a plan to get Swarts to be more open with him and then goes to sleep. After conversing with Ching during his breakfast, Maitland waits in his room until Swarts walks in and then promptly asks Swarts the year. Swarts avoid answering the question and takes Maitland to the laboratory for more testing. \\n\\nMaitland tries to fight against the new machine hoping Swarts will answer his question and his efforts are successful. Swarts tells him that it is the year 2634, and Maitland responds with a grin. He agrees to cooperate with Swarts as long as Ching answers his questions after the experiments. Back in his cell, Ching tells Maitland a quick history of the world of the last 500 years. She explains the deadly war that occurred and the response to it. Maitland then excitedly asks about space innovation but Ching seems confused by the question. Ching asks Maitland why he or anyone else during his time wants to travel in space. Maitland finds it incredulous that with all of the technology at hand people have not traveled to space. Ching explains that her time is the Age of Man and as long as machines work, humans donâ€™t want to think about them, while Maitlandâ€™s time is the Age of Technology. Maitland is very discouraged upon learning that in the present time there is not a familiar interest in space travel and asks to be alone in his room in reaction to the upsetting news. \\n']\n",
            "SUBMIT a: ['Fustians somewhat resemble gigantic, intelligent snapping turtles, and like turtles, start life as eggs. During their youth and adolescence, they are relatively agile and have no shells (unlike turtles). It is notable how many Fustian elders take a dim view of adolescents, with the Minister of Fust himself saying that the Youth should be â€œkept penned with the livestock until they grow a carapace to tame their irresponsibility.â€\\nWhen Fustians mature, they develop an enormous, horny carapace which they are obliged to carry around on their backs for the rest of their lives, which last over a thousand years. The carapaces cause the adult Fustians to be slow-moving, and they take up a lot of space â€“ hence their public transportation consists of flat-cars instead of buses with seats. Unfortunately, not much is known by off-worlders of Fustian females.\\nLike most intelligent races, Fustians enjoy music. The frequencies at which their music is played are subsonic, and therefore not audible to the human ear. Likewise, their ears are quite sensitive to high frequencies, such as those produced by tapping on a crystal glass with a spoon. This is not just unpleasant, but painful to Fustian ears.\\n', 'Fustians are similar to tortoises in build, with yellow eyes, scales, and very thick hides that leak purple blood when cut. They have a much longer life-cycle than humans, as those that are 75 years of age are still considered to be teenagers or even youths. \\n\\nAs Faustians age, they grow larger, their voices get deeper, and they eventually acquire very heavy shells. It is past their current medical knowledge to safely remove the shells, though we find out at the end of the story that the Groaci have discovered a technique that allows them to do this. This is important because the shells slow the older Fustians down and are often considered a nuisance. When they are young, they are very secretive, and wary of strangers from other groups and species. The older Fustians do not seem to mind the humans (and aliens in general) as much, and sometimes apologize for the behavior of the younger ones. It seems that they wish they could do more to control their behavior, but the younger ones are physically much faster and can escape attempts at control. It also seems to be the case that this difference in behavior is more acute now than it has been in the past, perhaps due to social pressures from other groups. \\n\\nSleep is very important to them, and regular greetings in day-to-day life include well wishes for a long rest, as well as specific types of dreams. When they are angry or want to insult someone, they wish nightmares upon them. They have regular siesta times during the work day. Sleep is so important to them that they have a National Dirge called the Lament of Hatching. Ceremonial revenge is also important to them: although the older Fustians are not necessarily quick to anger, they follow through once they have been wronged. ', 'Fustians are a species turtle-like in their appearance. They have very long lives; in fact, the average age of a Fustian youth is seventy-five years old. As they age, they develop a hard-shell on their backs, which is quite heavy and hard. This causes them to move slower as they get older. The younger Fustians can move quite fast in comparison. However, the older Fustians appear to be a great deal stronger and can hold their own in combat, as demonstrated by Whonk when he defends himself against Slockâ€™s cronies and eventually captures Slock. The elderly Fustians also grow thicker skin, which is what ultimately prevents Whonk from being decapitated when he is first attacked. Fustians have turtle-like mouths that snap when they are angry. Steel manufacturing fuels their economy. While older Fustians are generally hospitable and patient, the younger Fustians have become frustrated with the ways of the elderly Fustian leadership, and their drive to change things blinds them to being manipulated by the Groaci. Although weapons are illegal on Fust, the younger Fustians seem willing to break this rule by accepting weapons from the Groaci in exchange for their knowledge of the ships.', \"The Fustians look like turtles and have extremely long lifespans. Younger Fustians do not have a carapace, but older ones do, which can be quite heavy. Seventy-five-year-olds are considered youths, like teenagers, because they can live for about two thousand years. The 75-year-olds have a reputation as being at a trying age. As Whonk explains to Retief, the youth have a reputation for â€œshameâ€ and â€œdiscourtesy.â€ The Elders feel that there is little they can do about the youths' misbehavior since the Elders are so much slower with their carapaces. They have no police and have never needed them until the youth became so unruly. They have a youth group, the Sexual, Cultural, and Athletic Recreational Society (SCARS), that needs a sponsor and wants someone to provide them a clubhouse, uniforms, equipment, and so forth. The Fustiansâ€™ dwellings have a fishy odor and are found along a broad cobbled street. They have a caste system; the driver of a flat car is a member of the labor caste. Their greetings relate to peaceful sleep: â€œLong-may-you-sleepâ€ and â€œMay-you-dream-of-the-deeps.â€ Likewise, their insults related to unpleasant sleep: â€œMay you toss in nightmares!â€ The oldest Fustians are forced into retirement and given once-daily feedings; Whonk says this is nothing to look forward to for his next thousand years. They have a strong sense of right and wrong and carry out ceremonial revenge when wronged.\"]\n",
            "q: What are the key aspects of the life cycle and culture of the peculiar beings that resemble turtles but possess distinct characteristics and social dynamics?\n",
            "SUBMIT q: What is the plot of the story involving a spaceman who reflects on his life choices and the significance of his retirement amidst the backdrop of space exploration?\n",
            "a: ['Fustians somewhat resemble gigantic, intelligent snapping turtles, and like turtles, start life as eggs. During their youth and adolescence, they are relatively agile and have no shells (unlike turtles). It is notable how many Fustian elders take a dim view of adolescents, with the Minister of Fust himself saying that the Youth should be â€œkept penned with the livestock until they grow a carapace to tame their irresponsibility.â€\\nWhen Fustians mature, they develop an enormous, horny carapace which they are obliged to carry around on their backs for the rest of their lives, which last over a thousand years. The carapaces cause the adult Fustians to be slow-moving, and they take up a lot of space â€“ hence their public transportation consists of flat-cars instead of buses with seats. Unfortunately, not much is known by off-worlders of Fustian females.\\nLike most intelligent races, Fustians enjoy music. The frequencies at which their music is played are subsonic, and therefore not audible to the human ear. Likewise, their ears are quite sensitive to high frequencies, such as those produced by tapping on a crystal glass with a spoon. This is not just unpleasant, but painful to Fustian ears.\\n', 'Fustians are similar to tortoises in build, with yellow eyes, scales, and very thick hides that leak purple blood when cut. They have a much longer life-cycle than humans, as those that are 75 years of age are still considered to be teenagers or even youths. \\n\\nAs Faustians age, they grow larger, their voices get deeper, and they eventually acquire very heavy shells. It is past their current medical knowledge to safely remove the shells, though we find out at the end of the story that the Groaci have discovered a technique that allows them to do this. This is important because the shells slow the older Fustians down and are often considered a nuisance. When they are young, they are very secretive, and wary of strangers from other groups and species. The older Fustians do not seem to mind the humans (and aliens in general) as much, and sometimes apologize for the behavior of the younger ones. It seems that they wish they could do more to control their behavior, but the younger ones are physically much faster and can escape attempts at control. It also seems to be the case that this difference in behavior is more acute now than it has been in the past, perhaps due to social pressures from other groups. \\n\\nSleep is very important to them, and regular greetings in day-to-day life include well wishes for a long rest, as well as specific types of dreams. When they are angry or want to insult someone, they wish nightmares upon them. They have regular siesta times during the work day. Sleep is so important to them that they have a National Dirge called the Lament of Hatching. Ceremonial revenge is also important to them: although the older Fustians are not necessarily quick to anger, they follow through once they have been wronged. ', 'Fustians are a species turtle-like in their appearance. They have very long lives; in fact, the average age of a Fustian youth is seventy-five years old. As they age, they develop a hard-shell on their backs, which is quite heavy and hard. This causes them to move slower as they get older. The younger Fustians can move quite fast in comparison. However, the older Fustians appear to be a great deal stronger and can hold their own in combat, as demonstrated by Whonk when he defends himself against Slockâ€™s cronies and eventually captures Slock. The elderly Fustians also grow thicker skin, which is what ultimately prevents Whonk from being decapitated when he is first attacked. Fustians have turtle-like mouths that snap when they are angry. Steel manufacturing fuels their economy. While older Fustians are generally hospitable and patient, the younger Fustians have become frustrated with the ways of the elderly Fustian leadership, and their drive to change things blinds them to being manipulated by the Groaci. Although weapons are illegal on Fust, the younger Fustians seem willing to break this rule by accepting weapons from the Groaci in exchange for their knowledge of the ships.', \"The Fustians look like turtles and have extremely long lifespans. Younger Fustians do not have a carapace, but older ones do, which can be quite heavy. Seventy-five-year-olds are considered youths, like teenagers, because they can live for about two thousand years. The 75-year-olds have a reputation as being at a trying age. As Whonk explains to Retief, the youth have a reputation for â€œshameâ€ and â€œdiscourtesy.â€ The Elders feel that there is little they can do about the youths' misbehavior since the Elders are so much slower with their carapaces. They have no police and have never needed them until the youth became so unruly. They have a youth group, the Sexual, Cultural, and Athletic Recreational Society (SCARS), that needs a sponsor and wants someone to provide them a clubhouse, uniforms, equipment, and so forth. The Fustiansâ€™ dwellings have a fishy odor and are found along a broad cobbled street. They have a caste system; the driver of a flat car is a member of the labor caste. Their greetings relate to peaceful sleep: â€œLong-may-you-sleepâ€ and â€œMay-you-dream-of-the-deeps.â€ Likewise, their insults related to unpleasant sleep: â€œMay you toss in nightmares!â€ The oldest Fustians are forced into retirement and given once-daily feedings; Whonk says this is nothing to look forward to for his next thousand years. They have a strong sense of right and wrong and carry out ceremonial revenge when wronged.\"]\n",
            "SUBMIT a: [\"Seymour Pond has just retired from his career as the last astronaut from the Ultrawelfare State at the age of thirty. At his going away party he is given a watch, and academics like Lifting Gubelin and Dr Hans Girarad-Perregaux speak on his behalf. Si has decided to take the money he has saved up from his time working, which most people in the Ultrawelfare state don't, and live a simple comfortable life. He intends to never work again, after his six space flights. The currency used in the state was universal, controlled by a personal credit card. Because most jobs were automated, few people had to work, so most people lived off of a set welfare, and those selected to work were given a little extra compensation. Si was one of these people. Gubelin and Perregaux are both horrified by the fact that Pond has decided to take an early retirement. He was their only pilot for their space program, and if they were to get another, it would take at least a year of training. Without a pilot, they are worried that their funding will be cut, and the space program will be shut down. They scheme together as to how to get Pond back in the space program. They think that the only way to get him back would be to make sure he was left without any money, and therefore would have no choice but to return to his former position. \\nSi is planning a big night out. He has always gone and celebrated when there was a cause, and tonight, he was planning to spend at least half of all the money in his account. He gets dressed in his retirement rank suit to go out, checks his balance, and then takes his vacuum tube to New york city. Before he leaves, he books a room at a swanky hotel for the rich and famous, and after a few moments, his car transports him to his room. There is an amazing view of the city, and from his room, gets ready to go to the bar. \\nAt the bar he orders a drink, before noticing a beautiful woman beside him. They get to talking and before long, she tells him she recognises him, telling him about how moved she found his whole retirement ceremony. Making it very clear she wasn't happy he was retiring. He asks why she has an interest in space, to which she replies that she always has. He begins to explain the aspects of space flight, when the right side of his mouth begins to tick, and he knocks his drink back. \", 'In the Ultrawelfare State, the kind of jobs that one does is decided through a lottery. The lottery is drawn whenever thereâ€™s a need for new employees. Those that work will receive some additional Variable Basic shares to be added to their portfolios. And once their portfolios reach a certain level of Variable Basic shares, they can afford to live the life in the way they prefer. The story begins with Seymour Pond, the space pilot that has been on six trips, receiving a gold watch and a banquet from the officials including Academician Lofting Gubelin, an anachronistic man, and Doctor Hans Girard-Perregaux to persuade him not to retire. Because there is no other space pilot at this time, and it takes a few months, if not a year, and much resources to train a new pilot ready to travel to the moon. But Pondâ€™s mind is set, heâ€™s had enough anxiety over space cafard, and he has quite a large amount of Variable Basic shares to support his living and to show off to the others. \\n\\nIn the escape room at Gubelinâ€™s Floridian home arguing with Girard-Perregaux, who states that he would do the same in the position that Pond is currently in. Because of the way that employment works in the Ultrawelfare State, Pond doesnâ€™t need to face danger anymore. The law does not even allow him to be selected to work again. Later, they decide to use the sailor way of life method to force Pond back to being a pilot again. \\n\\nPond is aware of the sailor way of life, and he does not want to spend his money in such a quick rush. After dressing himself in a great retirement-rank suit, he checks his balance and makes sure that he has enough money to spend. He goes to Manhattan and settles in a nicer room of the hotel, where he can see the Empire State Building Museum and the Hudson as well as the city. Then he decides to visit the Kudos Room for a drink where celebrities sometimes go. While he was disappointed to see no celebrities, he gets to talk to a beautiful girl who seems extremely interested in space travelling and admires him a lot. As he was explaining space cafard to the girl, he felt a tic on his mouth, so he quickly finishes his drink. ', 'Spacemen on a Spree begins at a banquet celebrating the retirement of Seymour Pondâ€™s, a space pilot. At the retirement banquet, Pond expresses smugness and content as he knows the program will not be viable without him. \\n\\nAfter the party, Hans and Gubelin discuss the significance of Pondâ€™s retirement. They are upset because the Department of Space Exploration is in jeopardy because they do not have another trained space pilot to replace Pond and it would take a long time to train one. Hans and Gubelin go back and forth discussing how best to convince Pond to return to the space pilot job. \\n\\nSeymour was grateful for each time he returned from his space runs and was ready to retire at the age of 30, which was allowed by the Ultrawelfare State. Once he is retired, Seymour expresses his desire to throw a big celebration. He intends to use a great deal of his money and wants to do so in a more controlled and lavish manner than he previously has. He dresses in a newly purchased suit and is careful to attach his space pin that clearly identifies his previous occupation. He takes transportation to a Manhattan hotel to execute his plan. He is satisfied with his hotel room and heads to the bar to enjoy some drinks. At the bar he sees a girl that he finds very attractive. The girl, Natalie Paskov, initially responds coldly to his attention but then becomes interested when she sees the space pin on his suit. Natalie then mentions that she recognizes him because she follows space news since it is an interest of hers. She expresses her sadness that he retired. The story ends with him talking about space cafard. \\n', 'Seymour Pond is retiring from being a space pilot. Gubelin and Perregaux, big figures in space exploration, want to urge the man to stay as space has to be delved further into. The problem is that there are not enough young people willing to venture and explore the space. Pond is the only trained pilot in the world and they need him, while he has just enough fortune to retire with comfort. Without him the whole space exploration department will be terminated, so Gubelin and Perregaux think of means to deprive Seymour of his money and force him to go back to space. Seymour at that time is planning how to spend his money - he wants to spend a huge sum on the best entertainment. So, the ex-Space Pilot heads towards Manhattan in an automatic car. Seymour gets a luxurious room in a hotel and goes to get a drink in an expensive bar there. There he meets a graceful Oriental girl, and he offers her a drink. Soon she recognizes the famous pilot and starts treating him like a celebrity with utmost surprise of the possibility of talking to him. Turns out she is a huge fan of space and Seymour starts telling her things. ']\n",
            "q: What is the plot of the story involving a spaceman who reflects on his life choices and the significance of his retirement amidst the backdrop of space exploration?\n",
            "a: [\"Seymour Pond has just retired from his career as the last astronaut from the Ultrawelfare State at the age of thirty. At his going away party he is given a watch, and academics like Lifting Gubelin and Dr Hans Girarad-Perregaux speak on his behalf. Si has decided to take the money he has saved up from his time working, which most people in the Ultrawelfare state don't, and live a simple comfortable life. He intends to never work again, after his six space flights. The currency used in the state was universal, controlled by a personal credit card. Because most jobs were automated, few people had to work, so most people lived off of a set welfare, and those selected to work were given a little extra compensation. Si was one of these people. Gubelin and Perregaux are both horrified by the fact that Pond has decided to take an early retirement. He was their only pilot for their space program, and if they were to get another, it would take at least a year of training. Without a pilot, they are worried that their funding will be cut, and the space program will be shut down. They scheme together as to how to get Pond back in the space program. They think that the only way to get him back would be to make sure he was left without any money, and therefore would have no choice but to return to his former position. \\nSi is planning a big night out. He has always gone and celebrated when there was a cause, and tonight, he was planning to spend at least half of all the money in his account. He gets dressed in his retirement rank suit to go out, checks his balance, and then takes his vacuum tube to New york city. Before he leaves, he books a room at a swanky hotel for the rich and famous, and after a few moments, his car transports him to his room. There is an amazing view of the city, and from his room, gets ready to go to the bar. \\nAt the bar he orders a drink, before noticing a beautiful woman beside him. They get to talking and before long, she tells him she recognises him, telling him about how moved she found his whole retirement ceremony. Making it very clear she wasn't happy he was retiring. He asks why she has an interest in space, to which she replies that she always has. He begins to explain the aspects of space flight, when the right side of his mouth begins to tick, and he knocks his drink back. \", 'In the Ultrawelfare State, the kind of jobs that one does is decided through a lottery. The lottery is drawn whenever thereâ€™s a need for new employees. Those that work will receive some additional Variable Basic shares to be added to their portfolios. And once their portfolios reach a certain level of Variable Basic shares, they can afford to live the life in the way they prefer. The story begins with Seymour Pond, the space pilot that has been on six trips, receiving a gold watch and a banquet from the officials including Academician Lofting Gubelin, an anachronistic man, and Doctor Hans Girard-Perregaux to persuade him not to retire. Because there is no other space pilot at this time, and it takes a few months, if not a year, and much resources to train a new pilot ready to travel to the moon. But Pondâ€™s mind is set, heâ€™s had enough anxiety over space cafard, and he has quite a large amount of Variable Basic shares to support his living and to show off to the others. \\n\\nIn the escape room at Gubelinâ€™s Floridian home arguing with Girard-Perregaux, who states that he would do the same in the position that Pond is currently in. Because of the way that employment works in the Ultrawelfare State, Pond doesnâ€™t need to face danger anymore. The law does not even allow him to be selected to work again. Later, they decide to use the sailor way of life method to force Pond back to being a pilot again. \\n\\nPond is aware of the sailor way of life, and he does not want to spend his money in such a quick rush. After dressing himself in a great retirement-rank suit, he checks his balance and makes sure that he has enough money to spend. He goes to Manhattan and settles in a nicer room of the hotel, where he can see the Empire State Building Museum and the Hudson as well as the city. Then he decides to visit the Kudos Room for a drink where celebrities sometimes go. While he was disappointed to see no celebrities, he gets to talk to a beautiful girl who seems extremely interested in space travelling and admires him a lot. As he was explaining space cafard to the girl, he felt a tic on his mouth, so he quickly finishes his drink. ', 'Spacemen on a Spree begins at a banquet celebrating the retirement of Seymour Pondâ€™s, a space pilot. At the retirement banquet, Pond expresses smugness and content as he knows the program will not be viable without him. \\n\\nAfter the party, Hans and Gubelin discuss the significance of Pondâ€™s retirement. They are upset because the Department of Space Exploration is in jeopardy because they do not have another trained space pilot to replace Pond and it would take a long time to train one. Hans and Gubelin go back and forth discussing how best to convince Pond to return to the space pilot job. \\n\\nSeymour was grateful for each time he returned from his space runs and was ready to retire at the age of 30, which was allowed by the Ultrawelfare State. Once he is retired, Seymour expresses his desire to throw a big celebration. He intends to use a great deal of his money and wants to do so in a more controlled and lavish manner than he previously has. He dresses in a newly purchased suit and is careful to attach his space pin that clearly identifies his previous occupation. He takes transportation to a Manhattan hotel to execute his plan. He is satisfied with his hotel room and heads to the bar to enjoy some drinks. At the bar he sees a girl that he finds very attractive. The girl, Natalie Paskov, initially responds coldly to his attention but then becomes interested when she sees the space pin on his suit. Natalie then mentions that she recognizes him because she follows space news since it is an interest of hers. She expresses her sadness that he retired. The story ends with him talking about space cafard. \\n', 'Seymour Pond is retiring from being a space pilot. Gubelin and Perregaux, big figures in space exploration, want to urge the man to stay as space has to be delved further into. The problem is that there are not enough young people willing to venture and explore the space. Pond is the only trained pilot in the world and they need him, while he has just enough fortune to retire with comfort. Without him the whole space exploration department will be terminated, so Gubelin and Perregaux think of means to deprive Seymour of his money and force him to go back to space. Seymour at that time is planning how to spend his money - he wants to spend a huge sum on the best entertainment. So, the ex-Space Pilot heads towards Manhattan in an automatic car. Seymour gets a luxurious room in a hotel and goes to get a drink in an expensive bar there. There he meets a graceful Oriental girl, and he offers her a drink. Soon she recognizes the famous pilot and starts treating him like a celebrity with utmost surprise of the possibility of talking to him. Turns out she is a huge fan of space and Seymour starts telling her things. ']\n",
            "[DEBUG] Parser loads failed with: <string>:1 Unexpected \"S\" at column 1\n",
            "[DEBUG] Invalid JSON string:\n",
            "Schema:{\"search_query\":\"flight setting peculiar ability life-threatening situation story\",\"search_query_explanation\":\"This search query includes all the key elements mentioned by the user: setting, peculiar ability, life-threatening situation, and flight, which are all important aspects of the story they are interested in.\"}\n",
            "[DEBUG] Parser loads failed with: Expecting value: line 1 column 1 (char 0)\n",
            "[DEBUG] Invalid JSON string:\n",
            "Schema:{\"search_query\":\"flight setting peculiar ability life-threatening situation story\",\"search_query_explanation\":\"This search query includes all the key elements mentioned by the user: setting, peculiar ability, life-threatening situation, and flight, which are all important aspects of the story they are interested in.\"}\n",
            "[DEBUG] Final cleaned input (still invalid):\n",
            "Schema:{\"search_query\":\"flight setting peculiar ability life-threatening situation story\",\"search_query_explanation\":\"This search query includes all the key elements mentioned by the user: setting, peculiar ability, life-threatening situation, and flight, which are all important aspects of the story they are interested in.\"}\n",
            "Error: ['<string>:1 Unexpected \"S\" at column 1', 'Expecting value: line 1 column 1 (char 0)']\n",
            "Qwen/Qwen2.5-3B-Instruct-GPTQ-Int4\n",
            "Retrying...\n",
            "[DEBUG] Parser loads failed with: <string>:1 Unexpected \"S\" at column 1\n",
            "[DEBUG] Invalid JSON string:\n",
            "Schema:{\"search_query\":\"setting peculiar ability life-threatening situation flight\",\"search_query_explanation\":\"This search query includes the key aspects mentioned in the question: setting, peculiar ability, life-threatening situation, and flight. These terms will help in finding information about the story's context and the character's specific circumstances.\"}\n",
            "[DEBUG] Parser loads failed with: Expecting value: line 1 column 1 (char 0)\n",
            "[DEBUG] Invalid JSON string:\n",
            "Schema:{\"search_query\":\"setting peculiar ability life-threatening situation flight\",\"search_query_explanation\":\"This search query includes the key aspects mentioned in the question: setting, peculiar ability, life-threatening situation, and flight. These terms will help in finding information about the story's context and the character's specific circumstances.\"}\n",
            "[DEBUG] Final cleaned input (still invalid):\n",
            "Schema:{\"search_query\":\"setting peculiar ability life-threatening situation flight\",\"search_query_explanation\":\"This search query includes the key aspects mentioned in the question: setting, peculiar ability, life-threatening situation, and flight. These terms will help in finding information about the story's context and the character's specific circumstances.\"}\n",
            "Error: ['<string>:1 Unexpected \"S\" at column 1', 'Expecting value: line 1 column 1 (char 0)']\n",
            "Qwen/Qwen2.5-3B-Instruct-GPTQ-Int4\n",
            "Retrying...\n",
            "[DEBUG] Parser loads failed with: <string>:1 Unexpected \",\" at column 598\n",
            "[DEBUG] Invalid JSON string:\n",
            "{\"query_id\":0,\"relevance\":[{\"doc_id\":\"331\",\"is_relevant\":false,\"is_relevant_explanation\":\"The document is about a science fiction story titled 'The Fustians' and does not directly address the peculiar beings that resemble turtles or their life cycle and culture.\"},{\"doc_id\":\"957\",\"is_relevant\":true,\"is_relevant_explanation\":\"The document describes a group of robots that resemble the peculiar beings mentioned and discusses their unique characteristics and social dynamics.\"}],\"change_search_query\":true,\"new_search_query\":\"peculiar beings resembling turtles life cycle culture social dynamics\"},\"end_search\":false,\"end_search_explanation\":\"The first document is not relevant, and the second document is relevant. However, the search needs to be refined to better align with the question.\"}\n",
            "[DEBUG] Parser loads failed with: Extra data: line 1 column 598 (char 597)\n",
            "[DEBUG] Invalid JSON string:\n",
            "{\"query_id\":0,\"relevance\":[{\"doc_id\":\"331\",\"is_relevant\":false,\"is_relevant_explanation\":\"The document is about a science fiction story titled 'The Fustians' and does not directly address the peculiar beings that resemble turtles or their life cycle and culture.\"},{\"doc_id\":\"957\",\"is_relevant\":true,\"is_relevant_explanation\":\"The document describes a group of robots that resemble the peculiar beings mentioned and discusses their unique characteristics and social dynamics.\"}],\"change_search_query\":true,\"new_search_query\":\"peculiar beings resembling turtles life cycle culture social dynamics\"},\"end_search\":false,\"end_search_explanation\":\"The first document is not relevant, and the second document is relevant. However, the search needs to be refined to better align with the question.\"}\n",
            "[DEBUG] Final cleaned input (still invalid):\n",
            "{\"query_id\":0,\"relevance\":[{\"doc_id\":\"331\",\"is_relevant\":false,\"is_relevant_explanation\":\"The document is about a science fiction story titled 'The Fustians' and does not directly address the peculiar beings that resemble turtles or their life cycle and culture.\"},{\"doc_id\":\"957\",\"is_relevant\":true,\"is_relevant_explanation\":\"The document describes a group of robots that resemble the peculiar beings mentioned and discusses their unique characteristics and social dynamics.\"}],\"change_search_query\":true,\"new_search_query\":\"peculiar beings resembling turtles life cycle culture social dynamics\"},\"end_search\":false,\"end_search_explanation\":\"The first document is not relevant, and the second document is relevant. However, the search needs to be refined to better align with the question.\"}\n",
            "Error: ['<string>:1 Unexpected \",\" at column 598', 'Extra data: line 1 column 598 (char 597)']\n",
            "Qwen/Qwen2.5-3B-Instruct-GPTQ-Int4\n",
            "Retrying...\n",
            "Error: Error code: 400 - {'object': 'error', 'message': \"This model's maximum context length is 10240 tokens. However, you requested 12540 tokens in the messages, Please reduce the length of the messages.\", 'type': 'BadRequestError', 'param': None, 'code': 400}\n",
            "Qwen/Qwen2.5-3B-Instruct-GPTQ-Int4\n",
            "Retrying...\n",
            "Error: Error code: 400 - {'object': 'error', 'message': \"This model's maximum context length is 10240 tokens. However, you requested 12540 tokens in the messages, Please reduce the length of the messages.\", 'type': 'BadRequestError', 'param': None, 'code': 400}\n",
            "Qwen/Qwen2.5-3B-Instruct-GPTQ-Int4\n",
            "Retrying...\n",
            "Error: Error code: 400 - {'object': 'error', 'message': \"This model's maximum context length is 10240 tokens. However, you requested 12540 tokens in the messages, Please reduce the length of the messages.\", 'type': 'BadRequestError', 'param': None, 'code': 400}\n",
            "Qwen/Qwen2.5-3B-Instruct-GPTQ-Int4\n",
            "Retrying...\n",
            "[DEBUG] Parser loads failed with: <string>:1 Unexpected \",\" at column 1007\n",
            "[DEBUG] Invalid JSON string:\n",
            "{\"agent\":\"answerer\",\"input\":{\"question\":\"What are the key aspects of the life cycle and culture of the peculiar beings that resemble turtles but possess distinct characteristics and social dynamics?\",\"guidance\":\"Provide a structured response including the key aspects of the life cycle and culture of the creatures based on the provided information.\",\"important_information\":\"The Fustians resemble turtles and have a unique culture and social dynamics involving a group known as SCARS (Sexual, Cultural, and Athletic Recreational Society). They are described as long-lived and try to maim others in their hope of achieving their goals. They have been waiting for sponsorship for a few weeks, and the Terrestrial Embassy is in a competitive situation with the Groaci Embassy.\",\"reason\":\"The user's question requires information about the life cycle and culture of the Fustians. The provided document gives details about their characteristics and social dynamics, which can be used to answer the question.\"}},{\"answerer\",\"input\":{\"question\":\"What are the key aspects of the life cycle and culture of the peculiar beings that resemble turtles but possess distinct characteristics and social dynamics?\",\"guidance\":\"Provide a structured response including the key aspects of the life cycle and culture of the creatures based on the provided information.\",\"important_information\":\"The Fustians resemble turtles and have a unique culture and social dynamics involving a group known as SCARS (Sexual, Cultural, and Athletic Recreational Society). They are described as long-lived and try to maim others in their hope of achieving their goals. They have been waiting for sponsorship for a few weeks, and the Terrestrial Embassy is in a competitive situation with the Groaci Embassy.\",\"reason\":\"The provided information includes details about the life cycle and culture of the Fustians based on the document.\"}} {\"finisher\", \"input\": {\"finished\": true}, \"reason\": \"The answerer has generated a structured response based on the provided information, addressing the key aspects of the life cycle and culture of the Fustians as requested in the user's question.\"}\n",
            "[DEBUG] Parser loads failed with: Extra data: line 1 column 1007 (char 1006)\n",
            "[DEBUG] Invalid JSON string:\n",
            "{\"agent\":\"answerer\",\"input\":{\"question\":\"What are the key aspects of the life cycle and culture of the peculiar beings that resemble turtles but possess distinct characteristics and social dynamics?\",\"guidance\":\"Provide a structured response including the key aspects of the life cycle and culture of the creatures based on the provided information.\",\"important_information\":\"The Fustians resemble turtles and have a unique culture and social dynamics involving a group known as SCARS (Sexual, Cultural, and Athletic Recreational Society). They are described as long-lived and try to maim others in their hope of achieving their goals. They have been waiting for sponsorship for a few weeks, and the Terrestrial Embassy is in a competitive situation with the Groaci Embassy.\",\"reason\":\"The user's question requires information about the life cycle and culture of the Fustians. The provided document gives details about their characteristics and social dynamics, which can be used to answer the question.\"}},{\"answerer\",\"input\":{\"question\":\"What are the key aspects of the life cycle and culture of the peculiar beings that resemble turtles but possess distinct characteristics and social dynamics?\",\"guidance\":\"Provide a structured response including the key aspects of the life cycle and culture of the creatures based on the provided information.\",\"important_information\":\"The Fustians resemble turtles and have a unique culture and social dynamics involving a group known as SCARS (Sexual, Cultural, and Athletic Recreational Society). They are described as long-lived and try to maim others in their hope of achieving their goals. They have been waiting for sponsorship for a few weeks, and the Terrestrial Embassy is in a competitive situation with the Groaci Embassy.\",\"reason\":\"The provided information includes details about the life cycle and culture of the Fustians based on the document.\"}} {\"finisher\", \"input\": {\"finished\": true}, \"reason\": \"The answerer has generated a structured response based on the provided information, addressing the key aspects of the life cycle and culture of the Fustians as requested in the user's question.\"}\n",
            "[DEBUG] Final cleaned input (still invalid):\n",
            "{\"agent\":\"answerer\",\"input\":{\"question\":\"What are the key aspects of the life cycle and culture of the peculiar beings that resemble turtles but possess distinct characteristics and social dynamics?\",\"guidance\":\"Provide a structured response including the key aspects of the life cycle and culture of the creatures based on the provided information.\",\"important_information\":\"The Fustians resemble turtles and have a unique culture and social dynamics involving a group known as SCARS (Sexual, Cultural, and Athletic Recreational Society). They are described as long-lived and try to maim others in their hope of achieving their goals. They have been waiting for sponsorship for a few weeks, and the Terrestrial Embassy is in a competitive situation with the Groaci Embassy.\",\"reason\":\"The user's question requires information about the life cycle and culture of the Fustians. The provided document gives details about their characteristics and social dynamics, which can be used to answer the question.\"}},{\"answerer\",\"input\":{\"question\":\"What are the key aspects of the life cycle and culture of the peculiar beings that resemble turtles but possess distinct characteristics and social dynamics?\",\"guidance\":\"Provide a structured response including the key aspects of the life cycle and culture of the creatures based on the provided information.\",\"important_information\":\"The Fustians resemble turtles and have a unique culture and social dynamics involving a group known as SCARS (Sexual, Cultural, and Athletic Recreational Society). They are described as long-lived and try to maim others in their hope of achieving their goals. They have been waiting for sponsorship for a few weeks, and the Terrestrial Embassy is in a competitive situation with the Groaci Embassy.\",\"reason\":\"The provided information includes details about the life cycle and culture of the Fustians based on the document.\"}} {\"finisher\", \"input\": {\"finished\": true}, \"reason\": \"The answerer has generated a structured response based on the provided information, addressing the key aspects of the life cycle and culture of the Fustians as requested in the user's question.\"}\n",
            "Error: ['<string>:1 Unexpected \",\" at column 1007', 'Extra data: line 1 column 1007 (char 1006)']\n",
            "Qwen/Qwen2.5-3B-Instruct-GPTQ-Int4\n",
            "Retrying...\n",
            "Error: Error code: 400 - {'object': 'error', 'message': \"This model's maximum context length is 10240 tokens. However, you requested 12540 tokens in the messages, Please reduce the length of the messages.\", 'type': 'BadRequestError', 'param': None, 'code': 400}\n",
            "Qwen/Qwen2.5-3B-Instruct-GPTQ-Int4\n",
            "Retrying...\n",
            "Error: Error code: 400 - {'object': 'error', 'message': \"This model's maximum context length is 10240 tokens. However, you requested 12540 tokens in the messages, Please reduce the length of the messages.\", 'type': 'BadRequestError', 'param': None, 'code': 400}\n",
            "Qwen/Qwen2.5-3B-Instruct-GPTQ-Int4\n",
            "Retrying...\n",
            "Error: Error code: 400 - {'object': 'error', 'message': \"This model's maximum context length is 10240 tokens. However, you requested 12540 tokens in the messages, Please reduce the length of the messages.\", 'type': 'BadRequestError', 'param': None, 'code': 400}\n",
            "Qwen/Qwen2.5-3B-Instruct-GPTQ-Int4\n",
            "Retrying...\n",
            "Error: Error code: 400 - {'object': 'error', 'message': \"This model's maximum context length is 10240 tokens. However, you requested 12540 tokens in the messages, Please reduce the length of the messages.\", 'type': 'BadRequestError', 'param': None, 'code': 400}\n",
            "Qwen/Qwen2.5-3B-Instruct-GPTQ-Int4\n",
            "Retrying...\n",
            "Error: Error code: 400 - {'object': 'error', 'message': \"This model's maximum context length is 10240 tokens. However, you requested 12540 tokens in the messages, Please reduce the length of the messages.\", 'type': 'BadRequestError', 'param': None, 'code': 400}\n",
            "Qwen/Qwen2.5-3B-Instruct-GPTQ-Int4\n",
            "Retrying...\n",
            "Error: Error code: 400 - {'object': 'error', 'message': \"This model's maximum context length is 10240 tokens. However, you requested 12540 tokens in the messages, Please reduce the length of the messages.\", 'type': 'BadRequestError', 'param': None, 'code': 400}\n",
            "Qwen/Qwen2.5-3B-Instruct-GPTQ-Int4\n",
            "Retrying...\n",
            "Error: Error code: 400 - {'object': 'error', 'message': \"This model's maximum context length is 10240 tokens. However, you requested 12540 tokens in the messages, Please reduce the length of the messages.\", 'type': 'BadRequestError', 'param': None, 'code': 400}\n",
            "Qwen/Qwen2.5-3B-Instruct-GPTQ-Int4\n",
            "Retrying...\n",
            "[DEBUG] Parser loads failed with: <string>:1 Unexpected \"c\" at column 1\n",
            "[DEBUG] Invalid JSON string:\n",
            "cannot generate a response\n",
            "[DEBUG] Parser loads failed with: Expecting value: line 1 column 1 (char 0)\n",
            "[DEBUG] Invalid JSON string:\n",
            "cannot generate a response\n",
            "[DEBUG] Final cleaned input (still invalid):\n",
            "cannot generate a response\n",
            "Error processing query 'Q4. Describe the setting(s) of the story, which revolves around a character with a peculiar ability who faces a life-threatening situation during a flight. Why is it important?': ['<string>:1 Unexpected \"c\" at column 1', 'Expecting value: line 1 column 1 (char 0)']\n",
            "Saved intermediate results to /content/drive/MyDrive/mRAG_and_MSRS_source/experiences/experience.json_0\n",
            "SUBMIT q: What is the plot of the story that revolves around a character struggling with a lack of special abilities in a family of talented individuals, ultimately leading to unexpected revelations and conflicts with an alien race?\n",
            "SUBMIT a: ['This story takes place in the year 2102 and centers around a family with powers, including telekenisis and teleportation. The narrator is Kevin, one of the sons: he is the only person in the family without powers, a \"psi-deficient\", so he stays at home to take care of the house. The story starts at the breakfast table, where the father teleports in, the mother probes the others\\' thoughts, and there is grumbling about the goings-on in the household. Timothy, the youngest brother, senses turmoil in the family but is also the most hopeful--he figures that Kevin has a gift they just haven\\'t discovered yet, which is encouraging to Kevin. After everyone else in the family leaves for their jobs, Kevin is left to think about his situation, so he goes for a long walk. Reading is his only other real source of entertainment; he doesn\\'t have many friends because nobody wanted to play sports with someone without telepathic abilities. He couldn\\'t explore space because other planets weren\\'t habitable, so he wondered what would make him stand out. The reader learns that the psi powers were latent in humans and developed with exposure to nuclear energy. When he gets home from his walk, Kevin\\'s entire family is there, processing some news. There are two inhabited planets in Alpha Centauri, and the aliens there might be preparing for war.  Kevin partly hoped there would be war for a change of pace, and his mom figured people should start learning first-aid, including Kevin. He had a benefit over his sister because he couldn\\'t sense others\\' pain in the same way. He met a girl named Lucy in his first-aid class who he liked, and she was a \"low-grade telesensitive\" so he didn\\'t have to worry about his thoughts being read. Once the aliens attacked, things got hard as Kevin had to face the injured people bought to his care. This was especially shocking because injury was not common in his world. This was where Kevin finally found his power: touching the injured people healed them almost instantly. It turned out he was the only human with this power, which was invaluable -- a hospital was even built just for Kevin to work in, where Lucy became his assistant. All at once, he became the most important human on the planet, but the humans had to hide this from their alien adversaries. Lucy was jealous of Kevin but also worried about what would happen to Kevin when the war ended, which it eventually did four months later. The story ends with Kevin returning home after the Vice President informed him that his services were no longer needed. ', \"Kevin Faraday is psi-deficient in a family of five with special psi powers living in a world largely free of disease and conflict. His father is telepathic and uses this ability to help him get to long-distance appointments as a traveling salesman. His middle brother, Danny, has the power of telekinesis and works as a junior partner in a moving company. Kevin's sister, Sylvia, can sense emotions in people, so she is able to tell when he purposefully intensifies his anger to make her feel uncomfortable. The youngest of the family is Timothy, who works as a weather forecaster thanks to his powerful gift of prognostication. Kevin's mother is a psychiatrist with telepathic powers that she uses to read his mind. In fact, most people in the world have some kind of telepathic powers--they can read the minds of others unprotected by mind shields. While the rest of the family treats him awkwardly and goes off to their respective jobs every day, Kevin stays at home to maintain the house. However, even this task makes him feel largely useless because most of the chores can be completed by household machines. Therefore, Kevin spends much of his time daydreaming about what life would have been like for him had he been living in 1960 instead of 2102. He feels a stronger empathy for dying plants than he does for other humans, and this has given him the reputation of callousness. Although Kevin is largely resigned to his fate as a psi-deficient in a world of people with special powers, his brother Tim insists that he has some ability; it simply hasn't been discovered yet. The rest of the family shrugs off this notion, but Kevin secretly latches onto this hope. Because of his inability to tap into the telepathically-broadcast news transmissions, Kevin's family one day alerts him that a starship has returned to Earth from Alpha Centauri, where its crew had discovered two Earth-type planets. This excites Kevin, but unfortunately, the inhabitants of these planets are hostile, and they eventually make their way to Earth to begin a war. In preparation for the war, Kevin's mother encourages him and Sylvia to learn first-aid techniques at the Psycho Center in order to be ready to help the injured. During his training, Kevin meets a girl named Lucy, who flirts with him and admires his strength. When Kevin gets his first patient, he is shocked to discover that he is able to heal the injured man with a simple touch of his hands. Having discovered his new ability, Kevin sets out to heal as many of the wounded as possible; later, he learns that he is the only psi-negative in the world with this ability. Eventually, he is given his own hospital and hailed as a hero by various dignitaries including the President. When the war ends and the aliens surrender, however, Earth is no longer in need of his services, and he is out of a job again.\\n\", 'In the year 2102, the Faraday family are setting the table and gathering for a meal together in their home. Humans have supernatural powers (psi-powers) that began to show after nuclear energy was developed in the 1960s, and most of the family have special abilities. Father can teleport, Mother (Amy) is a telepathic psychiatrist, Dan (Danny) can move objects via telekinesis, Sylvia is telesensitive, and Tim can predict the future. Kevin (Kev) has no apparent powers, and feels disconnected and isolated from most of his family because without powers he is of little use to society. The exception is his brother Tim, who suggests that there just isnâ€™t a test yet for the powers that Kev has. His father asks if they should send him to a psychiatrist again, and his mother expresses disappointment at the amount of tests that have been run on Kev with no sign of psi-powers. \\nKev is crestfallen that he doesnâ€™t really have any life other than going on long walks and watching the house. He is sad he never had the chance to try exploring space, but by the time he was ten years old humans had already concluded that all the other planets were unsuited to human life. \\nThere are television-like telepathic projections in the society called â€œtelliesâ€ that those with psi-powers receive. One day, a tellie reports that space explorers from Earth have found two inhabited Earth-type planets in Alpha Centauri. The aliens chased off the humans in their own spaceships and now it is possible that aliens could attack Earth in less than six months. Kevâ€™s mother decides there will be a lot more people in need of medical training to treat casualties if there is an attack, and recruits Sylvia and Kev to train at the Psycho Center. During training, Kev meets a girl named Lucie who is a poet and they develop a fond relationship with each other. When alien weapons begin striking near their town, the casualties start rolling into the Psycho Center and Kev tries to run away at the first sight of the violent wounds. His mother forces him to stay and work. He is so shaky he canâ€™t hold a sponge to clean the blood off a person that is missing half of their face and drops it, accidentally pushing his fingers into the bloody wound. Touching the wound this way cures it completely. Kev quickly grows into a famous sensation who is able to heal any wounds. He is the only person on Earth with this psi-ability, and there is a special clinic built just for him. Lucie becomes his assistant. Presidents and generals visit him and present him with medals and honors. After four months, the war ends and peace returns to Earth. The Vice President thanks Kev on behalf of the country.\\n', 'Kevin is the only member of the Faraday family without psi-powers. His two brothers, sister, mother, and father are all extremely powerful individuals, but he, at the ripe age of 26 years old, had nothing. Because of this, he was considered an outcast and was forced to work in their home instead of in the outside world. People pitied him and looked down on him, which drove him crazy. The story begins at the breakfast table with Danny using his powers to levitate food in and out of the kitchen. Chaos ensues as the orange juice crashes into his sister, Sylvia, who senses Kevinâ€™s displeasure at his brazen use of psi-power. Their father soon appears out of thin air with his briefcase, while his mother strolls down and instantly reads Kevinâ€™s mind, only making him madder. The situation escalates until Tim, the youngest, strolls in and claims that Kevinâ€™s powers have yet to present themselves, which gives Kevin hope. His family leaves for work, and Kevin is left at home alone again. \\nKevin watches the servomechanisms as they clean and manage the house. Of course, sometimes they break down and he is needed, but largely he has nothing to do and is bored. In the year 2102, Kevin Faraday was considered useless. He takes a long walk that day, and when he returns home, his family is buzzing with the news. A spaceship returned from Alpha Centauri claiming they ran into inhabitable planets filled with humanoid aliens. One of the aliens followed them back to Earth, then turned around and headed home. They were hostile creatures and attacked them on sight. Earth had six months to prepare for the potential of war, so Kevin and his siblings learned first-aid techniques at the Psycho Center. There, Kevin meets Lucy, a cute blonde poetess who expresses interest in him. \\nWhen the first bomb strikes, Kevin is faced with his first injured patient. His face had been blown up in the explosion, and Kevin canâ€™t handle the sight, so he tries to run away. He is stopped by his mother, however, who scolds him and sends him back to his patient. As he is mopping his face with a sponge, his hand slips and he accidentally touches his patient skin-to-skin. Miraculously, his injuries are cured, and Kevinâ€™s powers are finally discovered. He is a healer. \\nHe heals the rest of the injured with just a touch and soon becomes the most important man in the world. He gets his own special hospital, where Lucy is his assistant, and visits from Presidents, cabinet members, and other people of power. He heals everyone who is injured in the war and loves the new attention. He is the only healer, and those who had his abilities in the past were kings. \\nHowever, four months later, the war ends and the Centaurions blow themselves up in surrender. The story ends with a question: will Kevin still be as needed in a post-war society? \\n']\n",
            "q: What is the plot of the story that revolves around a character struggling with a lack of special abilities in a family of talented individuals, ultimately leading to unexpected revelations and conflicts with an alien race?\n",
            "a: ['This story takes place in the year 2102 and centers around a family with powers, including telekenisis and teleportation. The narrator is Kevin, one of the sons: he is the only person in the family without powers, a \"psi-deficient\", so he stays at home to take care of the house. The story starts at the breakfast table, where the father teleports in, the mother probes the others\\' thoughts, and there is grumbling about the goings-on in the household. Timothy, the youngest brother, senses turmoil in the family but is also the most hopeful--he figures that Kevin has a gift they just haven\\'t discovered yet, which is encouraging to Kevin. After everyone else in the family leaves for their jobs, Kevin is left to think about his situation, so he goes for a long walk. Reading is his only other real source of entertainment; he doesn\\'t have many friends because nobody wanted to play sports with someone without telepathic abilities. He couldn\\'t explore space because other planets weren\\'t habitable, so he wondered what would make him stand out. The reader learns that the psi powers were latent in humans and developed with exposure to nuclear energy. When he gets home from his walk, Kevin\\'s entire family is there, processing some news. There are two inhabited planets in Alpha Centauri, and the aliens there might be preparing for war.  Kevin partly hoped there would be war for a change of pace, and his mom figured people should start learning first-aid, including Kevin. He had a benefit over his sister because he couldn\\'t sense others\\' pain in the same way. He met a girl named Lucy in his first-aid class who he liked, and she was a \"low-grade telesensitive\" so he didn\\'t have to worry about his thoughts being read. Once the aliens attacked, things got hard as Kevin had to face the injured people bought to his care. This was especially shocking because injury was not common in his world. This was where Kevin finally found his power: touching the injured people healed them almost instantly. It turned out he was the only human with this power, which was invaluable -- a hospital was even built just for Kevin to work in, where Lucy became his assistant. All at once, he became the most important human on the planet, but the humans had to hide this from their alien adversaries. Lucy was jealous of Kevin but also worried about what would happen to Kevin when the war ended, which it eventually did four months later. The story ends with Kevin returning home after the Vice President informed him that his services were no longer needed. ', \"Kevin Faraday is psi-deficient in a family of five with special psi powers living in a world largely free of disease and conflict. His father is telepathic and uses this ability to help him get to long-distance appointments as a traveling salesman. His middle brother, Danny, has the power of telekinesis and works as a junior partner in a moving company. Kevin's sister, Sylvia, can sense emotions in people, so she is able to tell when he purposefully intensifies his anger to make her feel uncomfortable. The youngest of the family is Timothy, who works as a weather forecaster thanks to his powerful gift of prognostication. Kevin's mother is a psychiatrist with telepathic powers that she uses to read his mind. In fact, most people in the world have some kind of telepathic powers--they can read the minds of others unprotected by mind shields. While the rest of the family treats him awkwardly and goes off to their respective jobs every day, Kevin stays at home to maintain the house. However, even this task makes him feel largely useless because most of the chores can be completed by household machines. Therefore, Kevin spends much of his time daydreaming about what life would have been like for him had he been living in 1960 instead of 2102. He feels a stronger empathy for dying plants than he does for other humans, and this has given him the reputation of callousness. Although Kevin is largely resigned to his fate as a psi-deficient in a world of people with special powers, his brother Tim insists that he has some ability; it simply hasn't been discovered yet. The rest of the family shrugs off this notion, but Kevin secretly latches onto this hope. Because of his inability to tap into the telepathically-broadcast news transmissions, Kevin's family one day alerts him that a starship has returned to Earth from Alpha Centauri, where its crew had discovered two Earth-type planets. This excites Kevin, but unfortunately, the inhabitants of these planets are hostile, and they eventually make their way to Earth to begin a war. In preparation for the war, Kevin's mother encourages him and Sylvia to learn first-aid techniques at the Psycho Center in order to be ready to help the injured. During his training, Kevin meets a girl named Lucy, who flirts with him and admires his strength. When Kevin gets his first patient, he is shocked to discover that he is able to heal the injured man with a simple touch of his hands. Having discovered his new ability, Kevin sets out to heal as many of the wounded as possible; later, he learns that he is the only psi-negative in the world with this ability. Eventually, he is given his own hospital and hailed as a hero by various dignitaries including the President. When the war ends and the aliens surrender, however, Earth is no longer in need of his services, and he is out of a job again.\\n\", 'In the year 2102, the Faraday family are setting the table and gathering for a meal together in their home. Humans have supernatural powers (psi-powers) that began to show after nuclear energy was developed in the 1960s, and most of the family have special abilities. Father can teleport, Mother (Amy) is a telepathic psychiatrist, Dan (Danny) can move objects via telekinesis, Sylvia is telesensitive, and Tim can predict the future. Kevin (Kev) has no apparent powers, and feels disconnected and isolated from most of his family because without powers he is of little use to society. The exception is his brother Tim, who suggests that there just isnâ€™t a test yet for the powers that Kev has. His father asks if they should send him to a psychiatrist again, and his mother expresses disappointment at the amount of tests that have been run on Kev with no sign of psi-powers. \\nKev is crestfallen that he doesnâ€™t really have any life other than going on long walks and watching the house. He is sad he never had the chance to try exploring space, but by the time he was ten years old humans had already concluded that all the other planets were unsuited to human life. \\nThere are television-like telepathic projections in the society called â€œtelliesâ€ that those with psi-powers receive. One day, a tellie reports that space explorers from Earth have found two inhabited Earth-type planets in Alpha Centauri. The aliens chased off the humans in their own spaceships and now it is possible that aliens could attack Earth in less than six months. Kevâ€™s mother decides there will be a lot more people in need of medical training to treat casualties if there is an attack, and recruits Sylvia and Kev to train at the Psycho Center. During training, Kev meets a girl named Lucie who is a poet and they develop a fond relationship with each other. When alien weapons begin striking near their town, the casualties start rolling into the Psycho Center and Kev tries to run away at the first sight of the violent wounds. His mother forces him to stay and work. He is so shaky he canâ€™t hold a sponge to clean the blood off a person that is missing half of their face and drops it, accidentally pushing his fingers into the bloody wound. Touching the wound this way cures it completely. Kev quickly grows into a famous sensation who is able to heal any wounds. He is the only person on Earth with this psi-ability, and there is a special clinic built just for him. Lucie becomes his assistant. Presidents and generals visit him and present him with medals and honors. After four months, the war ends and peace returns to Earth. The Vice President thanks Kev on behalf of the country.\\n', 'Kevin is the only member of the Faraday family without psi-powers. His two brothers, sister, mother, and father are all extremely powerful individuals, but he, at the ripe age of 26 years old, had nothing. Because of this, he was considered an outcast and was forced to work in their home instead of in the outside world. People pitied him and looked down on him, which drove him crazy. The story begins at the breakfast table with Danny using his powers to levitate food in and out of the kitchen. Chaos ensues as the orange juice crashes into his sister, Sylvia, who senses Kevinâ€™s displeasure at his brazen use of psi-power. Their father soon appears out of thin air with his briefcase, while his mother strolls down and instantly reads Kevinâ€™s mind, only making him madder. The situation escalates until Tim, the youngest, strolls in and claims that Kevinâ€™s powers have yet to present themselves, which gives Kevin hope. His family leaves for work, and Kevin is left at home alone again. \\nKevin watches the servomechanisms as they clean and manage the house. Of course, sometimes they break down and he is needed, but largely he has nothing to do and is bored. In the year 2102, Kevin Faraday was considered useless. He takes a long walk that day, and when he returns home, his family is buzzing with the news. A spaceship returned from Alpha Centauri claiming they ran into inhabitable planets filled with humanoid aliens. One of the aliens followed them back to Earth, then turned around and headed home. They were hostile creatures and attacked them on sight. Earth had six months to prepare for the potential of war, so Kevin and his siblings learned first-aid techniques at the Psycho Center. There, Kevin meets Lucy, a cute blonde poetess who expresses interest in him. \\nWhen the first bomb strikes, Kevin is faced with his first injured patient. His face had been blown up in the explosion, and Kevin canâ€™t handle the sight, so he tries to run away. He is stopped by his mother, however, who scolds him and sends him back to his patient. As he is mopping his face with a sponge, his hand slips and he accidentally touches his patient skin-to-skin. Miraculously, his injuries are cured, and Kevinâ€™s powers are finally discovered. He is a healer. \\nHe heals the rest of the injured with just a touch and soon becomes the most important man in the world. He gets his own special hospital, where Lucy is his assistant, and visits from Presidents, cabinet members, and other people of power. He heals everyone who is injured in the war and loves the new attention. He is the only healer, and those who had his abilities in the past were kings. \\nHowever, four months later, the war ends and the Centaurions blow themselves up in surrender. The story ends with a question: will Kevin still be as needed in a post-war society? \\n']\n",
            "[DEBUG] Parser loads failed with: <string>:1 Unexpected end of input at column 943\n",
            "[DEBUG] Invalid JSON string:\n",
            "{\"agent\":\"answerer\",\"input\":{\"question\": \"What is the plot of the story that revolves around a character struggling with a lack of special abilities in a family of talented individuals, ultimately leading to unexpected revelations and conflicts with an alien race?\",\"important_information\": \"The story is set on Earth where a family of talented psi-boys have a defective member, a character named Kev who struggles with his lack of special abilities. The story revolves around Kev's daily life, his struggles, and eventual unexpected revelations and conflicts.\", \"guidance\": \"Generate a response that includes the main plot points of the story as described in the document, focusing on the character's struggles and the unexpected revelations and conflicts with an alien race.\", \"reason\": \"The document contains the plot of the story that fits the user's description. The answerer can now generate a response using the information provided.\"}\n",
            "[DEBUG] Parser loads failed with: Expecting ',' delimiter: line 1 column 943 (char 942)\n",
            "[DEBUG] Invalid JSON string:\n",
            "{\"agent\":\"answerer\",\"input\":{\"question\": \"What is the plot of the story that revolves around a character struggling with a lack of special abilities in a family of talented individuals, ultimately leading to unexpected revelations and conflicts with an alien race?\",\"important_information\": \"The story is set on Earth where a family of talented psi-boys have a defective member, a character named Kev who struggles with his lack of special abilities. The story revolves around Kev's daily life, his struggles, and eventual unexpected revelations and conflicts.\", \"guidance\": \"Generate a response that includes the main plot points of the story as described in the document, focusing on the character's struggles and the unexpected revelations and conflicts with an alien race.\", \"reason\": \"The document contains the plot of the story that fits the user's description. The answerer can now generate a response using the information provided.\"}\n",
            "[DEBUG] Final cleaned input (still invalid):\n",
            "{\"agent\":\"answerer\",\"input\":{\"question\": \"What is the plot of the story that revolves around a character struggling with a lack of special abilities in a family of talented individuals, ultimately leading to unexpected revelations and conflicts with an alien race?\",\"important_information\": \"The story is set on Earth where a family of talented psi-boys have a defective member, a character named Kev who struggles with his lack of special abilities. The story revolves around Kev's daily life, his struggles, and eventual unexpected revelations and conflicts.\", \"guidance\": \"Generate a response that includes the main plot points of the story as described in the document, focusing on the character's struggles and the unexpected revelations and conflicts with an alien race.\", \"reason\": \"The document contains the plot of the story that fits the user's description. The answerer can now generate a response using the information provided.\"}\n",
            "Error: ['<string>:1 Unexpected end of input at column 943', \"Expecting ',' delimiter: line 1 column 943 (char 942)\"]\n",
            "Qwen/Qwen2.5-3B-Instruct-GPTQ-Int4\n",
            "Retrying...\n",
            "[DEBUG] Parser loads failed with: <string>:1 Unexpected \"\"\" at column 1045\n",
            "[DEBUG] Invalid JSON string:\n",
            "{\"agent\":\"answerer\",\"input\":{\"question\": \"What is the plot of the story that revolves around a character struggling with a lack of special abilities in a family of talented individuals, ultimately leading to unexpected revelations and conflicts with an alien race?\",\"important_information\": \"The story is about a character named Kev who has no special abilities and has to take care of the house, watch machines, and do chores due to his lack of special abilities. He struggles with this and takes long walks to pass the time. He doesn't have a girlfriend because he can't go out with them without being ridiculed. Eventually, the story leads to unexpected revelations and conflicts with an alien race.\", \"guidance\": \"Provide a concise response that covers the main plot points of the story as described in the document, including the struggles of the character with his lack of special abilities and the eventual conflict with an alien race.\", \"reason\": \"The document provided a detailed plot of the story that fits the user's description.\"},{\"agent\":\"finisher\",\"input\":{\"finished\": true},\"reason\": \"The answerer has provided a concise response that covers the main plot points of the story as described in the document.\"}\n",
            "[DEBUG] Parser loads failed with: Expecting property name enclosed in double quotes: line 1 column 1044 (char 1043)\n",
            "[DEBUG] Invalid JSON string:\n",
            "{\"agent\":\"answerer\",\"input\":{\"question\": \"What is the plot of the story that revolves around a character struggling with a lack of special abilities in a family of talented individuals, ultimately leading to unexpected revelations and conflicts with an alien race?\",\"important_information\": \"The story is about a character named Kev who has no special abilities and has to take care of the house, watch machines, and do chores due to his lack of special abilities. He struggles with this and takes long walks to pass the time. He doesn't have a girlfriend because he can't go out with them without being ridiculed. Eventually, the story leads to unexpected revelations and conflicts with an alien race.\", \"guidance\": \"Provide a concise response that covers the main plot points of the story as described in the document, including the struggles of the character with his lack of special abilities and the eventual conflict with an alien race.\", \"reason\": \"The document provided a detailed plot of the story that fits the user's description.\"},{\"agent\":\"finisher\",\"input\":{\"finished\": true},\"reason\": \"The answerer has provided a concise response that covers the main plot points of the story as described in the document.\"}\n",
            "[DEBUG] Final cleaned input (still invalid):\n",
            "{\"agent\":\"answerer\",\"input\":{\"question\": \"What is the plot of the story that revolves around a character struggling with a lack of special abilities in a family of talented individuals, ultimately leading to unexpected revelations and conflicts with an alien race?\",\"important_information\": \"The story is about a character named Kev who has no special abilities and has to take care of the house, watch machines, and do chores due to his lack of special abilities. He struggles with this and takes long walks to pass the time. He doesn't have a girlfriend because he can't go out with them without being ridiculed. Eventually, the story leads to unexpected revelations and conflicts with an alien race.\", \"guidance\": \"Provide a concise response that covers the main plot points of the story as described in the document, including the struggles of the character with his lack of special abilities and the eventual conflict with an alien race.\", \"reason\": \"The document provided a detailed plot of the story that fits the user's description.\"},{\"agent\":\"finisher\",\"input\":{\"finished\": true},\"reason\": \"The answerer has provided a concise response that covers the main plot points of the story as described in the document.\"}\n",
            "Error: ['<string>:1 Unexpected \"\"\" at column 1045', 'Expecting property name enclosed in double quotes: line 1 column 1044 (char 1043)']\n",
            "Qwen/Qwen2.5-3B-Instruct-GPTQ-Int4\n",
            "Retrying...\n",
            "[DEBUG] Parser loads failed with: <string>:3 Unexpected \"{\" at column 1\n",
            "[DEBUG] Invalid JSON string:\n",
            "{\"agent\":\"answerer\",\"input\":{\"question\": \"What is the plot of the story that revolves around a character struggling with a lack of special abilities in a family of talented individuals, ultimately leading to unexpected revelations and conflicts with an alien race?\",\"important_information\": \"The story is about a character named Kev who is psi-negative, meaning he has no special abilities, and has no job. His family consists of a psychiatrist, a writer, a meteorologist, a furniture mover, and a machine-sitter (Kev). His lack of abilities leads to a life of boredom and routine, and he is constantly watched by his family to ensure they don't need him for anything. He has to take care of the house, and if anything breaks, it takes days to fix. His only escape from this routine is to read books from the local Archives. He can't develop a talent for art, and the only thing he enjoys is taking long walks, but he can't compete with the psi-boys in sports. He also has to watch out for his family's gossip as they can hear what he thinks about them. Eventually, he is approached by an alien race that wants to use his body as a host for their aliens.\", \"guidance\": \"Provide a concise summary of the plot focusing on the character's struggles, the unexpected revelations, and the conflicts with the alien race.\", \"reason\": \"The provided document contains the information needed to answer the question about the plot of the story. It describes the protagonist's lack of abilities, family dynamics, and eventual conflicts with an alien race.\"}\n",
            "\n",
            "{\"agent\":\"finisher\",\"input\":{\"finished\": true},\"reason\": \"The document provides enough information to answer the question about the plot of the story. The plot is now clear, including the character's struggles, unexpected revelations, and conflicts with the alien race.\"}\n",
            "[DEBUG] Parser loads failed with: Expecting ',' delimiter: line 3 column 1 (char 1546)\n",
            "[DEBUG] Invalid JSON string:\n",
            "{\"agent\":\"answerer\",\"input\":{\"question\": \"What is the plot of the story that revolves around a character struggling with a lack of special abilities in a family of talented individuals, ultimately leading to unexpected revelations and conflicts with an alien race?\",\"important_information\": \"The story is about a character named Kev who is psi-negative, meaning he has no special abilities, and has no job. His family consists of a psychiatrist, a writer, a meteorologist, a furniture mover, and a machine-sitter (Kev). His lack of abilities leads to a life of boredom and routine, and he is constantly watched by his family to ensure they don't need him for anything. He has to take care of the house, and if anything breaks, it takes days to fix. His only escape from this routine is to read books from the local Archives. He can't develop a talent for art, and the only thing he enjoys is taking long walks, but he can't compete with the psi-boys in sports. He also has to watch out for his family's gossip as they can hear what he thinks about them. Eventually, he is approached by an alien race that wants to use his body as a host for their aliens.\", \"guidance\": \"Provide a concise summary of the plot focusing on the character's struggles, the unexpected revelations, and the conflicts with the alien race.\", \"reason\": \"The provided document contains the information needed to answer the question about the plot of the story. It describes the protagonist's lack of abilities, family dynamics, and eventual conflicts with an alien race.\"}\n",
            "\n",
            "{\"agent\":\"finisher\",\"input\":{\"finished\": true},\"reason\": \"The document provides enough information to answer the question about the plot of the story. The plot is now clear, including the character's struggles, unexpected revelations, and conflicts with the alien race.\"}\n",
            "[DEBUG] Final cleaned input (still invalid):\n",
            "{\"agent\":\"answerer\",\"input\":{\"question\": \"What is the plot of the story that revolves around a character struggling with a lack of special abilities in a family of talented individuals, ultimately leading to unexpected revelations and conflicts with an alien race?\",\"important_information\": \"The story is about a character named Kev who is psi-negative, meaning he has no special abilities, and has no job. His family consists of a psychiatrist, a writer, a meteorologist, a furniture mover, and a machine-sitter (Kev). His lack of abilities leads to a life of boredom and routine, and he is constantly watched by his family to ensure they don't need him for anything. He has to take care of the house, and if anything breaks, it takes days to fix. His only escape from this routine is to read books from the local Archives. He can't develop a talent for art, and the only thing he enjoys is taking long walks, but he can't compete with the psi-boys in sports. He also has to watch out for his family's gossip as they can hear what he thinks about them. Eventually, he is approached by an alien race that wants to use his body as a host for their aliens.\", \"guidance\": \"Provide a concise summary of the plot focusing on the character's struggles, the unexpected revelations, and the conflicts with the alien race.\", \"reason\": \"The provided document contains the information needed to answer the question about the plot of the story. It describes the protagonist's lack of abilities, family dynamics, and eventual conflicts with an alien race.\"}\n",
            "\n",
            "{\"agent\":\"finisher\",\"input\":{\"finished\": true},\"reason\": \"The document provides enough information to answer the question about the plot of the story. The plot is now clear, including the character's struggles, unexpected revelations, and conflicts with the alien race.\"}\n",
            "Error: ['<string>:3 Unexpected \"{\" at column 1', \"Expecting ',' delimiter: line 3 column 1 (char 1546)\"]\n",
            "Qwen/Qwen2.5-3B-Instruct-GPTQ-Int4\n",
            "Retrying...\n",
            "Saved intermediate results to /content/drive/MyDrive/mRAG_and_MSRS_source/experiences/experience.json_0\n",
            "Final results saved to /content/drive/MyDrive/mRAG_and_MSRS_source/experiences/experience.json_0\n",
            "\n",
            "WARNING: Using incubator modules: jdk.incubator.vector\n",
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\n",
            "                                     \n",
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\n",
            "                                     \n",
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\n",
            "                                     \n",
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\n",
            "                                     \n",
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\n",
            "                                     \n",
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\n",
            "                                     \n",
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\n",
            "                                     \n",
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\n",
            "                                     \n",
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\n",
            "                                     \n",
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\n",
            "                                     \n",
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\n",
            "                                     \n",
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\n",
            "                                     \n",
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\n",
            "                                     \n",
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\n",
            "                                     \n",
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\n",
            "                                     \n",
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\n",
            "                                     \n",
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]Dec 02, 2025 8:57:50 PM org.apache.lucene.store.MemorySegmentIndexInputProvider <init>\n",
            "INFO: Using MemorySegmentIndexInput with Java 21; to disable start with -Dorg.apache.lucene.store.MMapDirectory.enableMemorySegments=false\n",
            "\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:20<00:00, 80.46s/it]\n",
            "                                             \n",
            "\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:20<00:00, 80.46s/it]\n",
            "                                             \n",
            "\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:20<00:00, 80.46s/it]\n",
            "                                             \n",
            "\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:20<00:00, 80.46s/it]\n",
            "                                             \n",
            "\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:20<00:00, 80.46s/it]\n",
            "2it [02:24, 70.57s/it]                       \n",
            "2it [02:24, 72.05s/it]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#NOTE: Scoring using Reward model/ server\n",
        "\n",
        "#Minimal Run, num threads = 1 and num samples = 1\n",
        "\n",
        "#!source \"/*address to the bin directory of the venv*/\"\n",
        "!mamba run -n train_and_test python -u \"/content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/batch_training_generation_for_agent_self_training.py\" \\\n",
        "    --queries_addr \"/content/drive/MyDrive/mRAG_and_MSRS_source/train_test_jsons/train.json\" \\\n",
        "    --output_addr \"/content/drive/MyDrive/mRAG_and_MSRS_source/experiences/experience.json\" \\\n",
        "    --num_samples 4 \\\n",
        "    --max_workers 16 \\\n",
        "    --sampling_temperature 0.7 \\\n",
        "    --num_shards 1 \\\n",
        "    --shard_id 0 \\\n",
        "    --no_concise \\\n",
        "    --save_every_n 1\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84ef3780-7f05-461d-b33b-47ac663b30d8",
      "metadata": {
        "id": "84ef3780-7f05-461d-b33b-47ac663b30d8"
      },
      "outputs": [],
      "source": [
        "########### Isolate good training values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f1833225-c9d7-422e-bb5a-03b9aef62b49",
      "metadata": {
        "id": "f1833225-c9d7-422e-bb5a-03b9aef62b49"
      },
      "outputs": [],
      "source": [
        "# #!source \"/*address to the bin directory of the venv*/\"\n",
        "# !mamba run -n train_and_test python \"/content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/utils/extract_training_data_for_self_training.py\" \\\n",
        "#     --input_addr \"/content/drive/MyDrive/mRAG_and_MSRS_source/experiences/experience.json_0\" \\\n",
        "#     --output_addr \"/content/drive/MyDrive/mRAG_and_MSRS_source/train_test_jsons/refined_train.json\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec5e92fd-7ba4-48a1-ae7e-001cbac1c3f9",
      "metadata": {
        "id": "ec5e92fd-7ba4-48a1-ae7e-001cbac1c3f9"
      },
      "outputs": [],
      "source": [
        "########## Train agent with good training values"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#because saving as 4 bit quantized after:\n",
        "# !mamba run -n train_and_test pip install auto_gptq"
      ],
      "metadata": {
        "id": "iZGurNYrZvWt",
        "collapsed": true
      },
      "id": "iZGurNYrZvWt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ab26bf9-0501-4798-97f8-65ef8f849c8e",
      "metadata": {
        "id": "7ab26bf9-0501-4798-97f8-65ef8f849c8e",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# #!source \"/*address to the bin directory of the venv*/\"\n",
        "\n",
        "# #inputs_addr is single file containing inputs, a json\n",
        "# !mamba run -n train_and_test python \"/content/drive/MyDrive/mRAG_and_MSRS_source/inference_and_training/train_unsloth.py\" \\\n",
        "#     --inputs_addr \"/content/drive/MyDrive/mRAG_and_MSRS_source/train_test_jsons/refined_train.json\" \\\n",
        "#     --model_addr \"unsloth/Qwen2.5-0.5B-Instruct\" \\\n",
        "#     --output_dir \"/content/drive/MyDrive/mRAG_and_MSRS_source/unsloth_checkpoints\" \\\n",
        "#     --per_device_train_batch_size 1 \\\n",
        "#     --gradient_accumulation_steps 64 \\\n",
        "#     --learning_rate 0.0001 \\\n",
        "#     --weight_decay 0.0 \\\n",
        "#     --max_steps 50 \\\n",
        "#     --save_steps 25 \\\n",
        "#     --warmup_steps 50 \\\n",
        "#     --max_seq_length 2048"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1273e535-376e-4969-9e9b-ea7cabb805a9",
      "metadata": {
        "id": "1273e535-376e-4969-9e9b-ea7cabb805a9"
      },
      "outputs": [],
      "source": [
        "########## Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9243c83-4de5-4866-9a84-a90cbfe1291a",
      "metadata": {
        "id": "a9243c83-4de5-4866-9a84-a90cbfe1291a"
      },
      "outputs": [],
      "source": [
        "#NOTE: this --queries_addr is different from the one passed to batch_training_generation_for_agent_self_training.py above\n",
        "#this needs to be tinkered with to pass in the held out test set of the MSRS dataset since there isn't a question list provided by a competition(live rag)\n",
        "\n",
        "#expects jsonl as input\n",
        "\n",
        "\n",
        "#!source \"/*address to the bin directory of the venv*/\"\n",
        "# !mamba run -n train_and_test python inference-and-training/batch_agent_test_day.py \\\n",
        "#     --queries_addr \"/content/drive/MyDrive/train_test_jsons/test.json\" \\\n",
        "#     --output_addr \"/content/drive/MyDrive/test_runs/test_runs.jsonl\" \\\n",
        "#     --max_workers 32 \\\n",
        "#     --num_config 1 \\\n",
        "#     --no_concise \\\n",
        "#     --agent_name \"/*the address to the trained agent model*/\" \\\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#CHANGED TO:\n",
        "#python batch_agent_test_day.py \\\n",
        "#  --queries_addr /content/drive/MyDrive/your_tests/story_qa.json \\\n",
        "#  --output_addr  /content/drive/MyDrive/outputs/agent_runs.jsonl \\\n",
        "#  --max_workers 8 \\\n",
        "#  --num_config 1 \\\n",
        "#  --compute_metrics\n",
        "\n",
        "\n",
        "#tossed in pytrec_eval to generate some eval metrics\n",
        "\n",
        "#OR\n",
        "\n",
        "# How to use the metric/evaluation that is done in the training script, batch_training_generation_for_agent_self_training.py, for the test script\n",
        "\n",
        "\n",
        "#In Live Rag case fineweb taylored results are outputted and then graded by a judge, right?"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DzDtM_Hl0M1K"
      },
      "id": "DzDtM_Hl0M1K",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2ad78b352db24dfa980c18dbf4273bdb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cc8be01e63aa4b7db209bae0ab97c6af",
              "IPY_MODEL_ddfbebc0588746eaba0011e460d65ad6",
              "IPY_MODEL_14e1af12952647fab7e41f4e4a083298"
            ],
            "layout": "IPY_MODEL_03780aedb72749c78c3bf9777e1df3ab"
          }
        },
        "cc8be01e63aa4b7db209bae0ab97c6af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5633beeb17e24892ba2bea02a263c330",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_45777d0c16c04bdbb6371343449128de",
            "value": "README.md:â€‡"
          }
        },
        "ddfbebc0588746eaba0011e460d65ad6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_172543718d9441dd8b60eca6a8feb93a",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6a41485fc53e4660a6033b699ee5f3fc",
            "value": 1
          }
        },
        "14e1af12952647fab7e41f4e4a083298": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b4e0cc440c824aa8974fa194c496439e",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_d7329ecc02cb4be2815c378e724941d1",
            "value": "â€‡1.96k/?â€‡[00:00&lt;00:00,â€‡159kB/s]"
          }
        },
        "03780aedb72749c78c3bf9777e1df3ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5633beeb17e24892ba2bea02a263c330": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45777d0c16c04bdbb6371343449128de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "172543718d9441dd8b60eca6a8feb93a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "6a41485fc53e4660a6033b699ee5f3fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b4e0cc440c824aa8974fa194c496439e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7329ecc02cb4be2815c378e724941d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2e31699227d54db18a32e601ebe807a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_021c3ec1ff684d228e547dccd215e641",
              "IPY_MODEL_1b7b29d84faa4c5ab3aa8a698be7b4b7",
              "IPY_MODEL_a7d808a860914b2495bd11bc36a2dd69"
            ],
            "layout": "IPY_MODEL_de9cd1786ff44e56a907a3f3aa6bc122"
          }
        },
        "021c3ec1ff684d228e547dccd215e641": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_acc5f3df32a9454da53c6beccdd9bff5",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_dd2d6fc045ca4d74b39f963d4d74ed62",
            "value": "corpus.jsonl:â€‡"
          }
        },
        "1b7b29d84faa4c5ab3aa8a698be7b4b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_949cef931da1446d8d67936bbae0410d",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d3abb39ee9944750a3108948ef5beaf3",
            "value": 1
          }
        },
        "a7d808a860914b2495bd11bc36a2dd69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_88dffef9346d4803b6d097eda0ec4af9",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_e358b218c43d4b35a3d7b5bebb94423b",
            "value": "â€‡3.99M/?â€‡[00:00&lt;00:00,â€‡105MB/s]"
          }
        },
        "de9cd1786ff44e56a907a3f3aa6bc122": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "acc5f3df32a9454da53c6beccdd9bff5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd2d6fc045ca4d74b39f963d4d74ed62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "949cef931da1446d8d67936bbae0410d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "d3abb39ee9944750a3108948ef5beaf3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "88dffef9346d4803b6d097eda0ec4af9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e358b218c43d4b35a3d7b5bebb94423b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "00f154fffe6c42ec8ec345fc913d3d3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ceb043e76e444db59a440f19045c16f3",
              "IPY_MODEL_c40ded0841724894b5600e2cd8524227",
              "IPY_MODEL_5417bd40c614486cb0e181e21a737278"
            ],
            "layout": "IPY_MODEL_71b0159ba5c24c2b99d0714e88aaf5ff"
          }
        },
        "ceb043e76e444db59a440f19045c16f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dff9ef3b001b4a53a70ae3eff0bcb7cb",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_70b69f8ca43a41c8aef4c001c34265fa",
            "value": "Generatingâ€‡corpusâ€‡split:â€‡100%"
          }
        },
        "c40ded0841724894b5600e2cd8524227": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8bb4c95b68f8457db7a433d921ab6ad2",
            "max": 1138,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_173031b77c944f70b5d8f41dc7a978c7",
            "value": 1138
          }
        },
        "5417bd40c614486cb0e181e21a737278": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6fd042b3bb86488aa3d7afb45037e74d",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_a0c7d424fc5a4efd93642501e9cc8e39",
            "value": "â€‡1138/1138â€‡[00:00&lt;00:00,â€‡16037.30â€‡examples/s]"
          }
        },
        "71b0159ba5c24c2b99d0714e88aaf5ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dff9ef3b001b4a53a70ae3eff0bcb7cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70b69f8ca43a41c8aef4c001c34265fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8bb4c95b68f8457db7a433d921ab6ad2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "173031b77c944f70b5d8f41dc7a978c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6fd042b3bb86488aa3d7afb45037e74d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0c7d424fc5a4efd93642501e9cc8e39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8266eb85666c4bf3a12cbccb1da15b24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_16b02efa581f405d99569c81ee5f7937",
              "IPY_MODEL_737ecd1593424bd39c36149b069db59c",
              "IPY_MODEL_bc02d3f41983429ab26f0c624771fbcc"
            ],
            "layout": "IPY_MODEL_340b023546d4412fa9af0866bafa1a0b"
          }
        },
        "16b02efa581f405d99569c81ee5f7937": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_08ae6fa641684fd0ac306de1aa8a30a4",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_95870202f8ad4271bb18ee5a481d304e",
            "value": "corpus.jsonl:â€‡"
          }
        },
        "737ecd1593424bd39c36149b069db59c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_435a5445a9284b1d9ffe2f0ec206b8e9",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4f7c47e807d546c08d6bed464360ed15",
            "value": 1
          }
        },
        "bc02d3f41983429ab26f0c624771fbcc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_262d84953b864506be66cf270bf847db",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_de0f33fa7e0145719b11e72b33d4656e",
            "value": "â€‡7.42M/?â€‡[00:00&lt;00:00,â€‡120MB/s]"
          }
        },
        "340b023546d4412fa9af0866bafa1a0b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08ae6fa641684fd0ac306de1aa8a30a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95870202f8ad4271bb18ee5a481d304e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "435a5445a9284b1d9ffe2f0ec206b8e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "4f7c47e807d546c08d6bed464360ed15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "262d84953b864506be66cf270bf847db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de0f33fa7e0145719b11e72b33d4656e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f29cba1f3ef94106a39a75aa4f88d606": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_794e86e121b74cbab83d2afe9499fd97",
              "IPY_MODEL_3d3b4f1861da42a5a43b6020f5b16860",
              "IPY_MODEL_77536342dc0f4d77b8cad34ecfe02fda"
            ],
            "layout": "IPY_MODEL_c5989481862f43c1940235b64c796cf4"
          }
        },
        "794e86e121b74cbab83d2afe9499fd97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d49af1458474403ad3636b9901c6a39",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_03f9105782c242f5b0de34f226066586",
            "value": "Generatingâ€‡corpusâ€‡split:â€‡100%"
          }
        },
        "3d3b4f1861da42a5a43b6020f5b16860": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2127c4fa10624ec89a0db2cece5f0169",
            "max": 231,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a22d1795e0524349af104d8a5646aad0",
            "value": 231
          }
        },
        "77536342dc0f4d77b8cad34ecfe02fda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6c7ad5854dd54135a0ff688a5aab878a",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_7c54759f8b5f4d649fe67c8523ff68d7",
            "value": "â€‡231/231â€‡[00:00&lt;00:00,â€‡2973.10â€‡examples/s]"
          }
        },
        "c5989481862f43c1940235b64c796cf4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d49af1458474403ad3636b9901c6a39": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03f9105782c242f5b0de34f226066586": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2127c4fa10624ec89a0db2cece5f0169": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a22d1795e0524349af104d8a5646aad0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6c7ad5854dd54135a0ff688a5aab878a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c54759f8b5f4d649fe67c8523ff68d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "498c4afe79d147ce863ec384dc603983": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_44555aa9bb134d3bb2087f61fe717670",
              "IPY_MODEL_cd5ce2f5214347deaf221efae82d8d6f",
              "IPY_MODEL_c33dd65af2ca4ead907b86eba275672e"
            ],
            "layout": "IPY_MODEL_181828fd1ca7431c93962aa30e21b600"
          }
        },
        "44555aa9bb134d3bb2087f61fe717670": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c84030c227164541b9a9458b486b505b",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_9e01394d03e14558a41d8d0b583cd385",
            "value": "Creatingâ€‡jsonâ€‡fromâ€‡Arrowâ€‡format:â€‡100%"
          }
        },
        "cd5ce2f5214347deaf221efae82d8d6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_865c33a3258e43a7bfa7fdf83199a5b4",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_401ef170d34f421a90c6799aa7bc15b2",
            "value": 2
          }
        },
        "c33dd65af2ca4ead907b86eba275672e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ccdbc5e6caf45b1856e416bcf509210",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_e69664f152e74c01b557f3a1ccc3f779",
            "value": "â€‡2/2â€‡[00:00&lt;00:00,â€‡27.53ba/s]"
          }
        },
        "181828fd1ca7431c93962aa30e21b600": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c84030c227164541b9a9458b486b505b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e01394d03e14558a41d8d0b583cd385": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "865c33a3258e43a7bfa7fdf83199a5b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "401ef170d34f421a90c6799aa7bc15b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5ccdbc5e6caf45b1856e416bcf509210": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e69664f152e74c01b557f3a1ccc3f779": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "483cba3c924343af8a1cb29833d29a98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a230e6980f364e91b50368df1c162116",
              "IPY_MODEL_c6e8ce58b0b8498dbc9faa7b9a3230dd",
              "IPY_MODEL_be584e1d426e41848739b109afb8ecc3"
            ],
            "layout": "IPY_MODEL_f7315dedafd443369a8a30bcbb39186e"
          }
        },
        "a230e6980f364e91b50368df1c162116": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c1011b9798c345c5b071f842ea5007b2",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_625af6623ac947a6b41cdaeb6fe9c218",
            "value": "train.jsonl:â€‡"
          }
        },
        "c6e8ce58b0b8498dbc9faa7b9a3230dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_acd2217afcbf4eb4a8341b8de29ec4cc",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_39cc11419a0f46539a14b78713a9d014",
            "value": 1
          }
        },
        "be584e1d426e41848739b109afb8ecc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b05a0c74b5a14c7bb98d3f28b1d53654",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_7c7ef180d5b14c4bae29b02c7d472665",
            "value": "â€‡1.39M/?â€‡[00:00&lt;00:00,â€‡37.6MB/s]"
          }
        },
        "f7315dedafd443369a8a30bcbb39186e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1011b9798c345c5b071f842ea5007b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "625af6623ac947a6b41cdaeb6fe9c218": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "acd2217afcbf4eb4a8341b8de29ec4cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "39cc11419a0f46539a14b78713a9d014": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b05a0c74b5a14c7bb98d3f28b1d53654": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c7ef180d5b14c4bae29b02c7d472665": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "383dfde115834b68ae5e785a64d43c07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_73797b204b464b269eba7c40960bd837",
              "IPY_MODEL_204a4f9115cd4a1abc136a1d92c339b2",
              "IPY_MODEL_c1b80b7d105d45d4a13b64334e2fa25b"
            ],
            "layout": "IPY_MODEL_8ccfca73b3b24f6d8e0ebbf35998b818"
          }
        },
        "73797b204b464b269eba7c40960bd837": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_72a7dc2f647c40df88a1c59a1f745e0d",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_05981865bb8d4870b54a62ce00b3d251",
            "value": "dev.jsonl:â€‡"
          }
        },
        "204a4f9115cd4a1abc136a1d92c339b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3750b8054fb4aeaae6e27792e772d56",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0801df578756406f860f5a8bc82435f9",
            "value": 1
          }
        },
        "c1b80b7d105d45d4a13b64334e2fa25b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b1269758141941bb89a46c070f29bb81",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_e3801f1924fc4a3896e701ed7c13d111",
            "value": "â€‡701k/?â€‡[00:00&lt;00:00,â€‡922kB/s]"
          }
        },
        "8ccfca73b3b24f6d8e0ebbf35998b818": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72a7dc2f647c40df88a1c59a1f745e0d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05981865bb8d4870b54a62ce00b3d251": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e3750b8054fb4aeaae6e27792e772d56": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "0801df578756406f860f5a8bc82435f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b1269758141941bb89a46c070f29bb81": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3801f1924fc4a3896e701ed7c13d111": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "92a484041fd54055b7992f0d43fc2cef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1bb0edc0a9cb4e69bfc6dbe5cea3714b",
              "IPY_MODEL_58ada396b94f4958b3d9e708e46af8e8",
              "IPY_MODEL_86a923917ad64091a9366a891672a0ce"
            ],
            "layout": "IPY_MODEL_e4d105f3c100400a94c0d0792f6bcf90"
          }
        },
        "1bb0edc0a9cb4e69bfc6dbe5cea3714b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f75a5556c76c460f8fb033ed7a4c4410",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_8a04aaf00fdc44789e9a06c9f3e11edb",
            "value": "test.jsonl:â€‡"
          }
        },
        "58ada396b94f4958b3d9e708e46af8e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d906cbec4974cec96affca47d9a0dc5",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_50f8891ea99b426995fc2ccb1ae3da79",
            "value": 1
          }
        },
        "86a923917ad64091a9366a891672a0ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc029cb769dc445187a459a50d1ec1cf",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_0f5b0997298d411cb2ccd3a4337c96bf",
            "value": "â€‡1.46M/?â€‡[00:00&lt;00:00,â€‡51.2MB/s]"
          }
        },
        "e4d105f3c100400a94c0d0792f6bcf90": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f75a5556c76c460f8fb033ed7a4c4410": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a04aaf00fdc44789e9a06c9f3e11edb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2d906cbec4974cec96affca47d9a0dc5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "50f8891ea99b426995fc2ccb1ae3da79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fc029cb769dc445187a459a50d1ec1cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f5b0997298d411cb2ccd3a4337c96bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4914dcfd4ff74eaca9b4da7d66383ca3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7b83386a4ca9479fb0fbe1b8af2ebf52",
              "IPY_MODEL_4e6d1b23af8a49cda47b0ad9ff7b686b",
              "IPY_MODEL_32c1ad1b73684df789dae1ba9863e3ad"
            ],
            "layout": "IPY_MODEL_09e09715f1504522b946080f5b089edc"
          }
        },
        "7b83386a4ca9479fb0fbe1b8af2ebf52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e972c27fd96e40779000171c0b33f4e5",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_7498eb8d9a114fb2a474a728cf684772",
            "value": "Generatingâ€‡trainâ€‡split:â€‡100%"
          }
        },
        "4e6d1b23af8a49cda47b0ad9ff7b686b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_25f562a5f3ff4685a814ef4b4d07411d",
            "max": 250,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2016379acb81464caef78a769eaa40c9",
            "value": 250
          }
        },
        "32c1ad1b73684df789dae1ba9863e3ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a7ecc9ed8ca4b31836260eaf514513f",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_4b5299f6e6764188a853164689e62fdd",
            "value": "â€‡250/250â€‡[00:00&lt;00:00,â€‡3132.87â€‡examples/s]"
          }
        },
        "09e09715f1504522b946080f5b089edc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e972c27fd96e40779000171c0b33f4e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7498eb8d9a114fb2a474a728cf684772": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "25f562a5f3ff4685a814ef4b4d07411d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2016379acb81464caef78a769eaa40c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0a7ecc9ed8ca4b31836260eaf514513f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b5299f6e6764188a853164689e62fdd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6ad0a338f6fa4b969fdcae852bb2cfdc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e8bb8bd044c44bf29ff954a47b03d4a1",
              "IPY_MODEL_9120cde3bf054630a8577d16d2fdd07b",
              "IPY_MODEL_3be657354a974adea11b8e3bc512756d"
            ],
            "layout": "IPY_MODEL_2ec6b799affd40ebb7a5860988f9b590"
          }
        },
        "e8bb8bd044c44bf29ff954a47b03d4a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b83e8c1b7834a0a9b87c12ccd2ce91e",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_044635bb7db74c34828dce31e8b40871",
            "value": "Generatingâ€‡validationâ€‡split:â€‡100%"
          }
        },
        "9120cde3bf054630a8577d16d2fdd07b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_25d567f59023498a9ed73040d9399855",
            "max": 125,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_75bc27194a994bb2b9d48ab6d155bd94",
            "value": 125
          }
        },
        "3be657354a974adea11b8e3bc512756d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_04d69989d80d45e89e42f35810720d42",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_36d808358a6e43848f5e8bf0b042d10c",
            "value": "â€‡125/125â€‡[00:00&lt;00:00,â€‡5699.59â€‡examples/s]"
          }
        },
        "2ec6b799affd40ebb7a5860988f9b590": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b83e8c1b7834a0a9b87c12ccd2ce91e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "044635bb7db74c34828dce31e8b40871": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "25d567f59023498a9ed73040d9399855": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75bc27194a994bb2b9d48ab6d155bd94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "04d69989d80d45e89e42f35810720d42": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36d808358a6e43848f5e8bf0b042d10c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3d9ba12e97db4a188d55f3782ec84012": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5a9c0e23e0284473b801e8d996b50722",
              "IPY_MODEL_2d6aae5018054772a602de77c384ce4c",
              "IPY_MODEL_42df521ef7214b8bab580696b3e4c86f"
            ],
            "layout": "IPY_MODEL_638582c8939a4c74ac238ca2a049b530"
          }
        },
        "5a9c0e23e0284473b801e8d996b50722": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_47e1b3a919eb45149d5f4f86c052f73b",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_31ad1bbf384c485f81939bb54c8eeeaa",
            "value": "Generatingâ€‡testâ€‡split:â€‡100%"
          }
        },
        "2d6aae5018054772a602de77c384ce4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e9cafc14fb96444688d1a2654d718c3e",
            "max": 260,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1a672719385d41059c06dee8adb3ed9d",
            "value": 260
          }
        },
        "42df521ef7214b8bab580696b3e4c86f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd247c398db642d88da036c422e9dc88",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_4d2a17750615455e981520969b99d872",
            "value": "â€‡260/260â€‡[00:00&lt;00:00,â€‡12416.81â€‡examples/s]"
          }
        },
        "638582c8939a4c74ac238ca2a049b530": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47e1b3a919eb45149d5f4f86c052f73b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31ad1bbf384c485f81939bb54c8eeeaa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e9cafc14fb96444688d1a2654d718c3e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a672719385d41059c06dee8adb3ed9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bd247c398db642d88da036c422e9dc88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d2a17750615455e981520969b99d872": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "16d8eae03294426ab081353e7169529a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_df2d71ce434e4f39bb481cdd82dec98b",
              "IPY_MODEL_9ba6d07c6491411bb38919ab7dd9d92a",
              "IPY_MODEL_e290c9b1e6194b3db96a8c19a412c3db"
            ],
            "layout": "IPY_MODEL_b597e26df0b149e19c50fe098bcc223a"
          }
        },
        "df2d71ce434e4f39bb481cdd82dec98b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_29730af95b924a1c9a3cd13bb269b215",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_1f9db07dbff34235921566d1f20eb857",
            "value": "Creatingâ€‡jsonâ€‡fromâ€‡Arrowâ€‡format:â€‡100%"
          }
        },
        "9ba6d07c6491411bb38919ab7dd9d92a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e2b8a5c96ef543a9bf9f8413534e432e",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fc9e8186346143bd93ce689e5bc8a87c",
            "value": 1
          }
        },
        "e290c9b1e6194b3db96a8c19a412c3db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb2b0e12dc0349948822fcd8d04493c2",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_fabb2754f63d4029b01d82124decdeae",
            "value": "â€‡1/1â€‡[00:00&lt;00:00,â€‡13.85ba/s]"
          }
        },
        "b597e26df0b149e19c50fe098bcc223a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29730af95b924a1c9a3cd13bb269b215": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f9db07dbff34235921566d1f20eb857": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e2b8a5c96ef543a9bf9f8413534e432e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc9e8186346143bd93ce689e5bc8a87c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cb2b0e12dc0349948822fcd8d04493c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fabb2754f63d4029b01d82124decdeae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
